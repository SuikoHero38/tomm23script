Title,Abstract,Keywords
World-Driven Access Control for Continuous Sensing,"Modern s increasingly rely on continuous monitoring of video, audio, or other   to provide their functionality, particularly in s such as the Microsoft Kinect and Google Glass. Continuous sensing by untrusted s poses significant privacy challenges for both  s and bystanders. Even honest s will struggle to manage  permissions using existing approaches.We propose a general, extensible framework for controlling access to   on multi- continuous sensing s. Our approach, world-driven access control, allows -world objects to explicitly specify access policies. This approach relieves the 's permission management burden while mediating access at the granularity of objects rather than full  streams. A trusted policy module on the  senses policies in the world and modifies s' ""views"" accordingly. For example, world-driven access control allows the  to automatically stop recording in bathrooms or remove bystanders from video frames,without the  prompted to specify or activate such policies. To convey and authenticate policies, we introduce passports, a new kind of certificate that includes both a policy and optionally the code for recognizing a -world object.We implement a proto  and use it to  the feasibility of world-driven access control in practice. Our evaluation suggests that world-driven access control can effectively reduce the 's permission management burden in emerging continuous sensing s. Our investigation also surfaces key challenges for future access control mechanisms for continuous sensing s.",wearable; ; access control; permissions; continuous sensing
SurroundWeb: Mitigating Privacy Concerns in a 3D Web Browser," s that mix digital and -world objects are becoming ity, but they raise serious privacy concerns as they require -time  input. These s are already  on smartphones and game consoles via Kinect, and will eventually emerge on the web . However, browsers do not expose the display interfaces needed to render  s. Previous security research focuses on controlling  access to  input alone, and do not deal with display interfaces. Recent research in human computer interactions has explored a variety of high-level rendering interfaces for  s, but these interfaces reveal sensitive  to the . Bringing  s to the web requires a high-level interface that mitigates privacy concerns. This paper s Surround Web, the first 3D web browser, which provides the novel functionality of rendering web content onto a room while tackling many of the inherent privacy challenges. Following the principle of least privilege, we propose three abstractions for  rendering: 1) the room skeleton lets s place content in response to the physical dimensions and locations of render able surfaces in a room, 2) the detection sandbox lets s declaratively place content near recognized objects in the room without revealing if the object is , and 3) satellite screens let s display content across s registered with Surround Web. Through  surveys, we validate that these abstractions limit the amount of revealed  to an acceptable degree. In addition, we  that a wide range of  s can be implemented with acceptable performance.",;JavaScript;web browser;projection mapping
"Prepose: Privacy, Security, and Reliability for -Based Programming","With the rise of s such as the Microsoft Kinect, Leap , and hand  s in phones (i.e., Samsung Galaxy S6), -based interfaces have become practical. Unfortunately, today, to recognize such s, s must have access to depth and video of the , exposing sensitive  about the  and her environment. Besides these privacy concerns, there are also security threats in -based s, such as multiple s registering the same , leading to a conflict (akin to Clickjacking on the web). We address these security and privacy threats with Prepose, a novel domain-specific language (DSL) for easily building  recognizers, combined with a  architecture that protects privacy, security, and reliability with untrusted s. We run Prepose code in a trusted core, and only return specific  events to s. Prepose is specifically designed to enable precise and sound static analysis using SMT solvers, allowing the  to check security and reliability properties before running a  recognizer. We demonstrate that Prepose is expressive by creating s in three reative domains: physical therapy, tai-chi, and ballet. We further  that runtime  matching in Prepose is fast, creating no noticeable lag, as measured on traces from Microsoft Kinect runs. To  that  checking at the time of submission to a  store is fast, we developed a total of four Z3-based static analyses to test for basic  safety and internal validity, to make sure the so-called protected s are not overridden, and to check inter- conflicts. Our static analysis scales well in practice: safety checking is under 0.5 seconds per , average validity checking time is only 188ms, lastly, for 97% of the cases, the conflict detection time is below 5 seconds, with only one query taking longer than 15 seconds.",;domain-specific language;kinect;security;privacy
Securing  Output," (AR) technologies, such as Microsoft's HoloLens head-mounted display and AR-enabled car windshields, are rapidly emerging. AR s provide s with   s by capturing input from a 's surroundings and overlaying  output on the 's perception of the  world. These s enable s to interact with and perceive  content in fundamentally new ways. However, the  nature of AR s raises serious security and privacy concerns. Prior work has focused primarily on input privacy risks stemming from s with unrestricted access to  . However, the risks associated with malicious or buggy AR output remain largely unexplored. For example, an AR windshield  could intentionally or accidentally obscure oncoming vehicles or safety-critical output of other AR s. In this work, we address the fundamental challenge of securing AR output in the face of malicious or buggy s. We design, proto, and evaluate Arya, an AR  that controls  output according to policies specified in a constrained yet expressive policy framework. In doing so, we  and overcome numerous challenges in securing AR output.",security;
Towards Security and Privacy for Multi- : Foundations with End s,"  (AR) technologies are becoming a ity. Prior works have identified security and privacy risks raised by these technologies, primarily considering individual s or AR s. However, we make two key observations: (1) s will not always use AR in isolation, but also in ecos of other s, and (2) since  AR s have only recently become available, the risks of AR have been largely hypothetical to date. To provide a foundation for understanding and addressing the security and privacy challenges of emerging AR technologies, grounded in the s of  s, we conduct a qualitative lab  with an  AR headset, the Microsoft HoloLens. We conduct our  in pairs - 22 participants across 11 pairs - wherein participants engage in paired and individual (but physically co-located) HoloLens activities. Through semi-structured interviews, we explore participants' security, privacy, and other concerns, raising key findings. For example, we find that despite the HoloLens's limitations, participants were easily immersed, treating  objects as  (e.g., stepping around them for fear of tripping). We also uncover numerous security, privacy, and safety concerns unique to AR (e.g., deceptive  objects misleading s about the  world), and a need for access control among s to manage shared physical spaces and  content embedded in those spaces. Our findings give us the opportunity to  broader lessons and key challenges to inform the design of emerging single-and multi- AR technologies.",;multi  interaction;privacy;security; studies
SoK: Authentication in Augmented and ," (AR) and  (VR) s are emerging as prominent contenders to todayâ€™s personal computers. As personal s, s will use AR and VR to store and access their sensitive  and thus will need secure and usable ways to authenticate. In this paper, we evaluate the state-of-the-art of authentication mechanisms for AR/VR s by atizing research efforts and practical deployments. By ing sâ€™ s with authentication on AR and VR, we gain insight into the important properties needed for authentication on these s. We then use these properties to perform a comprehensive evaluation of AR/VR authentication mechanisms both proposed in literature and used in practice. In all, we synthesize a coherent picture of the current state of authentication mechanisms for AR/VR s. We draw on our findings to provide concrete research directions and advice on implementing and evaluating future authentication methods.",
Privacy Leakage via Unrestricted -Position s in the Age of : A  of Snooping d Input on  Keyboards," (VR) has gained popularity in numerous fields, including gaming, social interactions, shopping, and education. In this paper, we conduct a comprehensive  to assess the trustworthiness of the embedded s on VR, which embed various forms of sensitive  that may put sâ€™ privacy at risk. We find that accessing most on-board s (e.g., , position, and button s) on VR SDKs/APIs, such as OpenVR, Oculus , and WebXR, requires no security permission, exposing a huge attack surface for an adversary to steal the â€™s privacy. We validate this vulnerability through developing malware programs and malicious websites and specifically explore to what extent it exposes the â€™s  in the context of keystroke snooping. To examine its actual threat in practice, the adversary in the considered attack  doesnâ€™t possess any labeled  from the  nor knowledge about the â€™s VR settings. Extensive experiments, involving two mainstream VR s and four keyboards with different typing mechanisms, demonstrate that our proof-of-concept attack can recognize the â€™s  typing with over 89.7% accuracy. The attack can recover the â€™s passwords with up to 84.9% recognition accuracy if three attempts are allowed and achieve an average of 87.1% word recognition rate for paragraph inference. We hope this  will help the community gain awareness of the vulnerability in the  management of current VR s and provide insights to facilitate the future design of more comprehensive and restricted  access control mechanisms.",keystroke-inference;-ity;cybersecurity
Low-effort VR Headset  Authentication Using Head-reverberated Sounds with Replay Resistance,"While  (VR) s are becoming increasingly common, efficiently verifying a VR   before granting personal access is still a challenge. Existing VR authentication methods require s to enter PINs or draw graphical passwords using controllers. Though the entry is in the  space, it can be observed by others in proximity and is subject to critical security issues. Furthermore, the in-air hand movements or handheld controller-based authentications require active  participation and are not time-efficient. This work proposes a low-effort VR  authentication  based on the unique skull-reverberated sounds, which can be acquired when the  wears the VR . Specifically, when the  puts on the VR  or is wearing it to log into an online account, the proposed  actively emits an ultrasonic signal to initiate the authentication session. The signal returning to the VR â€™s microphone has been reverberated by the â€™s head, which is unique in size, skull shape and mass. We thus extract head biometric  from the received signal for unobtrusive VR  authentication.Though active acoustic sensing has been broadly used on mobile s, no prior work has ever successfully applied such techniques to commodity VR s. Because VR s are designed to provide s with  immersion, the echo sounds used for active sensing are unwanted and severely suppressed. The raw audio before this process is also not accessible without kernel/hardware modifications. Thus, our work further solves the challenge of active acoustic sensing under echo cancellation to enable deploying our  on off-the-shelf VR s. Additionally, we  that the echo cancellation mechanism is naturally good to prevent acoustic replay attacks. The proposed  is developed based on an autoencoder and a convolutional neural network for biometric  extraction and recognition. Experiments with a standalone and a mobile phone VR headset  that our  efficiently verifies a  and is also replay-resistant.",;Authentication;Biometric
OcuLock: Exploring Human Visual  for Authentication in  Head-mounted Display,"The increasing popularity of  (VR) in a wide spectrum of s has generated sensitive personal  such as medical records and credit card . While protecting such  from unauthorized access is critical, directly applying traditional authentication methods (e.g., PIN) through new VR input modalities such as remote controllers and head navigation would cause security issues. The authentication action can be purposefully observed by attackers to infer the authentication input. Unlike any other mobile s, VR s   via a head-mounted display (HMD) that fully covers s' eye area without public exposure. Leveraging this feature, we explore human visual  (HVS) as a novel biometric authentication tailored for VR s. While previous works used eye globe movement (gaze) to authenticate smartphones or PCs, they suffer from a high error rate and low stability since eye gaze is highly dependent on cognitive states. In this paper, we explore the HVS as a whole to consider not just the eye globe movement but also the eyelid, extraocular muscles, cells, and surrounding nerves in the HVS. Exploring HVS biostructure and unique HVS features triggered by  VR content can enhance authentication stability. To this end, we  OcuLock, an HVS-based  for reliable and unobservable VR HMD authentication. OcuLock is empowered by an electrooculography (EOG) based HVS sensing framework and a record-comparison driven authentication scheme. Experiments through 70 subjects  that OcuLock is resistant against common s of attacks such as impersonation attack and statistical attack with Equal Error Rates as low as 3.55% and 4.97% respectively. More importantly, OcuLock maintains a stable performance over a 2-month period and is preferred by s when compared to other potential approaches.",
SoundLock: A Novel  Authentication Scheme for VR s Using Auditory-Pupillary Response," (VR) has n promising potential in many s, such as e-business, healthcare, and social networking. Rich  regarding s’ activities and online accounts is stored in VR s. If they are carelessly unattended, adversarial access will cause  breaches and other critical consequences. Practical  authentication schemes for VR s are in dire need. Current solutions, including passwords, digital PINs, and pattern locks, mostly follow conventional approaches for general personal s. They have been criticized for deficits in both security and usability. In this work, we propose SoundLock, a novel  authentication scheme for VR s using auditory-pupillary response as biometrics. During authentication, auditory stimuli are ed to the  via the VR headset. The corresponding pupillary response is captured by the integrated eye tracker. ’s legitimacy is then determined by comparing the response with the template generated during the enrollment stage. To strike a balance between security and usability in the scheme design, an optimization problem is formulated. Due to its nonlinearity, a two-stage heuristic algorithm is proposed to solve it efficiently. The solution provides necessary guidance for selecting effective auditory stimuli and determining their corresponding lengths. We demonstrate through extensive in-field experiments that SoundLock outperforms state-of-the-art biometric solutions with FAR (FRR) as low as 0.76%(0.91%) and is well received among participants in the  .",
Lumos: ing and Localizing Diverse Hidden IoT s in an Unfamiliar Environment,"Hidden IoT s are increasingly being used to snoop on s in hotel rooms or AirBnBs. We envision empowering s entering such unfamiliar environments to  and locate (e.g., hidden camera behind plants) diverse hidden s (e.g., cameras, microphones, speakers) using only their personal handhelds. What makes this challenging is the limited network visibility and physical access that a  has in such unfamiliar environments, coupled with the lack of specialized equipment. This paper s Lumos, a  that runs on commodity  s (e.g., phone, laptop) and enables s to  and locate WiFi-connected hidden IoT s and visualize their presence using an  interface. Lumos addresses key challenges in: (1) ing diverse s using only coarse-grained wireless layer features, without IP/DNS layer  and without knowledge of the WiFi channel assignments of the hidden s; and (2) locating the identified IoT s with respect to the  using only phone s and wireless signal strength measurements. We evaluated Lumos across 44 different IoT s spanning various s, s, and brands across six different environments. Our results  that Lumos can  hidden s with 95% accuracy and locate them with a median error of 1.5m within 30 minutes in a two-bedroom, 1000 sq. ft. apartment.",
OVRSEEN: Auditing Network Traffic and Privacy Policies in Oculus VR," (VR) is an emerging technology that enables new s but also introduces privacy risks. In this paper, we focus on Oculus VR (OVR), the leading  in the VR space and we provide the first comprehensive analysis of personal  exposed by OVR  and the  itself, from a combined networking and privacy policy perspective. We experimented with the Quest 2 headset and tested the most popular VR  available on the official Oculus and the SideQuest app stores. We developed OVRSEEN, a methodology and  for collecting, analyzing, and comparing network traffic and privacy policies on OVR. On the networking side, we captured and decrypted network traffic of VR , which was previously not possible on OVR, and we extracted  flows, defined as < app,  , destination >. Compared to the mobile and other app ecos, we found OVR to be more centralized and driven by tracking and analytics, rather than by third-party advertising. We  that the  s exposed by VR  include personally identifiable  (PII),   that can be used for fingerprinting, and VR-specific  s. By comparing the  flows found in the network traffic with statements made in the ' privacy policies, we found that approximately 70% of OVR  flows were not properly disclosed. Furthermore, we extracted additional context from the privacy policies, and we observed that 69% of the  flows were used for purposes unrelated to the core functionality of .",
Kal epsilon ido: -Time Privacy Control for Eye-Tracking s,"Recent advances in sensing and computing technologies have led to the rise of eye-tracking s. Ranging from mobiles to high-end  headsets, a wide spectrum of interactive s now employs eye-tracking. However, eye gaze  is a rich source of sensitive  that can reveal an individual's physiological and psychological traits. Prior approaches to protecting eye-tracking  suffer from two major drawbacks: they are either incompatible with the current eye-tracking eco or provide no formal privacy guarantee. In this paper, we propose Kal epsilon ido, an eyetracking  processing  that (1) provides a formal privacy guarantee, (2) integrates seamlessly with existing eyetracking ecos, and (3) operates in -time. Kal epsilon ido acts as an intermediary protection layer in the software stack of eye-tracking s. We conduct a comprehensive   and trace-based analysis to evaluate Kal epsilon ido. Our   s that the s enjoy a satisfactory level of utility from Kal epsilon ido. Additionally, we  empirical evidence of Kal epsilon ido's effectiveness in thwarting -world attacks on eye-tracking .",
AdCube: WebVR Ad Fraud and Practical Confinement of Third-Party Ads,"Web technology has evolved to offer 360-degree  browsing s. This new technology, called WebVR, enables  by rendering a three-dimensional world on an HTML canvas. Unfortunately, there exists no browser-supported way of sharing this canvas between different parties. Assuming an abusive ad service provider who exploits this absence, we  four new ad fraud attack methods. Our   demonstrates that the success rates of our attacks range from 88.23% to 100%, confirming their effectiveness. To mitigate the ed threats, we propose AdCube, which allows publishers to specify the behaviors of third-party ad code and enforce this specification. We  that AdCube is able to block the ed threats with a small page loading latency of 236 msec and a negligible frame-per-second (FPS) drop for nine WebVR official demo sites.",
Secure Multi- Content Sharing for  s," (AR), which overlays  content on top of the 's perception of the  world, has now begun to enter the consumer market. Besides smartphone s, early-stage head-mounted displays such as the Microsoft HoloLens are under active development. Many compelling uses of these technologies are multi-: e.g., inperson collaborative tools, multiplayer gaming, and telepresence. While prior work on AR security and privacy has studied potential risks from AR s, new risks will also arise among multiple human s. In this work, we explore the challenges that arise in designing secure and private content sharing for multi- AR. We analyze reative  case studies and atize design goals for security and functionality that a multi- AR  should support. We design an AR content sharing control module that achieves these goals and build a proto implementation (ShareAR) for the HoloLens. This work builds foundations for secure and private multi- AR interactions.",
 U: Defeating Face Liveness Detection by Building  s From Your Public Photos,"In this paper, we introduce a novel approach to bypass modern face authentication s. More specifically, by leveraging a handful of pictures of the target  taken from social media, we  how to create istic, textured, 3D facial s that undermine the security of widely used face authentication solutions. Our framework makes use of  (VR) s, incorporating along the way the ability to perform animations (e.g., raising an eyebrow or smiling) of the facial , in order to trick liveness detectors into believing that the 3D  is a  human face. The synthetic face of the  is displayed on the screen of the VR , and as the  rotates and translates in the  world, the 3D face moves accordingly. To an observing face authentication , the depth and  cues of the display match what would be expected for a human face. We argue that such VR-based spoofing attacks constitute a fundamentally new class of attacks that point to a serious weaknesses in camera-based authentication s: Unless they incorporate other sources of verifiable , s relying on color image  and camera  are prone to attacks via  ism. To demonstrate the practical nature of this threat, we conduct thorough experiments using an end-to-end implementation of our approach and  how it undermines the security of several face authentication solutions that include both -based and liveness detectors.",
Enabling Fine-Grained Permissions for  s with Recognizers," (AR) s sense the environment, then render  objects on human senses. Examples include smartphone s that annotate storefronts with reviews and XBox Kinect games that "" avatars"" mimicking human movements. No current OS has special support for such s. As a result, permissions for AR s are necessarily coarse-grained: s must ask for access to raw  feeds, such as video and audio. These raw feeds expose significant additional  beyond what s need, including sensitive  such as the ’s location, face, or surroundings.",
Exploring  Reactions and Mental s Towards Perceptual Manipulation Attacks in ,"Perceptual Manipulation Attacks (PMA) involve manipulating s’ multi-y (e.g., visual, auditory, haptic) perceptions of the world through  (MR) content, in order to influence s’ judgments and following actions. For example, a MR driving  that is expected to  safety-critical output might also (maliciously or unintentionally) overlay the wrong signal on a traffic sign, misleading the  into slamming on the brake. While current MR technology is sufficient to create such attacks, little research has been done to understand how s perceive, react to, and defend against such potential manipulations. To provide a foundation for understanding and addressing PMA in MR, we conducted an in-person  with 21 participants. We developed three PMA in which we focused on attacking three different perceptions: visual, auditory, and situational awareness. Our  first investigates how  reactions are affected by evaluating their performance on “microbenchmark” tasks under benchmark and different attack conditions. We observe both primary and secondary impacts from attacks, later impacting participants’ performance even under non-attack conditions. We follow up with interviews, surfacing a range of  reactions and interpretations of PMA. Through qualitative  analysis of our observations and interviews, we  various defensive strategies participants developed, and we observe how these strategies sometimes backfire. We derive recommendations for future investigation and defensive directions based on our findings.",
LocIn: Inferring Semantic Location from Spatial Maps in ," (MR) s capture 3D spatial maps of s' surroundings to integrate  content into their physical environment. Existing permission s implemented in popular MR s allow all MR  to access these 3D spatial maps without explicit permission. Unmonitored access of MR  to these 3D spatial maps poses serious privacy threats to s as these maps capture detailed geometric and semantic characteristics of s' environments. In this paper, we  LocIn, a new location inference attack that exploits these detailed characteristics embedded in 3D spatial maps to infer a 's indoor location . LocIn develops a multi-task approach to train an end-to-end encoder-decoder network that extracts a spatial feature reation for capturing contextual patterns of the 's environment. LocIn leverages this reation to detect 3D objects and surfaces and integrates them into a classification network with a novel unified optimization function to predict the 's indoor location. We demonstrate LocIn attack on spatial maps collected from three popular MR s. We  that LocIn infers a 's location  with an average 84.1% accuracy.",
"Hidden ity: Caution, Your Hand  Inputs in the   World are Visible to All!","Text entry is an inevitable task while using  (VR) s in a wide range of s such as remote learning, gaming, and  meeting. VR s enter passwords/pins to log in to their  accounts in various s and  regular text to compose emails or browse the internet. The typing activity on VR s is believed to be resistant to direct observation attacks as the  screen in an  environment is not directly visible to others  in physical proximity. This paper s a video-based side-channel attack, Hidden ity (HR), that s – although the  screen in VR s is not in direct sight of adversaries, the indirect observations might get exploited to steal the ’s private . The Hidden ity (HR) attack utilizes video clips of the ’s hand s while they  on the  screen to decipher the d text in various key entry scenarios on VR s including d pins and passwords. Experimental analysis performed on a large corpus of 368 video clips  that the Hidden ity  can successfully decipher an average of over 75% of the text inputs. The high success rate of our attack  led us to conduct a   to understand the ’s behavior and perception of security in . The analysis ed that over 95% of s were not aware of any security threats on VR s and believed the  environments to be secure from digital attacks. Our attack  challenges s’ false sense of security in  environments and emphasizes the need for more stringent security solutions in VR space.",
Erebus: Access Control for  s," (AR) is widely considered the next evolution in personal s, enabling seamless integration of the digital world into our ity. Such integration, however, often requires unfettered access to  , causing significant overprivilege for s that run on these s. Through analysis of 17 AR s and 45 popular AR s, we explore existing mechanisms for access control in AR s,  key trends in how AR s use  , and pinpoint unique threats s face in AR environments. Using these findings, we design and implement Erebus, an access control framework for AR s that enables fine-grained control over  used by AR s. Erebus achieves the principle of least privileged through creation of a domain-specific language (DSL) for permission control in AR s, allowing s to specify  needed for their functionality. Using this DSL, Erebus further enables s to customize app permissions to apply under specific  conditions. We implement Erebus on Google's ARCore SDK and port five existing AR s to demonstrate Erebus capability to secure various classes of . Performance results using these s and various microbenchmarks  that Erebus achieves its security goals while being practical, introducing negligible performance overhead to the AR .",
"Unique Identification of 50, 000+  s from Head & Hand  ","With the recent explosive growth of interest and investment in  (VR) and the so-called ""metaverse,"" public attention has rightly shifted toward the unique security and privacy threats that these s may pose. While it has long been known that people reveal  about themselves via their , the extent to which this makes an individual globally identifiable within  has not yet been widely understood. In this , we  that a large number of  VR s (N=55,541) can be uniquely and reliably identified across multiple sessions using just their head and hand  relative to  objects. After training a classification  on 5 minutes of  per person, a  can be uniquely identified amongst the entire pool of 50,000+ with 94.33% accuracy from 100 seconds of , and with 73.20% accuracy from just 10 seconds of . This work is the first to truly demonstrate the extent to which biomechanics may serve as a unique identifier in VR, on par with widely used biometrics such as facial or fingerprint recognition.",
Going through the s: AR/VR keylogging from  head s,"/ (AR/VR) are the next step in the evolution of ubiquitous computing after personal computers to mobile s. s of AR/VR continue to grow, including education and  workspaces, increasing opportunities for s to enter private text, such as passwords or sensitive corporate . In this work, we  that there is a serious security risk of d text in the foreground being inferred by a background , without requiring any special permissions. The key insight is that a ’s head moves in subtle ways as she s on a  keyboard, and these  signals are sufficient for inferring the text that a  s. We develop a , TyPose, that extracts these signals and automatically infers words or characters that a victim is typing. Once the  signals are collected, TyPose uses machine learning to segment the  signals in time to determine word/character boundaries, and also perform inference on the words/characters themselves. Our experimental evaluation on commercial AR/VR headsets demonstrate the feasibility of this attack, both in situations where multiple s’  is used for training (82% top-5 word classification accuracy) or when the attack is personalized to a particular victim (92% top-5 word classification accuracy). We also  that first-line defenses of reducing the sampling rate or precision of head tracking are ineffective, suggesting that more sophisticated mitigations are needed.",
Is Your Wallet Snitching On You? An Analysis on the Privacy Implications of Web3,"With the recent hype around the Metaverse and NFTs, Web3 is getting more and more popular. The goal of Web3 is to decentralize the web via decentralized s. Wallets play a crucial role as they act as an interface between these s and the . Wallets such as MetaMask are being used by millions of s nowadays. Unfortunately, Web3 is often advertised as more secure and private. However, decentralized s as well as wallets are based on traditional technologies, which are not designed with privacy of s in mind. In this paper, we analyze the privacy implications that Web3 technologies such as decentralized s and wallets have on s. To this end, we build a framework that measures exposure of wallet . First, we  whether  about installed wallets is being used to track s online. We analyze the top 100K websites and find evidence of 1,325 websites running scripts that probe whether s have wallets installed in their browser. Second, we measure whether decentralized s and wallets leak the 's unique wallet address to third-parties. We intercept the traffic of 616 decentralized s and 100 wallets and find over 2000 leaks across 211 s and more than 300 leaks across 13 wallets. Our  s that Web3 poses a threat to s' privacy and requires new designs towards more privacy-aware wallet architectures.",
It's all in your head(set): Side-channel attacks on AR/VR s,"With the increasing adoption of / (AR/VR) s, security and privacy concerns at tract attention from both academia and industry. This paper demonstrates that AR/VR s are vulnerable to side channel attacks launched from software; a malicious appli cation without any special permissions can infer private in formation about  interactions, other concurrent applica tions, or even the surrounding world. We develop a number of side-channel attacks targeting different s of private . Specifically, we demonstrate three attacks on the victim’s interactions, successfully recovering hand s, voice commands made by victims, and keystrokes on a  keyboard, with accuracy exceeding 90%. We also demon strate an  fingerprinting attack where the spy is able to  an  being launched by the victim. The final attack demonstrates that the adversary can perceive a bystander in the -world environment and estimate the bystander’s distance with Mean Absolute Error (MAE) of 10.3 cm. We believe the threats ed by our attacks are pressing; they expand our understanding of the threat  faced by these emerging s and inform the development of new AR/VR s that are resistant to these threats.",
A Peek into the Metaverse: Detecting 3D  Clones in Mobile Games,"3D s are indispensable assets in metaverse in general and mobile games in particular. Yet, these 3D s can be readily extracted, duplicated, or cloned, a ity that poses a considerable threat. Although instances of games duplicating 3D s from other games have been documented, the pervasiveness of this issue remains unexplored. In this paper, we undertake the first atic investigation of 3D  cloning within mobile games. However, multiple challenges have to be addressed for clone detection, including scalability, precision, and robustness. Our solution is 3DSCAN, an open source 3D Scanning tool for Clone Assessment and Notification. We have evaluated 3DSCAN with about 12.2 million static 3D s and 2.5 million animated 3D s extracted from 176K mobile games. With these 3D s, 3DSCAN determined that 63.03% of the static s are likely cloned ones (derived from 1,046,632 distinct s), and 37.07% animated 3D s are likely cloned ones (derived from 180,174 distinctive s). With a heuristic-based clone detection algorithm, 3DSCAN finally detected 5,238 mobile games likely containing unauthorized 3D  clones.",
FaceReader: Unobtrusively Mining Vital Signs and Vital Sign Embedded Sensitive Info via AR/VR  s,"The market size of  and  (AR/VR) has been expanding rapidly in recent years, with the use of face-mounted headsets extending beyond gaming to various  sectors, such as education, healthcare, and the military. Despite the rapid growth, the understanding of  leakage through -rich headsets remains in its infancy. Some of the headset's built-in s do not require s' permission to access, and any  and websites can acquire their readings. While theseunrestricted s are generally considered free of privacy risks, we find that an adversary could uncover private  by scrutinizing  readings, making existing AR/VR  and websites potential eavesdroppers. In this work, we investigate a novel, unobtrusive privacy attack called FaceReader, which reconstructs high-quality vital sign signals (breathing and heartbeat patterns) based on unrestricted AR/VR  s. FaceReader is built on the key insight that the headset is closely mounted on the 's face, allowing the  s to detect subtle facial vibrations produced by s' breathing and heartbeats. Based on the reconstructed vital signs, we further investigate three more advanced attacks, including gender recognition,  re-identification, and body fat ratio estimation. Such attacks pose severe privacy concerns, as an adversary may obtain s' sensitive demographic/physiological traits and potentially uncover their -world identities. Compared to prior privacy attacks relying on speeches and activities, FaceReader targets spontaneous breathing and heartbeat activities that are naturally produced by the human body and are unobtrusive to victims. In particular, we design an adaptive filter to dynamically mitigate the impacts of body s. We further employ advanced deep-learning techniques to reconstruct vital sign signals, achieving signal qualities comparable to those of dedicated medical instruments, as well as deriving sensitive gender, identity, and body fat . We conduct extensive experiments involving 35 s on three s of mainstream AR/VR headsets across 3 months. The results reveal that FaceReader can reconstruct vital signs with low mean errors and accurately detect gender (over 93.33%). The attack can also link/re- s across different , websites, and longitudinal sessions with over 97.83% accuracy. Furthermore, we  the first successful attempt at revealing body fat  from   , achieving a remarkably low estimation error of 4.43%.",ar/vr headsets;  s; sensitive info; vital sign
