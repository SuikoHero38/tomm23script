Database,Item Type,Publication Year,Title,Venue,Venue Rank,Abstract,Keywords,Found In Group1,Found In Group2,Duplicate
ACM DL,conferencePaper,2014,World-Driven Access Control for Continuous Sensing,CCS - ACM Conference on Computer and Communications Security,A*,"Modern applications increasingly rely on continuous monitoring of video, audio, or other sensor data to provide their functionality, particularly in platforms such as the Microsoft Kinect and Google Glass. Continuous sensing by untrusted applications poses significant privacy challenges for both device users and bystanders. Even honest users will struggle to manage application permissions using existing approaches.We propose a general, extensible framework for controlling access to sensor data on multi-application continuous sensing platforms. Our approach, world-driven access control, allows real-world objects to explicitly specify access policies. This approach relieves the user's permission management burden while mediating access at the granularity of objects rather than full sensor streams. A trusted policy module on the platform senses policies in the world and modifies applications' ""views"" accordingly. For example, world-driven access control allows the system to automatically stop recording in bathrooms or remove bystanders from video frames,without the user prompted to specify or activate such policies. To convey and authenticate policies, we introduce passports, a new kind of certificate that includes both a policy and optionally the code for recognizing a real-world object.We implement a prototype system and use it to study the feasibility of world-driven access control in practice. Our evaluation suggests that world-driven access control can effectively reduce the user's permission management burden in emerging continuous sensing systems. Our investigation also surfaces key challenges for future access control mechanisms for continuous sensing applications.",wearable; augmented reality; access control; permissions; continuous sensing,Keywords,Abstract,
IEEE,conferencePaper,2015,SurroundWeb: Mitigating Privacy Concerns in a 3D Web Browser,SP - IEEE Symposium on Security and Privacy,A*,"Immersive experiences that mix digital and real-world objects are becoming reality, but they raise serious privacy concerns as they require real-time sensor input. These experiences are already present on smartphones and game consoles via Kinect, and will eventually emerge on the web platform. However, browsers do not expose the display interfaces needed to render immersive experiences. Previous security research focuses on controlling application access to sensor input alone, and do not deal with display interfaces. Recent research in human computer interactions has explored a variety of high-level rendering interfaces for immersive experiences, but these interfaces reveal sensitive data to the application. Bringing immersive experiences to the web requires a high-level interface that mitigates privacy concerns. This paper presents Surround Web, the first 3D web browser, which provides the novel functionality of rendering web content onto a room while tackling many of the inherent privacy challenges. Following the principle of least privilege, we propose three abstractions for immersive rendering: 1) the room skeleton lets applications place content in response to the physical dimensions and locations of render able surfaces in a room, 2) the detection sandbox lets applications declaratively place content near recognized objects in the room without revealing if the object is present, and 3) satellite screens let applications display content across devices registered with Surround Web. Through user surveys, we validate that these abstractions limit the amount of revealed information to an acceptable degree. In addition, we show that a wide range of immersive experiences can be implemented with acceptable performance.",augmented reality;JavaScript;web browser;projection mapping,Keywords,Title_Abstract,
IEEE,conferencePaper,2016,"Prepose: Privacy, Security, and Reliability for Gesture-Based Programming",SP - IEEE Symposium on Security and Privacy,A*,"With the rise of sensors such as the Microsoft Kinect, Leap Motion, and hand motion sensors in phones (i.e., Samsung Galaxy S6), gesture-based interfaces have become practical. Unfortunately, today, to recognize such gestures, applications must have access to depth and video of the user, exposing sensitive data about the user and her environment. Besides these privacy concerns, there are also security threats in sensor-based applications, such as multiple applications registering the same gesture, leading to a conflict (akin to Clickjacking on the web). We address these security and privacy threats with Prepose, a novel domain-specific language (DSL) for easily building gesture recognizers, combined with a system architecture that protects privacy, security, and reliability with untrusted applications. We run Prepose code in a trusted core, and only return specific gesture events to applications. Prepose is specifically designed to enable precise and sound static analysis using SMT solvers, allowing the system to check security and reliability properties before running a gesture recognizer. We demonstrate that Prepose is expressive by creating gestures in three representative domains: physical therapy, tai-chi, and ballet. We further show that runtime gesture matching in Prepose is fast, creating no noticeable lag, as measured on traces from Microsoft Kinect runs. To show that gesture checking at the time of submission to a gesture store is fast, we developed a total of four Z3-based static analyses to test for basic gesture safety and internal validity, to make sure the so-called protected gestures are not overridden, and to check inter-gesture conflicts. Our static analysis scales well in practice: safety checking is under 0.5 seconds per gesture, average validity checking time is only 188ms, lastly, for 97% of the cases, the conflict detection time is below 5 seconds, with only one query taking longer than 15 seconds.",augmented reality;domain-specific language;kinect;security;privacy,Keywords,Title_Abstract_Keywords,
IEEE,conferencePaper,2017,Securing Augmented Reality Output,SP - IEEE Symposium on Security and Privacy,A*,"Augmented reality (AR) technologies, such as Microsoft's HoloLens head-mounted display and AR-enabled car windshields, are rapidly emerging. AR applications provide users with immersive virtual experiences by capturing input from a user's surroundings and overlaying virtual output on the user's perception of the real world. These applications enable users to interact with and perceive virtual content in fundamentally new ways. However, the immersive nature of AR applications raises serious security and privacy concerns. Prior work has focused primarily on input privacy risks stemming from applications with unrestricted access to sensor data. However, the risks associated with malicious or buggy AR output remain largely unexplored. For example, an AR windshield application could intentionally or accidentally obscure oncoming vehicles or safety-critical output of other AR applications. In this work, we address the fundamental challenge of securing AR output in the face of malicious or buggy applications. We design, prototype, and evaluate Arya, an AR platform that controls application output according to policies specified in a constrained yet expressive policy framework. In doing so, we identify and overcome numerous challenges in securing AR output.",security;augmented reality,Title_Abstract_Keywords,Abstract_Keywords,
IEEE,conferencePaper,2018,Towards Security and Privacy for Multi-user Augmented Reality: Foundations with End Users,SP - IEEE Symposium on Security and Privacy,A*,"Immersive augmented reality (AR) technologies are becoming a reality. Prior works have identified security and privacy risks raised by these technologies, primarily considering individual users or AR devices. However, we make two key observations: (1) users will not always use AR in isolation, but also in ecosystems of other users, and (2) since immersive AR devices have only recently become available, the risks of AR have been largely hypothetical to date. To provide a foundation for understanding and addressing the security and privacy challenges of emerging AR technologies, grounded in the experiences of real users, we conduct a qualitative lab study with an immersive AR headset, the Microsoft HoloLens. We conduct our study in pairs - 22 participants across 11 pairs - wherein participants engage in paired and individual (but physically co-located) HoloLens activities. Through semi-structured interviews, we explore participants' security, privacy, and other concerns, raising key findings. For example, we find that despite the HoloLens's limitations, participants were easily immersed, treating virtual objects as real (e.g., stepping around them for fear of tripping). We also uncover numerous security, privacy, and safety concerns unique to AR (e.g., deceptive virtual objects misleading users about the real world), and a need for access control among users to manage shared physical spaces and virtual content embedded in those spaces. Our findings give us the opportunity to identify broader lessons and key challenges to inform the design of emerging single-and multi-user AR technologies.",augmented reality;multi user interaction;privacy;security;user studies,Title_Abstract_Keywords,Title_Abstract_Keywords,
IEEE,conferencePaper,2023,Privacy Leakage via Unrestricted Motion-Position Sensors in the Age of Virtual Reality: A Study of Snooping Typed Input on Virtual Keyboards,SP - IEEE Symposium on Security and Privacy,A*,"Virtual Reality (VR) has gained popularity in numerous fields, including gaming, social interactions, shopping, and education. In this paper, we conduct a comprehensive study to assess the trustworthiness of the embedded sensors on VR, which embed various forms of sensitive data that may put usersâ€™ privacy at risk. We find that accessing most on-board sensors (e.g., motion, position, and button sensors) on VR SDKs/APIs, such as OpenVR, Oculus Platform, and WebXR, requires no security permission, exposing a huge attack surface for an adversary to steal the userâ€™s privacy. We validate this vulnerability through developing malware programs and malicious websites and specifically explore to what extent it exposes the userâ€™s information in the context of keystroke snooping. To examine its actual threat in practice, the adversary in the considered attack model doesnâ€™t possess any labeled data from the user nor knowledge about the userâ€™s VR settings. Extensive experiments, involving two mainstream VR systems and four keyboards with different typing mechanisms, demonstrate that our proof-of-concept attack can recognize the userâ€™s virtual typing with over 89.7% accuracy. The attack can recover the userâ€™s passwords with up to 84.9% recognition accuracy if three attempts are allowed and achieve an average of 87.1% word recognition rate for paragraph inference. We hope this study will help the community gain awareness of the vulnerability in the sensor management of current VR systems and provide insights to facilitate the future design of more comprehensive and restricted sensor access control mechanisms.",keystroke-inference;virtual-reality;cybersecurity,Title_Abstract,Title_Abstract_Keywords,
IEEE,conferencePaper,2023,Low-effort VR Headset User Authentication Using Head-reverberated Sounds with Replay Resistance,SP - IEEE Symposium on Security and Privacy,A*,"While Virtual Reality (VR) applications are becoming increasingly common, efficiently verifying a VR device user before granting personal access is still a challenge. Existing VR authentication methods require users to enter PINs or draw graphical passwords using controllers. Though the entry is in the virtual space, it can be observed by others in proximity and is subject to critical security issues. Furthermore, the in-air hand movements or handheld controller-based authentications require active user participation and are not time-efficient. This work proposes a low-effort VR device authentication system based on the unique skull-reverberated sounds, which can be acquired when the user wears the VR device. Specifically, when the user puts on the VR device or is wearing it to log into an online account, the proposed system actively emits an ultrasonic signal to initiate the authentication session. The signal returning to the VR deviceâ€™s microphone has been reverberated by the userâ€™s head, which is unique in size, skull shape and mass. We thus extract head biometric information from the received signal for unobtrusive VR device authentication.Though active acoustic sensing has been broadly used on mobile devices, no prior work has ever successfully applied such techniques to commodity VR devices. Because VR devices are designed to provide users with virtual reality immersion, the echo sounds used for active sensing are unwanted and severely suppressed. The raw audio before this process is also not accessible without kernel/hardware modifications. Thus, our work further solves the challenge of active acoustic sensing under echo cancellation to enable deploying our system on off-the-shelf VR devices. Additionally, we show that the echo cancellation mechanism is naturally good to prevent acoustic replay attacks. The proposed system is developed based on an autoencoder and a convolutional neural network for biometric data extraction and recognition. Experiments with a standalone and a mobile phone VR headset show that our system efficiently verifies a user and is also replay-resistant.",Virtual Reality;Authentication;Biometric,Abstract_Keywords,Abstract,
Web of Science,conferencePaper,2020,OcuLock: Exploring Human Visual System for Authentication in Virtual Reality Head-mounted Display,NDSS - Usenix Network and Distributed System Security Symposium,A*,"The increasing popularity of virtual reality (VR) in a wide spectrum of applications has generated sensitive personal data such as medical records and credit card information. While protecting such data from unauthorized access is critical, directly applying traditional authentication methods (e.g., PIN) through new VR input modalities such as remote controllers and head navigation would cause security issues. The authentication action can be purposefully observed by attackers to infer the authentication input. Unlike any other mobile devices, VR presents immersive experience via a head-mounted display (HMD) that fully covers users' eye area without public exposure. Leveraging this feature, we explore human visual system (HVS) as a novel biometric authentication tailored for VR platforms. While previous works used eye globe movement (gaze) to authenticate smartphones or PCs, they suffer from a high error rate and low stability since eye gaze is highly dependent on cognitive states. In this paper, we explore the HVS as a whole to consider not just the eye globe movement but also the eyelid, extraocular muscles, cells, and surrounding nerves in the HVS. Exploring HVS biostructure and unique HVS features triggered by immersive VR content can enhance authentication stability. To this end, we present OcuLock, an HVS-based system for reliable and unobservable VR HMD authentication. OcuLock is empowered by an electrooculography (EOG) based HVS sensing framework and a record-comparison driven authentication scheme. Experiments through 70 subjects show that OcuLock is resistant against common types of attacks such as impersonation attack and statistical attack with Equal Error Rates as low as 3.55% and 4.97% respectively. More importantly, OcuLock maintains a stable performance over a 2-month period and is preferred by users when compared to other potential approaches.",,Title_Abstract,Abstract,
Web of Science,conferencePaper,2023,SoundLock: A Novel User Authentication Scheme for VR Devices Using Auditory-Pupillary Response,NDSS - Usenix Network and Distributed System Security Symposium,A*,"Virtual Reality (VR) has shown promising potential in many applications, such as e-business, healthcare, and social networking. Rich information regarding users’ activities and online accounts is stored in VR devices. If they are carelessly unattended, adversarial access will cause data breaches and other critical consequences. Practical user authentication schemes for VR devices are in dire need. Current solutions, including passwords, digital PINs, and pattern locks, mostly follow conventional approaches for general personal devices. They have been criticized for deficits in both security and usability. In this work, we propose SoundLock, a novel user authentication scheme for VR devices using auditory-pupillary response as biometrics. During authentication, auditory stimuli are presented to the user via the VR headset. The corresponding pupillary response is captured by the integrated eye tracker. User’s legitimacy is then determined by comparing the response with the template generated during the enrollment stage. To strike a balance between security and usability in the scheme design, an optimization problem is formulated. Due to its nonlinearity, a two-stage heuristic algorithm is proposed to solve it efficiently. The solution provides necessary guidance for selecting effective auditory stimuli and determining their corresponding lengths. We demonstrate through extensive in-field experiments that SoundLock outperforms state-of-the-art biometric solutions with FAR (FRR) as low as 0.76%(0.91%) and is well received among participants in the user study.",,Abstract,Abstract,
Web of Science,conferencePaper,2022,OVRSEEN: Auditing Network Traffic and Privacy Policies in Oculus VR,USS - Usenix Security Symposium,A*,"Virtual reality (VR) is an emerging technology that enables new applications but also introduces privacy risks. In this paper, we focus on Oculus VR (OVR), the leading platform in the VR space and we provide the first comprehensive analysis of personal data exposed by OVR apps and the platform itself, from a combined networking and privacy policy perspective. We experimented with the Quest 2 headset and tested the most popular VR apps available on the official Oculus and the SideQuest app stores. We developed OVRSEEN, a methodology and system for collecting, analyzing, and comparing network traffic and privacy policies on OVR. On the networking side, we captured and decrypted network traffic of VR apps, which was previously not possible on OVR, and we extracted data flows, defined as < app, data type, destination >. Compared to the mobile and other app ecosystems, we found OVR to be more centralized and driven by tracking and analytics, rather than by third-party advertising. We show that the data types exposed by VR apps include personally identifiable information (PII), device information that can be used for fingerprinting, and VR-specific data types. By comparing the data flows found in the network traffic with statements made in the apps' privacy policies, we found that approximately 70% of OVR data flows were not properly disclosed. Furthermore, we extracted additional context from the privacy policies, and we observed that 69% of the data flows were used for purposes unrelated to the core functionality of apps.",,Abstract,Title_Abstract,
Web of Science,conferencePaper,2021,Kal epsilon ido: Real-Time Privacy Control for Eye-Tracking Systems,USS - Usenix Security Symposium,A*,"Recent advances in sensing and computing technologies have led to the rise of eye-tracking platforms. Ranging from mobiles to high-end mixed reality headsets, a wide spectrum of interactive systems now employs eye-tracking. However, eye gaze data is a rich source of sensitive information that can reveal an individual's physiological and psychological traits. Prior approaches to protecting eye-tracking data suffer from two major drawbacks: they are either incompatible with the current eye-tracking ecosystem or provide no formal privacy guarantee. In this paper, we propose Kal epsilon ido, an eyetracking data processing system that (1) provides a formal privacy guarantee, (2) integrates seamlessly with existing eyetracking ecosystems, and (3) operates in real-time. Kal epsilon ido acts as an intermediary protection layer in the software stack of eye-tracking systems. We conduct a comprehensive user study and trace-based analysis to evaluate Kal epsilon ido. Our user study shows that the users enjoy a satisfactory level of utility from Kal epsilon ido. Additionally, we present empirical evidence of Kal epsilon ido's effectiveness in thwarting real-world attacks on eye-tracking data.",,Abstract,Title_Abstract,
Web of Science,conferencePaper,2019,Secure Multi-User Content Sharing for Augmented Reality Applications,USS - Usenix Security Symposium,A*,"Augmented reality (AR), which overlays virtual content on top of the user's perception of the real world, has now begun to enter the consumer market. Besides smartphone platforms, early-stage head-mounted displays such as the Microsoft HoloLens are under active development. Many compelling uses of these technologies are multi-user: e.g., inperson collaborative tools, multiplayer gaming, and telepresence. While prior work on AR security and privacy has studied potential risks from AR applications, new risks will also arise among multiple human users. In this work, we explore the challenges that arise in designing secure and private content sharing for multi-user AR. We analyze representative application case studies and systematize design goals for security and functionality that a multi-user AR platform should support. We design an AR content sharing control module that achieves these goals and build a prototype implementation (ShareAR) for the HoloLens. This work builds foundations for secure and private multi-user AR interactions.",,Title_Abstract,Abstract,
Web of Science,conferencePaper,2016,Virtual U: Defeating Face Liveness Detection by Building Virtual Models From Your Public Photos,USS - Usenix Security Symposium,A*,"In this paper, we introduce a novel approach to bypass modern face authentication systems. More specifically, by leveraging a handful of pictures of the target user taken from social media, we show how to create realistic, textured, 3D facial models that undermine the security of widely used face authentication solutions. Our framework makes use of virtual reality (VR) systems, incorporating along the way the ability to perform animations (e.g., raising an eyebrow or smiling) of the facial model, in order to trick liveness detectors into believing that the 3D model is a real human face. The synthetic face of the user is displayed on the screen of the VR device, and as the device rotates and translates in the real world, the 3D face moves accordingly. To an observing face authentication system, the depth and motion cues of the display match what would be expected for a human face. We argue that such VR-based spoofing attacks constitute a fundamentally new class of attacks that point to a serious weaknesses in camera-based authentication systems: Unless they incorporate other sources of verifiable data, systems relying on color image data and camera motion are prone to attacks via virtual realism. To demonstrate the practical nature of this threat, we conduct thorough experiments using an end-to-end implementation of our approach and show how it undermines the security of several face authentication solutions that include both motion-based and liveness detectors.",,Abstract,Abstract,
Web of Science,conferencePaper,2023,LocIn: Inferring Semantic Location from Spatial Maps in Mixed Reality,USS - Usenix Security Symposium,A*,"Mixed reality (MR) devices capture 3D spatial maps of users' surroundings to integrate virtual content into their physical environment. Existing permission models implemented in popular MR platforms allow all MR apps to access these 3D spatial maps without explicit permission. Unmonitored access of MR apps to these 3D spatial maps poses serious privacy threats to users as these maps capture detailed geometric and semantic characteristics of users' environments. In this paper, we present LocIn, a new location inference attack that exploits these detailed characteristics embedded in 3D spatial maps to infer a user's indoor location type. LocIn develops a multi-task approach to train an end-to-end encoder-decoder network that extracts a spatial feature representation for capturing contextual patterns of the user's environment. LocIn leverages this representation to detect 3D objects and surfaces and integrates them into a classification network with a novel unified optimization function to predict the user's indoor location. We demonstrate LocIn attack on spatial maps collected from three popular MR devices. We show that LocIn infers a user's location type with an average 84.1% accuracy.",,Title_Abstract,Abstract,
Web of Science,conferencePaper,2023,"Hidden Reality: Caution, Your Hand Gesture Inputs in the Immersive Virtual World are Visible to All!",USS - Usenix Security Symposium,A*,"Text entry is an inevitable task while using Virtual Reality (VR) devices in a wide range of applications such as remote learning, gaming, and virtual meeting. VR users enter passwords/pins to log in to their user accounts in various applications and type regular text to compose emails or browse the internet. The typing activity on VR devices is believed to be resistant to direct observation attacks as the virtual screen in an immersive environment is not directly visible to others present in physical proximity. This paper presents a video-based side-channel attack, Hidden Reality (HR), that shows – although the virtual screen in VR devices is not in direct sight of adversaries, the indirect observations might get exploited to steal the user’s private information. The Hidden Reality (HR) attack utilizes video clips of the user’s hand gestures while they type on the virtual screen to decipher the typed text in various key entry scenarios on VR devices including typed pins and passwords. Experimental analysis performed on a large corpus of 368 video clips show that the Hidden Reality model can successfully decipher an average of over 75% of the text inputs. The high success rate of our attack model led us to conduct a user study to understand the user’s behavior and perception of security in virtual reality. The analysis showed that over 95% of users were not aware of any security threats on VR devices and believed the immersive environments to be secure from digital attacks. Our attack model challenges users’ false sense of security in immersive environments and emphasizes the need for more stringent security solutions in VR space.",,Abstract,Abstract,
Web of Science,conferencePaper,2023,Erebus: Access Control for Augmented Reality Systems,USS - Usenix Security Symposium,A*,"Augmented Reality (AR) is widely considered the next evolution in personal devices, enabling seamless integration of the digital world into our reality. Such integration, however, often requires unfettered access to sensor data, causing significant overprivilege for applications that run on these platforms. Through analysis of 17 AR systems and 45 popular AR applications, we explore existing mechanisms for access control in AR platforms, identify key trends in how AR applications use sensor data, and pinpoint unique threats users face in AR environments. Using these findings, we design and implement Erebus, an access control framework for AR platforms that enables fine-grained control over data used by AR applications. Erebus achieves the principle of least privileged through creation of a domain-specific language (DSL) for permission control in AR platforms, allowing applications to specify data needed for their functionality. Using this DSL, Erebus further enables users to customize app permissions to apply under specific user conditions. We implement Erebus on Google's ARCore SDK and port five existing AR applications to demonstrate Erebus capability to secure various classes of apps. Performance results using these applications and various microbenchmarks show that Erebus achieves its security goals while being practical, introducing negligible performance overhead to the AR system.",,Title_Abstract,Abstract,
Web of Science,conferencePaper,2023,"Unique Identification of 50, 000+ Virtual Reality Users from Head & Hand Motion Data",USS - Usenix Security Symposium,A*,"With the recent explosive growth of interest and investment in virtual reality (VR) and the so-called ""metaverse,"" public attention has rightly shifted toward the unique security and privacy threats that these platforms may pose. While it has long been known that people reveal information about themselves via their motion, the extent to which this makes an individual globally identifiable within virtual reality has not yet been widely understood. In this study, we show that a large number of real VR users (N=55,541) can be uniquely and reliably identified across multiple sessions using just their head and hand motion relative to virtual objects. After training a classification model on 5 minutes of data per person, a user can be uniquely identified amongst the entire pool of 50,000+ with 94.33% accuracy from 100 seconds of motion, and with 73.20% accuracy from just 10 seconds of motion. This work is the first to truly demonstrate the extent to which biomechanics may serve as a unique identifier in VR, on par with widely used biometrics such as facial or fingerprint recognition.",,Title_Abstract,Abstract,
Web of Science,conferencePaper,2023,Going through the motions: AR/VR keylogging from user head motions,USS - Usenix Security Symposium,A*,"Augmented Reality/Virtual Reality (AR/VR) are the next step in the evolution of ubiquitous computing after personal computers to mobile devices. Applications of AR/VR continue to grow, including education and virtual workspaces, increasing opportunities for users to enter private text, such as passwords or sensitive corporate information. In this work, we show that there is a serious security risk of typed text in the foreground being inferred by a background application, without requiring any special permissions. The key insight is that a user’s head moves in subtle ways as she types on a virtual keyboard, and these motion signals are sufficient for inferring the text that a user types. We develop a system, TyPose, that extracts these signals and automatically infers words or characters that a victim is typing. Once the sensor signals are collected, TyPose uses machine learning to segment the motion signals in time to determine word/character boundaries, and also perform inference on the words/characters themselves. Our experimental evaluation on commercial AR/VR headsets demonstrate the feasibility of this attack, both in situations where multiple users’ data is used for training (82% top-5 word classification accuracy) or when the attack is personalized to a particular victim (92% top-5 word classification accuracy). We also show that first-line defenses of reducing the sampling rate or precision of head tracking are ineffective, suggesting that more sophisticated mitigations are needed.",,Abstract,Abstract,
Web of Science,conferencePaper,2023,Is Your Wallet Snitching On You? An Analysis on the Privacy Implications of Web3,USS - Usenix Security Symposium,A*,"With the recent hype around the Metaverse and NFTs, Web3 is getting more and more popular. The goal of Web3 is to decentralize the web via decentralized applications. Wallets play a crucial role as they act as an interface between these applications and the user. Wallets such as MetaMask are being used by millions of users nowadays. Unfortunately, Web3 is often advertised as more secure and private. However, decentralized applications as well as wallets are based on traditional technologies, which are not designed with privacy of users in mind. In this paper, we analyze the privacy implications that Web3 technologies such as decentralized applications and wallets have on users. To this end, we build a framework that measures exposure of wallet information. First, we study whether information about installed wallets is being used to track users online. We analyze the top 100K websites and find evidence of 1,325 websites running scripts that probe whether users have wallets installed in their browser. Second, we measure whether decentralized applications and wallets leak the user's unique wallet address to third-parties. We intercept the traffic of 616 decentralized applications and 100 wallets and find over 2000 leaks across 211 applications and more than 300 leaks across 13 wallets. Our study shows that Web3 poses a threat to users' privacy and requires new designs towards more privacy-aware wallet architectures.",,Abstract,Title_Abstract,
Web of Science,conferencePaper,2023,It's all in your head(set): Side-channel attacks on AR/VR systems,USS - Usenix Security Symposium,A*,"With the increasing adoption of Augmented Reality/Virtual Reality (AR/VR) systems, security and privacy concerns at tract attention from both academia and industry. This paper demonstrates that AR/VR systems are vulnerable to side channel attacks launched from software; a malicious appli cation without any special permissions can infer private in formation about user interactions, other concurrent applica tions, or even the surrounding world. We develop a number of side-channel attacks targeting different types of private information. Specifically, we demonstrate three attacks on the victim’s interactions, successfully recovering hand gestures, voice commands made by victims, and keystrokes on a virtual keyboard, with accuracy exceeding 90%. We also demon strate an application fingerprinting attack where the spy is able to identify an application being launched by the victim. The final attack demonstrates that the adversary can perceive a bystander in the real-world environment and estimate the bystander’s distance with Mean Absolute Error (MAE) of 10.3 cm. We believe the threats presented by our attacks are pressing; they expand our understanding of the threat model faced by these emerging systems and inform the development of new AR/VR systems that are resistant to these threats.",,Abstract,Abstract,
ACM DL,conferencePaper,2023,FaceReader: Unobtrusively Mining Vital Signs and Vital Sign Embedded Sensitive Info via AR/VR Motion Sensors,CCS - ACM Conference on Computer and Communications Security,A*,"The market size of augmented reality and virtual reality (AR/VR) has been expanding rapidly in recent years, with the use of face-mounted headsets extending beyond gaming to various application sectors, such as education, healthcare, and the military. Despite the rapid growth, the understanding of information leakage through sensor-rich headsets remains in its infancy. Some of the headset's built-in sensors do not require users' permission to access, and any apps and websites can acquire their readings. While theseunrestricted sensors are generally considered free of privacy risks, we find that an adversary could uncover private information by scrutinizing sensor readings, making existing AR/VR apps and websites potential eavesdroppers. In this work, we investigate a novel, unobtrusive privacy attack called FaceReader, which reconstructs high-quality vital sign signals (breathing and heartbeat patterns) based on unrestricted AR/VR motion sensors. FaceReader is built on the key insight that the headset is closely mounted on the user's face, allowing the motion sensors to detect subtle facial vibrations produced by users' breathing and heartbeats. Based on the reconstructed vital signs, we further investigate three more advanced attacks, including gender recognition, user re-identification, and body fat ratio estimation. Such attacks pose severe privacy concerns, as an adversary may obtain users' sensitive demographic/physiological traits and potentially uncover their real-world identities. Compared to prior privacy attacks relying on speeches and activities, FaceReader targets spontaneous breathing and heartbeat activities that are naturally produced by the human body and are unobtrusive to victims. In particular, we design an adaptive filter to dynamically mitigate the impacts of body motions. We further employ advanced deep-learning techniques to reconstruct vital sign signals, achieving signal qualities comparable to those of dedicated medical instruments, as well as deriving sensitive gender, identity, and body fat information. We conduct extensive experiments involving 35 users on three types of mainstream AR/VR headsets across 3 months. The results reveal that FaceReader can reconstruct vital signs with low mean errors and accurately detect gender (over 93.33%). The attack can also link/re-identify users across different apps, websites, and longitudinal sessions with over 97.83% accuracy. Furthermore, we present the first successful attempt at revealing body fat information from motion sensor data, achieving a remarkably low estimation error of 4.43%.",ar/vr headsets; motion sensors; sensitive info; vital sign,Abstract,Abstract,
ACM DL,conferencePaper,2022,A Study of User Privacy in Android Mobile AR Apps,ASE - Automated Software Engineering,A*,"With the development of augmented reality (AR) technology, the use of mobile AR applications (MAR apps) is rising rapidly in various aspects of people’s everyday lives, such as games, shopping, and education. When compared to traditional apps, AR apps typically need access to the smartphone’s camera all the time and collect and analyze significantly more data, such as sensor data, geolocation, and biometric information. Due to the sensitivity and volume of data collected by MAR apps, new privacy concerns are raised. In this paper, we describe a preliminary empirical study of Android MAR apps in terms of the sensitive data collected by MAR apps, whether the collected data is well protected, and whether the data practice is publicly available so that users can learn about the data safety and make informed decisions when deciding which apps to install. In this study, we analyzed 390 real-world MAR apps and reported the dangerous permissions they requested, the data leaks detected in them, and the availability of their data safety.",user privacy; mobile application; data safety; privacy leak,Abstract,Title_Abstract_Keywords,
ACM DL,conferencePaper,2023,Eliciting Security &amp; Privacy-Informed Sharing Techniques for Multi-User Augmented Reality,CHI - Human Factors in Computing Systems,A*,"The HCI community has explored new interaction designs for collaborative AR interfaces in terms of usability and feasibility; however, security &amp; privacy (S&amp;P) are often not considered in the design process and left to S&amp;P professionals. To produce interaction proposals with S&amp;P in mind, we extend the user-driven elicitation method with a scenario-based approach that incorporates a threat model involving access control in multi-user AR. We conducted an elicitation study in two conditions, pairing AR/AR experts in one condition and AR/S&amp;P experts in the other, to investigate the impact of each pairing. We contribute a set of expert-elicited interactions for sharing AR content enhanced with access control provisions, analyze the benefits and tradeoffs of pairing AR and S&amp;P experts, and present recommendations for designing future multi-user AR interactions that better balance competing design goals of usability, feasibility, and S&amp;P in collaborative AR.",elicitation studies; threat modeling,Title,Title_Abstract,
ACM DL,conferencePaper,2023,Understanding Context to Capture when Reconstructing Meaningful Spaces for Remote Instruction and Connecting in XR,CHI - Human Factors in Computing Systems,A*,"Recent technological advances are enabling HCI researchers to explore interaction possibilities for remote XR collaboration using high-fidelity reconstructions of physical activity spaces. However, creating these reconstructions often lacks user involvement with an overt focus on capturing sensory context that does not necessarily augment an informal social experience. This work seeks to understand social context that can be important for reconstruction to enable XR applications for informal instructional scenarios. Our study involved the evaluation of an XR remote guidance prototype by 8 intergenerational groups of closely related gardeners using reconstructions of personally meaningful spaces in their gardens. Our findings contextualize physical objects and areas with various motivations related to gardening and detail perceptions of XR that might affect the use of reconstructions for remote interaction. We discuss implications for user involvement to create reconstructions that better translate real-world experience, encourage reflection, incorporate privacy considerations, and preserve shared experiences with XR as a medium for informal intergenerational activities.",metaverse; Extended Reality; 3D reconstruction; contextual capture; gardening; hobby activities; intergenerational study; remote instruction,Keywords,Abstract,
ACM DL,conferencePaper,2022,The Dark Side of Perceptual Manipulations in Virtual Reality,CHI - Human Factors in Computing Systems,A*,"“Virtual-Physical Perceptual Manipulations” (VPPMs) such as redirected walking and haptics expand the user’s capacity to interact with Virtual Reality (VR) beyond what would ordinarily physically be possible. VPPMs leverage knowledge of the limits of human perception to effect changes in the user’s physical movements, becoming able to (perceptibly and imperceptibly) nudge their physical actions to enhance interactivity in VR. We explore the risks posed by the malicious use of VPPMs. First, we define, conceptualize and demonstrate the existence of VPPMs. Next, using speculative design workshops, we explore and characterize the threats/risks posed, proposing mitigations and preventative recommendations against the malicious use of VPPMs. Finally, we implement two sample applications to demonstrate how existing VPPMs could be trivially subverted to create the potential for physical harm. This paper aims to raise awareness that the current way we apply and publish VPPMs can lead to malicious exploits of our perceptual vulnerabilities.",VR security; physical harm; virtual-physical perceptual manipulation; VPPM,Title_Abstract,Keywords,
ACM DL,conferencePaper,2022,"Something Personal from the Metaverse: Goals, Topics, and Contextual Factors of Self-Disclosure in Commercial Social VR",CHI - Human Factors in Computing Systems,A*,"Current Social VR literature provides limited insight on one of the most critical behaviors for developing and maintaining interpersonal relationships: self-disclosure. Therefore, we present an online survey (N = 126) investigating how users disclose personal information to each other in Social VR. Our results indicate that many participants see in Social VR access to authentic connections with others despite tending towards skepticism and privacy concerns. Most users disclose sexuality-related information, lifestyle preferences, and personal goals. In contrast, information that breaks anonymity, such as real names and more intimate aspects of oneself, are shared less commonly. Thereby, self-disclosure decisions depend on factors like the relationship to or age of disclosure recipients, the privacy of a virtual environment, the group size, or the activity context, and is driven by different goals, i.a., relational development or exploration of oneself. These insights advance the understanding of current Social VR users and their behavior by directing future research on self-disclosure-based relationship building in Social VR and outlying broader design implications for the future metaverse.",social virtual reality; self-disclosure; online social interaction,Title_Abstract_Keywords,Abstract,
ACM DL,conferencePaper,2021,Identifying Manipulative Advertising Techniques in XR Through Scenario Construction,CHI - Human Factors in Computing Systems,A*,"As Extended Reality (XR) devices and applications become more mainstream, so too will XR advertising&nbsp;—&nbsp;advertising that takes place in XR mediums. Due to the defining features of XR devices, such as the immersivity of the medium and the ability of XR devices to simulate reality, there are fears that these features could be exploited to create manipulative XR ads that trick consumers into buying products they do not need or might harm them. Using scenario construction, we investigate potential future incarnations of manipulative XR advertising and their harms. We identify five key mechanisms of manipulative XR advertising: misleading experience marketing; inducing artificial emotions in consumers; sensing and targeting people when they are vulnerable; emotional manipulation through hyperpersonalization; and distortion of reality. We discuss research challenges and questions in order to address and mitigate manipulative XR advertising risks.",augmented reality; privacy; virtual reality; mixed reality; advertising; computer ethics.; Extended reality; scenario construction,Abstract_Keywords,Keywords,
ACM DL,conferencePaper,2021,Understanding User Identification in Virtual Reality Through Behavioral Biometrics and the Effect of Body Normalization,CHI - Human Factors in Computing Systems,A*,"Virtual Reality (VR) is becoming increasingly popular both in the entertainment and professional domains. Behavioral biometrics have recently been investigated as a means to continuously and implicitly identify users in VR. Applications in VR can specifically benefit from this, for example, to adapt virtual environments and user interfaces as well as to authenticate users. In this work, we conduct a lab study (N = 16) to explore how accurately users can be identified during two task-driven scenarios based on their spatial movement. We show that an identification accuracy of up to 90% is possible across sessions recorded on different days. Moreover, we investigate the role of users’ physiology in behavioral biometrics by virtually altering and normalizing their body proportions. We find that body normalization in general increases the identification rate, in some cases by up to 38%; hence, it improves the performance of identification systems.",usable security; virtual reality; identification; task-driven biometrics,Title_Abstract_Keywords,Keywords,
ACM DL,conferencePaper,2021,RepliCueAuth: Validating the Use of a Lab-Based Virtual Reality Setup for Evaluating Authentication Systems,CHI - Human Factors in Computing Systems,A*,"Evaluating novel authentication systems is often costly and time-consuming. In this work, we assess the suitability of using Virtual Reality (VR) to evaluate the usability and security of real-world authentication systems. To this end, we conducted a replication study and built a virtual replica of CueAuth [52], a recently introduced authentication scheme, and report on results from: (1) a lab-based in-VR usability study (N=20) evaluating user performance; (2) an online security study (N=22) evaluating system’s observation resistance through virtual avatars; and (3) a comparison between our results and those previously reported in the real-world evaluation. Our analysis indicates that VR can serve as a suitable test-bed for human-centred evaluations of real-world authentication schemes, but the used VR technology can have an impact on the evaluation. Our work is a first step towards augmenting the design and evaluation spectrum of authentication systems and offers ground work for more research to follow.",Virtual Reality; Usable Security; Authentication; Research Method,Title_Abstract_Keywords,Abstract_Keywords,
ACM DL,conferencePaper,2021,Covert Embodied Choice: Decision-Making and the Limits of Privacy Under Biometric Surveillance,CHI - Human Factors in Computing Systems,A*,"Algorithms engineered to leverage rich behavioral and biometric data to predict individual attributes and actions continue to permeate public and private life. A fundamental risk may emerge from misconceptions about the sensitivity of such data, as well as the agency of individuals to protect their privacy when fine-grained (and possibly involuntary) behavior is tracked. In this work, we examine how individuals adjust their behavior when incentivized to avoid the algorithmic prediction of their intent. We present results from a virtual reality task in which gaze, movement, and other physiological signals are tracked. Participants are asked to decide which card to select without an algorithmic adversary anticipating their choice. We find that while participants use a variety of strategies, data collected remains highly predictive of choice (80% accuracy). Additionally, a significant portion of participants became more predictable despite efforts to obfuscate, possibly indicating mistaken priors about the dynamics of algorithmic prediction.",privacy; biometrics; virtual reality; surveillance; prediction,Abstract_Keywords,Title_Abstract_Keywords,
ACM DL,conferencePaper,2021,Crowdsourcing Design Guidance for Contextual Adaptation of Text Content in Augmented Reality,CHI - Human Factors in Computing Systems,A*,"Augmented Reality (AR) can deliver engaging user experiences that seamlessly meld virtual content with the physical environment. However, building such experiences is challenging due to the developer’s inability to assess how uncontrolled deployment contexts may influence the user experience. To address this issue, we demonstrate a method for rapidly conducting AR experiments and real-world data collection in the user’s own physical environment using a privacy-conscious mobile web application. The approach leverages the large number of distinct user contexts accessible through crowdsourcing to efficiently source diverse context and perceptual preference data. The insights gathered through this method complement emerging design guidance and sample-limited lab-based studies. The utility of the method is illustrated by re-examining the design challenge of adapting AR text content to the user’s environment. Finally, we demonstrate how gathered design insight can be operationalized to provide adaptive text content functionality in an AR headset.",Augmented Reality; Privacy; Crowdsourcing,Title_Abstract_Keywords,Abstract_Keywords,
ACM DL,conferencePaper,2014,In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies,CHI - Human Factors in Computing Systems,A*,"Augmented reality (AR) devices are poised to enter the market. It is unclear how the properties of these devices will affect individuals' privacy. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in cafés and interviewed 31 bystanders regarding their reactions to a co-located AR device. Participants were predominantly split between having indifferent and negative reactions to the device. Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology's lack of prevalence. Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken. Participants expressed interest in being asked permission before being recorded and in recording-blocking devices. We use the interview results to guide an exploration of design directions for privacy-mediating technologies.",augmented reality; privacy; surveillance; wearable camera,Title_Abstract_Keywords,Title_Abstract_Keywords,
IEEE,conferencePaper,2022,Combining Real-World Constraints on User Behavior with Deep Neural Networks for Virtual Reality (VR) Biometrics,VR - International Symposium Virtual Reality,A*,"Deep networks have demonstrated enormous potential for identification and authentication using behavioral biometrics in virtual reality (VR). However, existing VR behavioral biometrics datasets have small sample sizes which can make it challenging for deep networks to automatically learn features that characterize real-world user behavior and that may enable high success, e.g., high-level spatial relationships between headset and hand controller devices and underlying smoothness of trajectories despite noise. We provide an approach to perform behavioral biometrics using deep networks while incorporating spatial and smoothing constraints on input data to represent real-world behavior. We represent the input data to neural networks as a combination of scale- and translation-invariant device-centric position and orientation features, and displacement vectors representing spatial relationships between device pairs. We assess identification and authentication by including spatial relationships and by performing Gaussian smoothing of the position features. We evaluate our approach against baseline methods that use the raw data directly and that perform a global normalization of the data. By using displacement vectors, our work shows higher success over baseline methods in 36 out of 42 cases of analysis done by varying user sets and pairings of VR systems and sessions.",Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Security and privacy;Security services;Authentication;Biometrics,Title_Abstract_Keywords,Keywords,
IEEE,conferencePaper,2022,HoloLogger: Keystroke Inference on Mixed Reality Head Mounted Displays,VR - International Symposium Virtual Reality,A*,"When using personal computing services in mixed reality (MR) such as online payment and social media, sensitive information and account passwords must be typed in MR. To design secure MR systems and build up user trust, it is imperative to first understand the security threat to the sensitive MR input. Although keystroke inference attacks by analyzing human-computer interaction in videos or via wireless signals have been successful, they require placing extra hardware near the user which is easily noticeable in practice. In this paper, we expose a more dangerous malware-based attack through the vulnerability that no permission is required for accessing MR motion data. We aim to monitor MR headset motion and infer the user input through a benign App. Realizing the attack system requires addressing unique challenges in MR such as six-degree-of-freedom (6DoF) device motion and no explicit motion signal for keystroke identification. To this end, we present HoloLogger, the first malware-based keystroke inference attack system on HoloLens. HoloLogger is empowered by a 6DoF-head-motion-driven key tracking scheme and an air-tap-pattern-based keystroke inference framework. Extensive evaluations with 25 users and 750 inference trials of passwords consisting of 4â€“8 lowercase English letters demonstrate that HoloLogger successfully achieves a top-5 accuracy of 93%. HoloLogger is also robust in various environments such as different user positions and input categories.",Human-centered computing;Human computer interaction;Mixed/augmented reality;Security and privacy;Human and societal aspects of security and privacy;Privacy protection,Title_Abstract_Keywords,Abstract_Keywords,
IEEE,conferencePaper,2022,SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image Classifiers,VR - International Symposium Virtual Reality,A*,"Light-based adversarial attacks use spatial augmented reality (SAR) techniques to fool image classifiers by altering the physical light condition with a controllable light source, e.g., a projector. Compared with physical attacks that place hand-crafted adversarial objects, projector-based ones obviate modifying the physical entities, and can be performed transiently and dynamically by altering the projection pattern. However, subtle light perturbations are insufficient to fool image classifiers, due to the complex environment and project-and-capture process. Thus, existing approaches focus on projecting clearly perceptible adversarial patterns, while the more interesting yet challenging goal, stealthy projector-based attack, remains open. In this paper, for the first time, we formulate this problem as an end-to-end differentiable process and propose a Stealthy Projector-based Adversarial Attack (SPAA) solution. In SPAA, we approximate the real Project-and-Capture process using a deep neural network named PCNet, then we include PCNet in the optimization of projector-based attacks such that the generated adversarial projection is physically plausible. Finally, to generate both robust and stealthy adversarial projections, we propose an algorithm that uses minimum perturbation and adversarial confidence thresholds to alternate between the adversarial loss and stealthiness loss optimization. Our experimental evaluations show that SPAA clearly outperforms other methods by achieving higher attack success rates and meanwhile being stealthier, for both targeted and untargeted attacks.",Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Security and privacy;Human and societal aspects of security and privacy;Privacy protections Computing methodologies;Artificial intelligence;Computer vision;Object recognition,Abstract_Keywords,Keywords,
IEEE,conferencePaper,2022,Temporal Effects in Motion Behavior for Virtual Reality (VR) Biometrics,VR - International Symposium Virtual Reality,A*,"Using the motion behavior of users in virtual reality (VR) as a biometric signature has the potential to enable continuous identification and authentication of users without compromising VR applications if traditional passwords are acquired by malicious agents. Users exhibit natural variabilities in behavior over time that influence their body motions and can alter the trajectories of VR devices such as the headset and the controllers. Behavior variabilities may negatively impact the success rate of VR biometrics. In this work, we evaluate how deep learning approaches to match input and enrollment trajectories are influenced by user behavior variation over varying time scales. We demonstrate that over short timescales on the order of seconds to minutes, no statistically significant relationship is found in the temporal placement of enrollment trajectories and their matches to input trajectories. We find that on medium-scale separation between enrollment and input trajectories, on the order of days to weeks, median accuracy is similar within users who provide input close and distant to enrollment data. Over long timescales on the order of 7 to 18 months, we obtain optimal performance for short and long enrollment/input separations by using training sets from users providing long-timescale data, as these sets encompass coarse and fine-scale changes in behavior.",Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Security and privacy;Security services;Authentication;Biometrics,Title_Abstract_Keywords,Keywords,
IEEE,conferencePaper,2022,A Keylogging Inference Attack on Air-Tapping Keyboards in Virtual Environments,VR - International Symposium Virtual Reality,A*,"Enabling users to push the physical worldâ€™s limits, augmented and virtual reality platforms opened a new chapter in perception. Novel immersive experiences resulted in the emergence of new interaction methods for virtual environments, which came with unprecedented security and privacy risks. This paper presents a keylogging inference attack to infer user inputs typed with in-air tapping keyboards. We observe that hands follow specific patterns when typing in the air and exploit this observation to carry out our attack. Starting with three plausible attack scenarios where the adversary obtains the hand trace patterns of the victim, we build a pipeline to reconstruct the user input. Our attack pipeline takes the hand traces of the victim as an input and outputs a set of input inferences ordered from the best to worst. Through various experiments, we showed that our inference attack achieves a pinpoint accuracy ranging from 40% to 87% within at most the top-500 candidate reconstructions. Finally, we discuss countermeasures, while the results presented provide a cautionary tale of the security and privacy risk of the immersive mobile technology.",Security and privacyâ€”Privacy protections;Human-centered computingâ€”Text input;Human-centered computingâ€”Ubiquitous and mobile devices,Abstract,Abstract_Keywords,
IEEE,conferencePaper,2021,Using Siamese Neural Networks to Perform Cross-System Behavioral Authentication in Virtual Reality,VR - International Symposium Virtual Reality,A*,"In this paper, we provide an approach on using behavioral biometrics to perform cross-system high-assurance authentication of users in virtual reality (VR) environments. VR is currently being explored as a critical tool to ensure seamless delivery of essential services, such as education, healthcare, and personal finance, while enabling users to work from home environments. Due to the sensitive nature of personal data generated, VR applications for essential services need to provide secure access. Traditional PIN or password-based credentials can be breached by malicious impostors, or be handed over by an intended user of a VR system to a confederate to assist the intended user in completing a task, e.g., an exam or a physical therapy routine. Existing approaches that use the behavior of the user in VR as a biometric signature fail when users provide enrollment and use-time data on different VR systems. We use Siamese neural networks to learn a distance function that characterizes the systematic differences between data provided across pairs of dissimilar VR systems. Our approach provides average equal error rates (EERs) ranging from 1.38% to 3.86% for authentication using a benchmark dataset that consists of 41 users performing a ball-throwing task with 3 VR systems-an Oculus Quest, an HTC Vive, and an HTC Vive Cosmos. To compare to prior approaches in VR biometrics, we also obtain average accuracies for the task of identification, where given an input user's trajectory in a use-time VR system, we use Siamese networks to return the user with the top matching trajectory in an enrollment VR system as the label. We report identification results ranging from 87.82% to 98.53% with average improvements of 29.78%Â±8.58% and 30.78%Â±3.68% over existing approaches that use generic distance matching and fully convolutional networks on the enrollment dataset respectively.",Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Virtual reality;Security and privacy-Security services-Authentication-Biometrics,Title_Abstract_Keywords,Keywords,
IEEE,conferencePaper,2021,VR-Spy: A Side-Channel Attack on Virtual Key-Logging in VR Headsets,VR - International Symposium Virtual Reality,A*,"In Virtual Reality (VR), users typically interact with the virtual world using virtual keyboard to insert keywords, surfing the webpages, or typing passwords to access online accounts. Hence, it becomes imperative to understand the security of virtual keystrokes. In this paper, we present VR-Spy, a virtual keystrokes recognition method using channel state information (CSI) of WiFi signals. To the best of our knowledge, this is the first work that uses WiFi signals to recognize virtual keystrokes in VR headsets. The key idea behind VR -Spy is that the side-channel information of fine-granular hand movements associated with each virtual keystroke has a unique gesture pattern in the CSI waveforms. Our novel pattern extraction algorithm leverages signal processing techniques to extract the patterns from the variations of CSI. We implement VR-Spy using two Commercially Off-The-Shelf (COTS) devices, a transmitter (WAVLINK router), and a receiver (Intel NUC with an IWL 5300 NIC). Finally, VR-Spy achieves a virtual keystrokes recognition accuracy of 69.75% in comparison to techniques that assume very advanced adversary models with vision and motion sensors near the victim.",Human-centered computing-Gesture Computing-Virtual Key-logging Attack-Channel State Information,Abstract,Abstract,
IEEE,conferencePaper,2021,Influence of Interactivity and Social Environments on User Experience and Social Acceptability in Virtual Reality,VR - International Symposium Virtual Reality,A*,"Nowadays, Virtual Reality (VR) technology can be potentially used everywhere through wearable head-mounted displays. Nevertheless, it is still uncommon to see VR devices used in public settings. In these contexts, unaware bystanders in the surroundings might influence the User Experience (UX) and create concerns about the social acceptability of this technology. The user acts in a Social Environment (SE), characterized by surrounding people's number, proximity, and behavior. Simultaneously, VR applications often require a different degree of interactivity concerning body movements and controllers interaction. In this paper, the influence of Social Environments, and degree of interactivity on User Experience and social acceptability is investigated. Four Social Environments were simulated employing 360Â° Videos, and two VR games developed with two levels of interactivity. Results showed a statistically significant influence of Social Environments on Overall UX as well as Public VR, Interaction, Isolation, Privacy and Safety acceptability, and of the degree of interactivity on Presence, Valence, Arousal, Overall UX, UX Hedonic quality, and Safety acceptability. Findings indicate that Social Environments and degree of interactivity should be taken into account while designing VR applications.",Virtual Reality;Social Acceptability;User Experience;Social Environments;Interactivity;360Â° Videos,Title_Abstract_Keywords,Abstract,
IEEE,conferencePaper,2019,Investigating the Third Dimension for Authentication in Immersive Virtual Reality and in the Real World,VR - International Symposium Virtual Reality,A*,"Immersive Virtual Reality (IVR) is a growing 3D environment, where social and commercial applications will require user authentication. Similarly, smart homes in the real world (RW), offer an opportunity to authenticate in the third dimension. For both environments, there is a gap in understanding which elements of the third dimension can be leveraged to improve usability and security of authentication. In particular, investigating transferability of findings between these environments would help towards understanding how rapid prototyping of authentication concepts can be achieved in this context. We identify key elements from prior research that are promising for authentication in the third dimension. Based on these, we propose a concept in which users' authenticate by selecting a series of 3D objects in a room using a pointer. We created a virtual 3D replica of a real world room, which we leverage to evaluate and compare the factors that impact the usability and security of authentication in IVR and RW. In particular, we investigate the influence of randomized user and object positions, in a series of user studies (N=48). We also evaluate shoulder surfing by real world bystanders for IVR (N=75). Our results show that 3D passwords within our concept are resistant against shoulder surfing attacks. Interactions are faster in RW compared to IVR, yet workload is comparable.",Human-centered computingâ€”User studies;Human-centered computingâ€”Virtual reality,Title_Abstract_Keywords,Abstract,
IEEE,conferencePaper,2019,Tracking-Tolerant Visual Cryptography,VR - International Symposium Virtual Reality,A*,"We introduce a novel secure display system, which uses visual cryptography [4] with tolerance for tracking. Our system brings cryptographic privacy from text to virtual worlds [3]. Much like traditional encryption that uses a public key and a private key, our system uses two images that are both necessary for visual decryption of the data. The public image could be widely shared on a printed page, on a traditional display (desktop, tablet, or smartphone), or in a multi-participant virtual world, while the other private image can be exclusively on a user's personal AR or VR display. Only the recipient is able to visually decrypt the data by fusing both images. In contrast to prior art, our system is able to provide tracking tolerance, making it more practically usable in modern VR and AR systems. We model the probability of misalignment caused by head or body jitter as a Gaussian distribution. Our algorithm diffuses the second image using the normalized probabilities, thus enabling the visual cryptography to be tolerant of alignment errors due to tracking.","visual cryptography;augmented reality (AR);tracking;H.5.1 [Information Interfaces and Presentation (e.g., HCI)]: Multimedia Information Systemsâ€”Artificial, augmented, and virtual realities;I.3.3 [Computer Graphics]: Picture/Image Generationâ€”Display algorithms",Keywords,Abstract,
IEEE,conferencePaper,2019,"Person Independent, Privacy Preserving, and Real Time Assessment of Cognitive Load using Eye Tracking in a Virtual Reality Setup",VR - International Symposium Virtual Reality,A*,"Eye tracking is handled as key enabling technology to VR and AR for multiple reasons, since it not only can help to massively reduce computational costs through gaze-based optimization of graphics and rendering, but also offers a unique opportunity to design gaze-based personalized interfaces and applications. Additionally, the analysis of eye tracking data allows to assess the cognitive load, intentions and actions of the user. In this work, we propose a person-independent, privacy-preserving and gaze-based cognitive load recognition scheme for drivers under critical situations based on previously collected driving data from a driving experiment in VR including a safety critical situation. Based on carefully annotated ground-truth information, we used pupillary information and performance measures (inputs on accelerator, brake, and steering wheel) to train multiple classifiers with the aim of assessing the cognitive load of the driver. Our results show that incorporating eye tracking data into the VR setup allows to predict the cognitive load of the user at a high accuracy above 80%. Beyond the specific setup, the proposed framework can be used in any adaptive and intelligent VR/AR application.","Eye tracking;cognitive load recognition;virtual reality;driving simulation;Computing methodologiesâ€”Computer graphicsâ€”Graphics systems and interfacesâ€”Virtual reality, Perception;Computing methodologiesâ€”Machine learningâ€”Machine learning approachesâ€”Classification and regression trees, Kernel methods;Human-centered computingâ€”Human computer interaction (HCI)â€”Empirical studies in HCI",Title_Keywords,Title_Abstract,
IEEE,conferencePaper,2019,Validating Virtual Reality as an Effective Training Medium in the Security Domain,VR - International Symposium Virtual Reality,A*,"Virtual Reality (VR) training simulations are an idea which is being explored in numerous industries and professions. However, evidence purporting to the effectiveness of VR technology in relation to standard real-world exercises is still relatively thin. In this paper, we discuss our approach for validating the effectiveness of a VR training for law enforcement professionals in the context of the AUGGMED project, and present results of the validation study. Our study indicates that realistic VR-based trainings, either by themselves or in combination with the traditional hands-on training, can be as effective as highly resource-intensive practical training sessions.",Virtual Reality;Training;Evaluation;Police,Title_Abstract_Keywords,Title,
IEEE,conferencePaper,2018,Human Identification Using Neural Network-Based Classification of Periodic Behaviors in Virtual Reality,VR - International Symposium Virtual Reality,A*,"There are a lot of techniques that help computer systems or devices identify their users in order to not only protect privacy, personal information, and sensitive data but also provide appropriate treatments, advertisements, or benefits. With passcode, password, fingerprint, or iris, people need to explicitly do some required activities such as typing their codes, showing their eyes, and putting their fingers on the scanners. Those solutions should be used in high-secure scenarios such as executing banking transactions and unlocking personal phones. In other systems such as gaming machines and collaborative frameworks, which aim to prioritize user experience and convenience, it would be better if user profile can be collected and built implicitly. Among those systems, virtual reality (VR) is a new trend, a new platform supporting not only fully immersive experience for gamers but also a collaborative environment for students, researchers, and other people. Currently, VR systems can track user physical activities via trackable devices such as HMD and VR controllers. Therefore, we aim to use virtual reality as our identification equipment. In virtual reality, we can easily simulate an invariant condition at any time so that people have larger probability to replicate their behaviors without any external affections. Therefore, we want to investigate if we could classify VR users based on their periodic interaction with virtual objects. We collect the position and direction of user's head or hands when doing a task and build a classification model based on those data using convolutional neural network approach. We have done an experiment to explore the capability of our proposed technique. The result was motivated with the highest accuracy of 90.92%. Identification in VR hence is potentially applicable. In the future, we plan to do a large-scale experiment with a larger group of participants to examine the strength of our method.",Human identification;virtual reality;neural network;classification;periodic task;Human-centered computing~Virtual reality;Computing methodologies~Neural networks,Title_Abstract_Keywords,Abstract,
IEEE,conferencePaper,2018,Cliffhanger-VR,VR - International Symposium Virtual Reality,A*,"The performance and security in outdoor climbing sports can depend on anxieties. These appear in frightening situations where, e.g. a deep fall is risked. Deep falls can lead to serious injuries or even to fatal accidents. Such situations can be trained in order to be mentally resistant to them and thereby to make climbing safer. However, drawbacks have to be taken into account. The trainee has to bring himself in a possible hazardous situation and nature is not directly reachable for every person. Thus, we present a system, where a user can climb at low heights in reality and simultaneously on a high cliff in VR. In this contribution, we describe the system architecture and future possibilities to safely train stressful outdoor climbing situations indoors.",Virtual Reality-Climbing-Mental Training-Body-Tracking-Finger-Tracking;,Keywords,Abstract,
IEEE,conferencePaper,2017,Using augmented reality to improve dismounted operators' situation awareness,VR - International Symposium Virtual Reality,A*,"Whether it in the military, law enforcement or private security, dismounted operators tend to deal with a large amount of volatile information that may or may not be relevant according to a variety of factors. In this paper we draft some ideas on the building blocks of an augmented reality system aimed to improve the situational awareness of dismounted operators by filtering, organizing, and displaying this information in a way that reduces the strain over the operator.",Situation Awareness;Augmented Reality,Title_Abstract_Keywords,Abstract,
IEEE,conferencePaper,2015,Mobile user interfaces for efficient verification of holograms,VR - International Symposium Virtual Reality,A*,"Paper documents such as passports, visas and banknotes are frequently checked by inspection of security elements. In particular, view-dependent elements such as holograms are interesting, but the expertise of individuals performing the task varies greatly. Augmented Reality systems can provide all relevant information on standard mobile devices. Hologram verification still takes long and causes considerable load for the user. We aim to address this drawback by first presenting a work flow for recording and automatic matching of hologram patches. Several user interfaces for hologram verification are presented, aiming to noticeably reduce verification time. We evaluate the most promising interfaces in a user study with prototype applications running on off-the-shelf hardware. Our results indicate that there is a significant difference in capture time between interfaces but that users do not prefer the fastest interface.",Document inspection;holograms;augmented reality;user interfaces;mobile devices,Abstract_Keywords,Abstract,
IEEE,conferencePaper,2022,NailRing: An Intelligent Ring for Recognizing Micro-gestures in Mixed Reality,ISMAR - International Symposium on Mixed and Augmented Reality,A*,"Gesture interaction is currently a main interaction technology in the field of mixed reality. However, long-term and large-scale gesture in mid-air will lead to muscle fatigue and privacy problems, which cannot meet the comfort requirements of continuous interaction and inevitably hinder the development of mixed reality systems. To solve this problem, we propose NailRing, an intelligent ring to recognize fingertip micro-gestures using a micro-close-focus camera on a fingertip bracket. Such fingertip physiological characteristics as the changes in fingertip color distribution and muscle shape changes caused by fingertip pressure have been studied. According to the recognition principle, ten types of micro-gestures have been designed and used for contact interaction and one-hand interaction respectively. The accuracy of gesture recognition (cross-session $ F_{Macro}=98.3\%$; cross-person $ F_{Macro}=86.4\%$) in user studies verifies the performances of NailRing under different interaction conditions. Finally, the capability of NailRing in a series of potential application scenarios has also been discussed and analyzed.",Human-centered computing;Human computer interaction (HCI);Interaction paradigms-Mixed / augmented reality;Interaction techniques;Gestural input,Title_Abstract_Keywords,Abstract,
IEEE,conferencePaper,2022,Enabling Customizable Workflows for Industrial AR Applications,ISMAR - International Symposium on Mixed and Augmented Reality,A*,"Augmented Reality (AR) is increasingly considered for use in real industrial applications [8]. In our industrial research lab at Siemens Technology, we are continuously discussing suitable AR scenarios in business sectors involving power plants, wind turbine plants, and oil and gas factories. We have developed a company-internal AR system architecture, Hololayer, which provides AR facilities in a reusable manner to development engineers such that they can build their own AR applications for their specialized use cases. The integration of AR technology into industrial processes encounters many complex issues: we need to adhere to many safety, security and quality guarantees while also adapting quickly to the rapidly changing state of the art of AR devices (HMDs, tablets). To increase flexibility, it might be good to integrate Hololayer with one of the open frameworks that have recently been proposed [11], [29], [38]. Yet, care must be taken when converting an already existing, large company-owned framework like Hololayer to such platforms. Some of the proposed standardized APIs and communication protocols may be difficult to abide by, without requiring significant rewriting efforts or even violating company-internal regulations. In this paper, we report on our efforts to combine Hololayer with one such platform, Ubi-Interact [38]. This is a collaboration between Siemens technology and the FAR group at TU Munich. After exemplary descriptions of typical application scenarios, we present the underlying principles of Hololayer to support this range of applications. We then describe rudimentary concepts of Ubi-Interact, followed by an elaboration on the efforts to combine both systems for a selected application scenario and a discussion of the results achieved thus far.",Human-centered computingUbiquitous and mobile computing;Human-centered computingHuman computer interaction (HCI)Interaction ParadigmsMixed / Augmented Reality,Abstract_Keywords,Abstract,
IEEE,conferencePaper,2014,[Poster] Using augmented reality to support information exchange of teams in the security domain,ISMAR - International Symposium on Mixed and Augmented Reality,A*,"For operational units in the security domain that work together in teams it is important to quickly and adequately exchange context-related information. This extended abstract investigates the potential of augmented reality (AR) techniques to facilitate information exchange and situational awareness of teams from the security domain. First, different scenarios from the security domain that have been elicited using an end-user oriented design approach are described. Second, a usability study is briefly presented based on an experiment with experts from operational security units. The results of the study show that the scenarios are well-defined and the AR environment can successfully support information exchange in teams operating in the security domain.",Augmented reality;information exchange;usability,Title_Abstract_Keywords,Title_Abstract,
ACM DL,conferencePaper,2023,Going Incognito in the Metaverse: Achieving Theoretically Optimal Privacy-Usability Tradeoffs in VR,UIST - Symposium on User Interface Software and Technology,A*,"Virtual reality (VR) telepresence applications and the so-called “metaverse” promise to be the next major medium of human-computer interaction. However, with recent studies demonstrating the ease at which VR users can be profiled and deanonymized, metaverse platforms carry many of the privacy risks of the conventional internet (and more) while at present offering few of the defensive utilities that users are accustomed to having access to. To remedy this, we present the first known method of implementing an “incognito mode” for VR. Our technique leverages local ε-differential privacy to quantifiably obscure sensitive user data attributes, with a focus on intelligently adding noise when and where it is needed most to maximize privacy while minimizing usability impact. Our system is capable of flexibly adapting to the unique needs of each VR application to further optimize this trade-off. We implement our solution as a universal Unity (C#) plugin that we then evaluate using several popular VR applications. Upon faithfully replicating the most well-known VR privacy attack studies, we show a significant degradation of attacker capabilities when using our solution.",data harvesting; differential privacy; identification; incognito mode; private browsing; profiling; usable security; virtual reality,Title_Abstract_Keywords,Title_Abstract_Keywords,
ACM DL,conferencePaper,2023,SmartPoser: Arm Pose Estimation with a Smartphone and Smartwatch Using UWB and IMU Data,UIST - Symposium on User Interface Software and Technology,A*,"The ability to track a user’s arm pose could be valuable in a wide range of applications, including fitness, rehabilitation, augmented reality input, life logging, and context-aware assistants. Unfortunately, this capability is not readily available to consumers. Systems either require cameras, which carry privacy issues, or utilize multiple worn IMUs or markers. In this work, we describe how an off-the-shelf smartphone and smartwatch can work together to accurately estimate arm pose. Moving beyond prior work, we take advantage of more recent ultra-wideband (UWB) functionality on these devices to capture absolute distance between the two devices. This measurement is the perfect complement to inertial data, which is relative and suffers from drift. We quantify the performance of our software-only approach using off-the-shelf devices, showing it can estimate the wrist and elbow joints with a median positional error of 11.0&nbsp;cm, without the user having to provide training data.",body pose; hand gestures; interaction techniques.; mobile devices; sensing; Smartwatch,Abstract,Abstract,
ACM DL,conferencePaper,2023,Reframe: An Augmented Reality Storyboarding Tool for Character-Driven Analysis of Security &amp; Privacy Concerns,UIST - Symposium on User Interface Software and Technology,A*,"While current augmented reality (AR) authoring tools lower the technical barrier for novice AR designers, they lack explicit guidance to consider potentially harmful aspects of AR with respect to security &amp; privacy (S&amp;P). To address potential threats in the earliest stages of AR design, we developed Reframe, a digital storyboarding tool for designers with no formal training to analyze S&amp;P threats. We accomplish this through a frame-based authoring approach, which captures and enhances storyboard elements that are relevant for threat modeling, and character-driven analysis tools, which personify S&amp;P threats from an underlying threat model to provide simple abstractions for novice AR designers. Based on evaluations with novice AR designers and S&amp;P experts, we find that Reframe enables designers to analyze threats and propose mitigation techniques that experts consider good quality. We discuss how Reframe can facilitate collaboration between designers and S&amp;P professionals and propose extensions to Reframe to incorporate additional threat models.",storyboarding; threat modeling,Title_Abstract,Title_Abstract,
ACM DL,conferencePaper,2019,Designing AR Visualizations to Facilitate Stair Navigation for People with Low Vision,UIST - Symposium on User Interface Software and Technology,A*,"Navigating stairs is a dangerous mobility challenge for people with low vision, who have a visual impairment that falls short of blindness. Prior research contributed systems for stair navigation that provide audio or tactile feedback, but people with low vision have usable vision and don't typically use nonvisual aids. We conducted the first exploration of augmented reality (AR) visualizations to facilitate stair navigation for people with low vision. We designed visualizations for a projection-based AR platform and smartglasses, considering the different characteristics of these platforms. For projection-based AR, we designed visual highlights that are projected directly on the stairs. In contrast, for smartglasses that have a limited vertical field of view, we designed visualizations that indicate the user's position on the stairs, without directly augmenting the stairs themselves. We evaluated our visualizations on each platform with 12 people with low vision, finding that the visualizations for projection-based AR increased participants' walking speed. Our designs on both platforms largely increased participants' self-reported psychological security.",accessibility; augmented reality; low vision; visualization,Abstract_Keywords,Abstract,
ACM DL,conferencePaper,2015,Candid Interaction: Revealing Hidden Mobile and Wearable Computing Activities,UIST - Symposium on User Interface Software and Technology,A*,"The growth of mobile and wearable technologies has made it often difficult to understand what people in our surroundings are doing with their technology. In this paper, we introduce the concept of candid interaction: techniques for providing awareness about our mobile and wearable device usage to others in the vicinity. We motivate and ground this exploration through a survey on current attitudes toward device usage during interpersonal encounters. We then explore a design space for candid interaction through seven prototypes that leverage a wide range of technological enhancements, such as Augmented Reality, shape memory muscle wire, and wearable projection. Preliminary user feedback of our prototypes highlights the trade-offs between the benefits of sharing device activity and the need to protect user privacy.",awareness; candid interaction; social acceptance; wearable devices,Abstract,Abstract,
Scopus,journalPaper,2022,Data Mining on Smartphones: An Introduction and Survey,CSUR - Computing Surveys,A*,"Data mining is the science of extracting information or ""knowledge""from data. It is a task commonly executed on cloud computing resources, personal computers and laptops. However, what about smartphones? Despite the fact that these ubiquitous mobile devices now offer levels of hardware and performance approaching that of laptops, locally executed model-training using data mining methods on smartphones is still notably rare. On-device model-training offers a number of advantages. It largely mitigates issues of data security and privacy, since no data is required to leave the device. It also ensures a self-contained, fully portable data mining solution requiring no cloud computing or network resources and able to operate in any location. In this article, we focus on the intersection of smartphones and data mining. We investigate the growth in smartphone performance, survey smartphone usage models in previous research, and look at recent developments in locally executed data mining on smartphones.  © 2022 Association for Computing Machinery.",augmented reality; data mining; decision trees; deep learning; smartphones; Survey,Keywords,Abstract,
Scopus,journalPaper,2019,Security and privacy approaches in mixed reality: A literature survey,CSUR - Computing Surveys,A*,"Mixed reality (MR) technology development is now gaining momentum due to advances in computer vision, sensor fusion, and realistic display technologies. With most of the research and development focused on delivering the promise of MR, the privacy and security implications of this technology are yet to be thoroughly investigated. This survey article aims to put in to light these risks and to look into the latest security and privacy work on MR. Specifically, we list and review the different protection approaches that have been proposed to ensure user and data security and privacy in MR. We extend the scope to include work on related technologies such as augmented reality, virtual reality, and human-computer interaction as crucial components, if not the origins, of MR, as well as numerous related work from the larger area of mobile devices, wearables, and Internet-of-Things. We highlight the lack of investigation, implementation, and evaluation of data protection approaches in MR. Further challenges and directions on MR security and privacy are also discussed. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Augmented reality; Mixed reality; Privacy; Security,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,journalPaper,2019,Indoor localization improved by spatial context - A survey,CSUR - Computing Surveys,A*,"Indoor localization is essential for healthcare, security, augmented reality gaming, and many other locationbased services. There is currently a wealth of relevant literature on indoor localization. This article focuses on recent advances in indoor localization methods that use spatial context to improve the location estimation. Spatial context in the form of maps and spatial models have been used to improve the localization by constraining location estimates in the navigable parts of indoor environments. Landmarks such as doors and corners, which are also one form of spatial context, have proved useful in assisting indoor localization by correcting the localization error. This survey gives a comprehensive review of state-of-the-art indoor localization methods and localization improvement methods using maps, spatial models, and landmarks. © 2019 Association for Computing Machinery.",Hybrid localization; Indoor positioning; Landmark detection; Sensory landmarks; Smartphones; Spatial information; Wireless localization,Abstract,Abstract,
Web of Science,conferencePaper,2017,HoloPair: Securing Shared Augmented Reality Using Microsoft HoloLens,ACSAC - Annual Computer Security Applications Conference,A,"Augmented Reality (AR) devices continuously scan their environment in order to naturally overlay virtual objects onto user's view of the physical world. In contrast to Virtual Reality, where one's environment is fully replaced with a virtual one, one of AR's killer features is co-located collaboration, in which multiple users interact with the same combination of virtual and real objects. Microsoft recently released HoloLens, the first consumer-ready augmented reality headset that needs no outside markers to achieve precise inside-out spatial mapping, which allows centimeter-scale hologram positioning. However, despite many applications published on the Windows Mixed Reality platform that rely on direct communication between AR devices, there currently exists no implementation or achievable proposal for secure direct pairing of two unassociated headsets. As augmented reality gets into mainstream, this omission exposes current and future users to a range of avoidable attacks. In order to close this real-world gap in both theory and engineering practice, in this paper we design and evaluate HoloPair, a system for secure and usable pairing of two AR headsets. We propose a pairing protocol and build a working prototype to experimentally evaluate its security guarantees, usability, and system performance. By running a user study with a total of 22 participants, we show that the system achieves high rates of attack detection, short pairing times, and a high average usability score. Moreover, in order to make an immediate impact on the wider developer community, we have published the full implementation and source code of our prototype, which is currently under consideration to be included in the official HoloLens development toolkit.",,Title_Abstract,Abstract,
Web of Science,conferencePaper,2019,A First Look into Privacy Leakage in 3D Mixed Reality Data,ESORICS - European Symposium on Research in Computer Security,A,"We have seen a rise in mixed (MR) and augmented reality (AR) applications and devices in recent years. Subsequently, we have become familiar with the sensing power of these applications and devices, and we are only starting to realize the nascent risks that these technology puts over our privacy and security. Current privacy protection measures are primarily aimed towards known and well-utilised data types (i.e. location, on-line activity, biometric, and so on) while a few works have focused on looking into the security and privacy risks of and providing protection on MR data, particularly on 3D MR data. In this work, we primarily reveal the privacy leakage from released 3D MR data and how the leakage persist even after implementing spatial generalizations and abstractions. Firstly, we formalize the spatial privacy problem in 3D mixed reality data as well as the adversary model. Then, we demonstrate through an inference model how adversaries can identify 3D spaces and, potentially, infer more spatial information. Moreover, we also demonstrate how compact 3D MR Data can be in terms of memory usage which allows adversaries to create lightweight 3D inference models of user spaces.",Mixed and augmented reality; 3D data; Point cloud data; Security and privacy,Title_Abstract_Keywords,Title_Abstract_Keywords,
Web of Science,conferencePaper,2015,Visual Cryptography and Obfuscation: A Use-Case for Decrypting and Deobfuscating Information Using Augmented Reality,FC - Financial Cryptography and Data Security,A,"As new technologies emerge such as wearables, it opens up for new challenges, especially related to security and privacy. One such recent technology is smart glasses. The use of glasses introduces security and privacy concerns for the general public but also for the user itself. In this paper we present work which focus on privacy of the user during authentication. We propose and analyze two methods, visual cryptography and obfuscation for protecting the user against HUD and camera logging adversaries as well as shoulder-surfing.",Visual cryptography; Visual obfuscation; Augmented reality; Wearables,Title_Keywords,Abstract,
Web of Science,conferencePaper,2015,Design and Analysis of Shoulder Surfing Resistant PIN Based Authentication Mechanisms on Google Glass,FC - Financial Cryptography and Data Security,A,"This paper explores options to the built-in authentication mechanism of the Google Glass which is vulnerable to shoulder surfing attacks. Two simple PIN-based authentication techniques are presented, both of which provide protection against shoulder surfing. The techniques employ two interfaces for entering the PIN, namely, voice (Voice-based PIN) and touchpad (Touch-based PIN). To enter the same PIN, user has the freedom to choose either technique and thereby interface, as per the environment in which authentication is being performed. A user study was conducted with 30 participants to compare the performance of the proposed methods with the built-in technique. The results show that the proposed mechanisms have a significantly better login success rate than the built-in technique. Interestingly, although the average authentication times of the proposed methods are higher than that of the built-in one, the users perceived them as being faster. The results also indicate that the proposed methods have better perceived security and usability than the built-in method. The study reveals that when it comes to authentication on augmented reality devices, there is a need for authentication mechanisms that complement each other as users tend to prefer a different interface in different contexts.",Google Glass; PIN; Authentication; Security; Usability,Abstract,Abstract_Keywords,
Web of Science,journalPaper,2019,GaitLock: Protect Virtual and Augmented Reality Headsets Using Gait,TODSC -Transactions on Dependable and Secure Computing,A,"With the fast penetration of commercial Virtual Reality (VR) and Augmented Reality (AR) systems into our daily life, the security issues of those devices have attracted significant interests from both academia and industry. Modern VR/AR systems typically use head-mounted devices (i.e., headsets) to interact with users, and often store private user data, e.g., social network accounts, online transactions or even payment information. This poses significant security threats, since in practice the headset can be potentially obtained and accessed by unauthenticated parties, e.g., identity thieves, and thus cause catastrophic breach. In this paper, we propose a novel GaitLock system, which can reliably authenticate users using their gait signatures. Our system doesn't require extra hardware, e.g., fingerprint sensors or retina scanners, but only uses the on-board inertial measurement units (IMUs) equipped in almost all mainstream VR/AR headsets to authenticate the legitimate users from intruders, by simply asking them to walk a few steps. To achieve that, we propose a new gait recognition model Dynamic-SRC, which combines the strength of Dynamic Time Warping (DTW) and Sparse Representation Classifier (SRC), to extract unique gait patterns from the inertial signals during walking. We implement GaitLock on Google Glass (a typical AR headset), and extensive experiments show that GaitLock outperforms the state-of-the-art systems significantly in recognition accuracy (> 98 percent success in 5 steps), and is able to run in-situ on the resource-constrained VR/AR headsets without incurring high energy cost.",Gait recognition; VR/AR; sparse representation classification; dynamic time warping,Title_Abstract,Abstract,
Web of Science,journalPaper,2021,Immersive Virtual Reality Attacks and the Human Joystick,TODSC -Transactions on Dependable and Secure Computing,A,"This is one of the first accounts for the security analysis of consumer immersive Virtual Reality (VR) systems. This work breaks new ground, coins new terms, and constructs proof of concept implementations of attacks related to immersive VR. Our work used the two most widely adopted immersive VR systems, the HTC Vive, and the Oculus Rift. More specifically, we were able to create attacks that can potentially disorient users, turn their Head Mounted Display (HMD) camera on without their knowledge, overlay images in their field of vision, and modify VR environmental factors that force them into hitting physical objects and walls. Finally, we illustrate through a human participant deception study the success of being able to exploit VR systems to control immersed users and move them to a location in physical space without their knowledge. We term this the Human Joystick Attack. We conclude our work with future research directions and ways to enhance the security of these systems.",Security; Virtual reality; Software; Tracking; Cameras; Testing; Resists; Computer security; human computer interaction; privacy-invasive software; virtual reality,Title_Abstract_Keywords,Abstract_Keywords,
Web of Science,journalPaper,2022,Modeling and Defense of Social Virtual Reality Attacks Inducing Cybersickness,TODSC -Transactions on Dependable and Secure Computing,A,"Social Virtual Reality Learning Environments (VRLE) offer a new medium for flexible and immersive learning environments with geo-distributed users. Ensuring user safety in VRLE application domains such as education, flight simulations, military training is of utmost importance. Specifically, there is a need to study the impact of immersion attacks (e.g., chaperone attack, occlusion) and other types of attacks/faults (e.g., unauthorized access, network congestion) that may cause user safety issues (i.e., inducing of cybersickness). In this article, we present a novel framework to quantify the security, privacy issues triggered via immersion attacks and other types of attacks/faults. By using a real-world social VRLE viz., vSocial and creating a novel attack-fault tree model, we show that such attacks can induce undesirable levels of cybersickness. Next, we convert these attack-fault trees into stochastic timed automata (STA) representations to perform statistical model checking for a given attacker profile. Using this model checking approach, we determine the most vulnerable threat scenarios that can trigger high occurrence cases of cybersickness for VRLE users. Lastly, we show the effectiveness of our attack-fault tree modeling by incorporating suitable design principles such as hardening, diversity, redundancy and principle of least privilege to ensure user safety in a VRLE session.",Cybersickness; Security; Privacy; Safety; Solid modeling; Servers; Virtual environments; Security and privacy; user safety; cybersickness; virtual reality learning environments; attack-fault trees; statistical model checking; risk assessment; design principles,Title_Abstract_Keywords,Abstract_Keywords,
Web of Science,journalPaper,2021,Designing Leakage-Resilient Password Entry on Head-Mounted Smart Wearable Glass Devices,TOIFS - Transactions on Information Forensics and Security,A,"With the boom of Augmented Reality (AR) and Virtual Reality (VR) applications, head-mounted smart wearable glass devices are becoming popular to help users access various services like E-mail freely. However, most existing password entry schemes on smart glasses rely on additional computers or mobile devices connected to smart glasses, which require users to switch between different systems and devices. This may greatly lower the practicability and usability of smart glasses. In this paper, we focus on this challenge and design three practical anti-eavesdropping password entry schemes on stand-alone smart glasses, named gTapper, gRotator and gTalker. The main idea is to break the correlation between the underlying password and the interaction observable to adversaries. In our IRB-approved user study, these schemes are found to be easy-to-use without additional hardware under various test conditions, where the participants can enter their passwords within moderate time, at high accuracy, and in various situations.",Password; Smart glasses; Eavesdropping; Usability; Glass; Authentication; Password entry; anti-eavesdropping; smart glasses; head-mounted device; usability and security,Abstract,Keywords,
Web of Science,journalPaper,2023,A Secure Authentication Framework to Guarantee the Traceability of Avatars in Metaverse,TOIFS - Transactions on Information Forensics and Security,A,"Metaverse is a vast virtual environment parallel to the physical world in which users enjoy a variety of services acting as an avatar. To build a secure living habitat, it's vital to ensure the virtual-physical traceability that tracking a malicious player in the physical world via his avatars in virtual space. In this paper, we propose a two-factor authentication framework based on biometric-based authentication and chameleon signature. First, aiming at disguise in virtual space, we design an avatar's two-factor identity model to ensure the verifiability of avatar's virtual identity and physical identity. Second, facing at authentication efficiency and keys holding cost, we propose a chameleon collision signature algorithm to efficiently ensure that the avatar's virtual identity is associated with its physical identity. Finally, aiming at impersonation in the physical world, we design two decentralized authentication protocols based on the avatar's identity model and the chameleon collision signature to achieve real-time authentication on the avatar's identity. Security analysis indicates that the proposed authentication framework guarantees the consistency and traceability of the avatar's identity. Simulation experiments show that the framework not only completes the decentralized authentication between avatars but also achieves virtual-physical tracking.",Metaverse; avatar; authentication; traceability,Title_Abstract_Keywords,Abstract,
Web of Science,journalPaper,2022,Hidden in Plain Sight: Exploring Privacy Risks of Mobile Augmented Reality Applications,TOPS - Transactions on Privacy and Security,A,"Mobile augmented reality systems are becoming increasingly common and powerful, with applications in such domains as healthcare, manufacturing, education, and more. This rise in popularity is thanks in part to the functionalities offered by commercially available vision libraries such as ARCore, Vuforia, and Google's ML Kit; however, these libraries also give rise to the possibility of a hidden operations threat, that is, the ability of a malicious or incompetent application developer to conduct additional vision operations behind the scenes of an otherwise honest AR application without alerting the end-user. In this article, we present the privacy risks associated with the hidden operations threat and propose a framework for application development and runtime permissions targeted specifically at preventing the execution of hidden operations. We follow this with a set of experimental results, exploring the feasibility and utility of our system in differentiating between user-expectation-compliant and non-compliant AR applications during runtime testing, for which preliminary results demonstrate accuracy of up to 71%. We conclude with a discussion of open problems in the areas of software testing and privacy standards in mobile AR systems.",Augmented reality; mobile system security; user privacy,Title_Abstract_Keywords,Title_Abstract_Keywords,
ACM DL,conferencePaper,2023,A Tagging Solution to Discover IoT Devices in Apartments,ACSAC - Annual Computer Security Applications Conference,A,"The number of Internet of Things (IoT) devices in smart homes is increasing. This broad adoption facilitates users’ lives, but it also brings problems. One such issue is that some IoT devices may invade users’ privacy through obscure data collection practices or hidden devices. Specific IoT devices can exist out of sight and still collect user data to send to third parties via the Internet. Owners can easily forget the location or even the existence of these devices, especially if the owner is a landlord managing several properties. The landlord-owner scenario creates multi-user problems as designers typically build IoT devices for single users. We developed tag models that use wireless protocols, buzzers, and LED lighting to guide users toward the hidden device in shared spaces and accommodate multi-user scenarios. They are attached to IoT devices inside a residential unit during their installation to be later discovered by a tenant. These tags are similar to Tile models or Airtag but have different features based on our privacy use case. For instance, our tags do not require pairing; multiple users can interact with them through our Android application. Our tags can also embed the IoT device’s information while protecting against unwanted access to that information through a proximity requirement. Researchers have developed several other tools, such as thermal cameras or virtual reality (VR), for discovering devices, but we focused on wireless technologies. We measured specific performance metrics of our tags to analyze their feasibility for this problem. We also conducted a user study to measure the participants’ comfort levels while finding objects with our tags attached. Our results indicate that wireless tags can be viable for device tracking in residential properties.",IoT; Privacy; Smart Homes; Wireless,Abstract,Abstract_Keywords,
Scopus,conferencePaper,2023,Understanding Person Identification Through Gait,PETS - International Symposium on Privacy Enhancing Technologies,A,"Gait recognition is the process of identifying humans from their bipedal locomotion such as walking or running. As such, gait data is privacy sensitive information and should be anonymized where possible. With the rise of higher quality gait recording techniques, such as depth cameras or motion capture suits, an increasing amount of detailed gait data is captured and processed. The introduction and rise of the Metaverse is an example of a potentially popular application scenario in which the gait of users is transferred onto digital avatars. As a first step towards developing effective anonymization techniques for high-quality gait data, we study different aspects of movement data to quantify their contribution to gait recognition. We first extract categories of features from the literature on human gait perception and then design experiments for each category to assess how much the information they contain contributes to recognition success. We evaluated the utility of gait perturbation by means of naturalness ratings in a user study. Our results show that gait anonymization will be challenging, as the data is highly redundant and inter-dependent.",,Abstract,Abstract,
Scopus,conferencePaper,2023,Exploring the Privacy Risks of Adversarial VR Game Design,PETS - International Symposium on Privacy Enhancing Technologies,A,"Fifty study participants playtested an innocent-looking “escape room” game in virtual reality (VR). Within just a few minutes, an adversarial program had accurately inferred over 25 of their personal data attributes, from anthropometrics like height and wingspan to demographics like age and gender. As notoriously data-hungry companies become increasingly involved in VR development, this experimental scenario may soon represent a typical VR user experience. Since the Cambridge Analytica scandal of 2018, adversarially-designed gamified elements have been known to constitute a significant privacy threat in conventional social platforms. In this work, we present a case study of how metaverse environments can similarly be adversarially constructed to covertly infer dozens of personal data attributes from seemingly-anonymous users. While existing VR privacy research largely focuses on passive observation, we argue that because individuals subconsciously reveal personal information via their motion in response to specific stimuli, active attacks pose an outsized risk in VR environments.",,Abstract,Title_Abstract,
Scopus,conferencePaper,2023,Speculative Privacy Concerns About AR Glasses Data Collection,PETS - International Symposium on Privacy Enhancing Technologies,A,"As technology companies develop mass market augmented reality (AR) glasses that are increasingly sensor-laden and affordable, uses of such devices pose potential privacy and security problems. Though prior work has broadly addressed some of these problems, our work specifically addresses the potential data collection of 15 data types by AR glasses and five potential data uses. Via semi-structured interviews, we explored the attitudes and concerns of 21 current AR technology users regarding potential data collection and data use by hypothetical consumer-grade AR glasses. Participants expressed diverse concerns and suggested potential limits to AR data collection and use, evoking privacy concepts and informational norms. We discuss how participants’ attitudes and reservations about data collection and use, like definitions of privacy, are varying and context-dependent, and make recommendations for designers and policy makers, including customizable and multidimensional privacy solutions.",,Abstract,Title_Abstract,
Scopus,journalPaper,2023,Visual Indicators Representing Avatars' Authenticity in Social Virtual Reality and Their Impacts on Perceived Trustworthiness,TVCG - Transactions on Visualization and Computer Graphics,A,"Photorealistic avatars show great potential in social VR and VR collaboration. However, identity and privacy issues are threatening avatars' authenticity in social VR. In addition to the necessary authentication and protection, effective solutions are needed to convey avatars' authenticity status to users and thereby enhance the overall trustworthiness. We designed several visual indicators (VIs) using static or dynamic visual effects on photorealistic avatars and evaluated their effectiveness in visualizing avatars' authenticity status. In this study we explored suitable attributes and designs for conveying the authenticity of photorealistic avatars and influencing their perceived trustworthiness. Furthermore, we investigated how different interactivity levels influence their effectiveness (the avatar was either presented in a static image, an animated video clip, or an immersive virtual environment). Our findings showed that using a full name can increase trust, while most other VIs could decrease users' trust. We also found that interactivity levels significantly impacted users' trust and the effectiveness of VIs. Based on our results, we developed design guidelines for visual indicators as effective tools to convey authenticity, as a first step towards the improvement of trustworthiness in social VR with identity management.  © 2023 IEEE.",authenticity; avatar; design guidelines; identity management; social VR; trust; visual indicator,Title,Abstract,
Scopus,journalPaper,2023,MagLoc-AR: Magnetic-Based Localization for Visual-Free Augmented Reality in Large-Scale Indoor Environments,TVCG - Transactions on Visualization and Computer Graphics,A,"Accurate localization of a display device is essential for AR in large-scale environments. Visual-based localization is the most commonly used solution, but poses privacy risks, suffers from robustness issues and consumes high power. Wireless signal-based localization is a potential visual-free solution, but its accuracy is not enough for AR. In this paper, we present MagLoc-AR, a novel visual-free localization solution that achieves sufficient accuracy for some AR applications (e.g. AR navigation) in large-scale indoor environments. We exploit the location-dependent magnetic field interference that is ubiquitous indoors as a localization signal. Our method requires only a consumer-grade 9-axis IMU, with the gyroscope and acceleration measurements used to recover the motion trajectory, and the magnetic measurements used to register the trajectory to the global map. To meet the accuracy requirement of AR, we propose a mapping method to reconstruct a globally consistent magnetic field of the environment, and a localization method fusing the biased magnetic measurements with the network-predicted motion to improve localization accuracy. In addition, we provide the first dataset for both visual-based and geomagnetic-based localization in large-scale indoor environments. Evaluations on the dataset demonstrate that our proposed method is sufficiently accurate for AR navigation and has advantages over the visual-based methods in terms of power consumption and robustness. Project page: https://github.com/zju3dv/MagLoc-AR/  © 2023 IEEE.",Augmented reality; Indoor localization; Inertial navigation system,Title_Keywords,Abstract,
Scopus,journalPaper,2021,A privacy-preserving approach to streaming eye-tracking data,TVCG - Transactions on Visualization and Computer Graphics,A,"Eye-tracking technology is being increasingly integrated into mixed reality devices. Although critical applications are being enabled, there are significant possibilities for violating user privacy expectations. We show that there is an appreciable risk of unique user identification even under natural viewing conditions in virtual reality. This identification would allow an app to connect a user's personal ID with their work ID without needing their consent, for example. To mitigate such risks we propose a framework that incorporates gatekeeping via the design of the application programming interface and via software-implemented privacy mechanisms. Our results indicate that these mechanisms can reduce the rate of identification from as much as 85% to as low as 30%. The impact of introducing these mechanisms is less than 1.5° error in gaze position for gaze prediction. Gaze data streams can thus be made private while still allowing for gaze prediction, for example, during foveated rendering. Our approach is the first to support privacy-by-design in the flow of eye-tracking data within mixed reality use cases.",Gaze tracking; Mixed reality; Privacy; Rendering (computer graphics); Streaming media; Tracking; Training,Abstract_Keywords,Title_Abstract_Keywords,
Scopus,journalPaper,2020,The Security-Utility Trade-off for Iris Authentication and Eye Animation for Social Virtual Avatars,TVCG - Transactions on Visualization and Computer Graphics,A,"The gaze behavior of virtual avatars is critical to social presence and perceived eye contact during social interactions in Virtual Reality. Virtual Reality headsets are being designed with integrated eye tracking to enable compelling virtual social interactions. This paper shows that the near infra-red cameras used in eye tracking capture eye images that contain iris patterns of the user. Because iris patterns are a gold standard biometric, the current technology places the user's biometric identity at risk. Our first contribution is an optical defocus based hardware solution to remove the iris biometric from the stream of eye tracking images. We characterize the performance of this solution with different internal parameters. Our second contribution is a psychophysical experiment with a same-different task that investigates the sensitivity of users to a virtual avatar's eye movements when this solution is applied. By deriving detection threshold values, our findings provide a range of defocus parameters where the change in eye movements would go unnoticed in a conversational setting. Our third contribution is a perceptual study to determine the impact of defocus parameters on the perceived eye contact, attentiveness, naturalness, and truthfulness of the avatar. Thus, if a user wishes to protect their iris biometric, our approach provides a solution that balances biometric protection while preventing their conversation partner from perceiving a difference in the user's virtual avatar. This work is the first to develop secure eye tracking configurations for VR/AR/XR applications and motivates future work in the area. © 2020 IEEE.",Animated Avatars; Eye Movements; Eye Tracking; Iris Recognition; Security,Abstract,Title_Keywords,
Scopus,journalPaper,2016,Efficient verification of holograms using mobile augmented reality,TVCG - Transactions on Visualization and Computer Graphics,A,"Paper documents such as passports, visas and banknotes are frequently checked by inspection of security elements. In particular, optically variable devices such as holograms are important, but difficult to inspect. Augmented Reality can provide all relevant information on standard mobile devices. However, hologram verification on mobiles still takes long and provides lower accuracy than inspection by human individuals using appropriate reference information. We aim to address these drawbacks by automatic matching combined with a special parametrization of an efficient goal-oriented user interface which supports constrained navigation. We first evaluate a series of similarity measures for matching hologram patches to provide a sound basis for automatic decisions. Then a re-parametrized user interface is proposed based on observations of typical user behavior during document capture. These measures help to reduce capture time to approximately 15 s with better decisions regarding the evaluated samples than what can be achieved by untrained users. © 1995-2012 IEEE.",augmented reality; Document inspection; holograms; mobile devices; user interfaces,Title_Abstract_Keywords,Abstract,
Scopus,conferencePaper,2023,Securing Data Exchange in the Convergence of Metaverse and IoT Applications,"ARES - International Conference on Availability, Reliability and Security",B,"The convergence of Metaverse and Internet of Things (IoT) presents new opportunities for exchanging data, but it also introduces unprecedented security challenges. With the proliferation of IoT devices, the risk of unauthorized access and data breaches is on the rise, posing significant threats to data confidentiality and integrity. To address these challenges and protect user privacy, comprehensive security solutions are essential. We propose the SafeMetaNet approach, which combines proximity-based authentication, encryption, and blockchain technology to establish secure data exchange in the IoT-Metaverse convergence. SafeMetaNet ensures data confidentiality and integrity through encryption and establishes a tamper-proof record of data exchange using blockchain technology. We evaluated the approach's performance using various metrics, including latency, throughput, and two security metrics: data confidentiality and data integrity, and compared it with existing approaches. Our findings show that SafeMetaNet outperforms existing approaches, providing improved security. SafeMetaNet is a promising solution for secure data exchange in the IoT-Metaverse convergence. © 2023 ACM.",Blockchain; Data Exchange; Internet of Things; Metaverse; Security,Title_Abstract_Keywords,Abstract_Keywords,
Scopus,conferencePaper,2022,SoK: A Systematic Literature Review of Knowledge-Based Authentication on Augmented Reality Head-Mounted Displays,"ARES - International Conference on Availability, Reliability and Security",B,"The adoption of Augmented Reality (AR) technology has increased over the years. AR enhances various activities for consumers and businesses, particularly in industrial contexts. The three-dimensional virtual experience is realized by the usage of Head-Mounted Displays (HMD). These devices provide access to sensitive data and services. Thus, secure and usable authentication schemes are essential to control access to the HMD and the stored data as well as schemes to authenticate to the services one wants to use with the AR device. We conducted a systematic literature review on knowledge-based authentication schemes for AR HMD. 31 different schemes were identified. These schemes were assessed regarding various aspects including the type of AR HMD, the type of secret, how users input their secret, as well as usability and security aspects. We discuss gaps for future work.  © 2022 Owner/Author.",Augmented Reality; Authentication; Head-Mounted Display; Literature Review; Password Entry,Title_Abstract_Keywords,Abstract,
Scopus,conferencePaper,2015,Ethics emerging: The story of privacy and security perceptions in virtual reality,SOUPS - Symposium On Usable Privacy and Security,B,"Virtual reality (VR) technology aims to transport the user to a virtual world, fully immersing them in an experience entirely separate from the real world. VR devices can use sensor data to draw deeply personal inferences (e.g., medical conditions, emotions) and can enable virtual crimes (e.g., theft, assault on virtual representations of the user) from which users have been shown to experience real, significant emotional pain. As such, VR may involve especially sensitive user data and interactions. To effectively mitigate such risks and design for safer experiences, we aim to understand end-user perceptions of VR risks and how, if at all, developers are considering and addressing those risks. In this paper, we present the first work on VR security and privacy perceptions: a mixed-methods study involving semi-structured interviews with 20 VR users and developers, a survey of VR privacy policies, and an ethics co-design study with VR developers. We establish a foundational understanding of perceived risks in VR; raise concerns about the state of VR privacy policies; and contribute a concrete VR developer “code of ethics”, created by developers, for developers. © 2018 by The USENIX Association All Rights Reserved.",,Title_Abstract,Title_Abstract,
Scopus,conferencePaper,2015,Evaluating and redefining smartphone permissions with contextualized justifications for mobile augmented reality apps,SOUPS - Symposium On Usable Privacy and Security,B,"Augmented reality (AR), and specifically mobile augmented reality (MAR) gained much public attention after the success of Pokémon Go in 2016, and since then has found application in online games, social media, entertainment, real estate, interior design, and other services. MAR apps are highly dependent on real time context-specific information provided by the different sensors and data processing capabilities of smartphones (e.g., LiDAR, gyroscope or object recognition). This dependency raises crucial privacy issues for end users. We evaluate whether the existing access permission systems, initially developed for non-AR apps, as well as proposed new permissions, relevant for MAR apps, provide sufficient and clear information to the users. We address this research goal in two online survey-based experiments with a total of 581 participants. Based on our results, we argue that it is necessary to increase transparency about MAR apps' data practices by requesting users' permissions to access certain novel and privacy invasive resources and functionalities commonly used in MAR apps, such as speech and face recognition. We also find that adding justifications, contextualized to the data collection practices of the app, improves transparency and can mitigate privacy concerns, at least in the context of data utilized to the users' benefit. Better understanding of the app's practices and lower concerns, in turn, increase the intentions to grant permissions. We provide recommendations for better transparency in MAR apps. © is held by the author/owner. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee. USENIX Symposium on Usable Privacy and Security (SOUPS) 2021.",,Title_Abstract,Abstract,
Scopus,conferencePaper,2018,Ethics emerging: The story of privacy and security perceptions in virtual reality,SOUPS - Symposium On Usable Privacy and Security,B,"Virtual reality (VR) technology aims to transport the user to a virtual world, fully immersing them in an experience entirely separate from the real world. VR devices can use sensor data to draw deeply personal inferences (e.g., medical conditions, emotions) and can enable virtual crimes (e.g., theft, assault on virtual representations of the user) from which users have been shown to experience real, significant emotional pain. As such, VR may involve especially sensitive user data and interactions. To effectively mitigate such risks and design for safer experiences, we aim to understand end-user perceptions of VR risks and how, if at all, developers are considering and addressing those risks. In this paper, we present the first work on VR security and privacy perceptions: a mixed-methods study involving semi-structured interviews with 20 VR users and developers, a survey of VR privacy policies, and an ethics co-design study with VR developers. We establish a foundational understanding of perceived risks in VR; raise concerns about the state of VR privacy policies; and contribute a concrete VR developer “code of ethics”, created by developers, for developers. © 2018 by The USENIX Association All Rights Reserved.",,Title_Abstract,Title_Abstract,Duplicate
Scopus,conferencePaper,2021,Evaluating and redefining smartphone permissions with contextualized justifications for mobile augmented reality apps,SOUPS - Symposium On Usable Privacy and Security,B,"Augmented reality (AR), and specifically mobile augmented reality (MAR) gained much public attention after the success of Pokémon Go in 2016, and since then has found application in online games, social media, entertainment, real estate, interior design, and other services. MAR apps are highly dependent on real time context-specific information provided by the different sensors and data processing capabilities of smartphones (e.g., LiDAR, gyroscope or object recognition). This dependency raises crucial privacy issues for end users. We evaluate whether the existing access permission systems, initially developed for non-AR apps, as well as proposed new permissions, relevant for MAR apps, provide sufficient and clear information to the users. We address this research goal in two online survey-based experiments with a total of 581 participants. Based on our results, we argue that it is necessary to increase transparency about MAR apps' data practices by requesting users' permissions to access certain novel and privacy invasive resources and functionalities commonly used in MAR apps, such as speech and face recognition. We also find that adding justifications, contextualized to the data collection practices of the app, improves transparency and can mitigate privacy concerns, at least in the context of data utilized to the users' benefit. Better understanding of the app's practices and lower concerns, in turn, increase the intentions to grant permissions. We provide recommendations for better transparency in MAR apps. © is held by the author/owner. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee. USENIX Symposium on Usable Privacy and Security (SOUPS) 2021.",,Title_Abstract,Abstract,Duplicate
Web of Science,conferencePaper,2023,Investigating Security Indicators for Hyperlinking Within the Metaverse,SOUPS - Symposium On Usable Privacy and Security,B,"Security indicators, such as the padlock icon indicating SSL encryption in browsers, are established mechanisms to convey secure connections. Currently, such indicators mainly exist for browsers and mobile environments. With the rise of the metaverse, we investigate how to mark secure transitions between applications in virtual reality to so-called sub-metaverses. For this, we first conducted in-depth interviews with domain experts (N=8) to understand the general design dimensions for security indicators in virtual reality (VR). Using these insights and considering additional design constraints, we implemented the five most promising indicators and evaluated them in a user study (N=25). While the visual blinking indicator placed in the periphery performed best regarding accuracy and task completion time, participants subjectively preferred the static visual indicator above the portal. Moreover, the latter received high scores regarding understandability while still being rated low regarding intrusiveness and disturbance. Our findings contribute to a more secure and enjoyable metaverse experience.",,Title_Abstract,Title_Abstract,
Web of Science,conferencePaper,2023,"An Investigation of Teenager Experiences in Social Virtual Reality from Teenagers', Parents', and Bystanders' Perspectives",SOUPS - Symposium On Usable Privacy and Security,B,"The recent rise of social virtual reality (VR) platforms has introduced new technology characteristics and user experiences, which may lead to new forms of online harassment, particularly among teenagers (aged 13-17). In this paper, we took a multi-stakeholder approach and investigate teenagers' experiences and safety threats in social VR from three perspectives (teenagers, parents, and bystanders) to cover complementary perspectives. Through an interview study with 24 participants (8 teenagers, 7 parents, and 9 bystanders), we found several safety threats that teenagers may face, such as virtual grooming, ability-based discrimination, unforeseeable threats in privacy rooms, etc. We highlight new forms of harassment in the social VR context, such as erotic role-play and abuse through phantom sense, as well as the discrepancies among teenagers, parents, and bystanders regarding their perceptions of such threats. We draw design implications to better support safer social VR environments for teenagers.",,Title_Abstract,Abstract,
Scopus,conferencePaper,2021,Spectrum-flexible secure broadcast ranging,WiSec - Security and Privacy in Wireless and Mobile Networks,B,"Secure ranging is poised to play a critical role in several emerging applications such as self-driving cars, unmanned aerial systems, wireless IoT devices, and augmented reality. In this paper, we propose a design of a secure broadcast ranging system with unique features and techniques. Its spectral-flexibility, and low-power short ranging bursts enable co-existence with existing systems such as in the 2.4GHz ISM band. We exploit a set of RF techniques such as upsampling and successive interference cancellation to achieve high accuracy and scalability to tens of reflectors even when operating over narrow bands of spectrum. We demonstrate that it can be implemented on popular SDR platforms FPGA and/or hosts (with minimal FPGA modifications). The protocol design, and cryptographically generated/detected signals, and randomized timing of transmissions, provide stealth and security against denial of service, sniffing, and distance manipulation attacks. Through extensive experimental evaluations (and simulations for scalability to over 100 reflectors) we demonstrate an accuracy below 20cm on a wide range of SNR (as low as 0dB), spectrum 25MHz-100MHz, with bursts as short as 5us. © 2021 ACM.",privacy; protocols; software defined radio; wireless ranging,Abstract,Abstract_Keywords,
IEEE,conferencePaper,2017,Visualizing the New Zealand Cyber Security Challenge for Attack Behaviors,"TrustCom - International Conference on Trust, Security and Privacy in Computing and Communications",B,"Datasets are important for security analytics and mitigation processes in cyber security research and investigations. ""Cyber security challenge (CSC)"" events provide the means to collect datasets. The New Zealand National cyber security challenge event is designed to promote cyber security education, awareness and equally as important, collect datasets for research purposes. In this paper, we present the: (1) Importance of cyber security challenge events, (2) Highlight the importance of collecting datasets, and (3) present a user-centric security visualization model of attack behaviors. User-centric features with the theoretical concept of Data Provenance as a Security Visualization Service (DPaaSVS) reused to display attacks commencing at the reconnaissance stage through to compromising a defending team machine and exploiting the systems. DPaaSVS creates the ability for users to interact and observe correlations between cyber-attacks. Finally we provide future work on Security Visualization with Augmented Reality capabilities to enhance and improve user interactions with the security visualization platform.",Security Visualization;Cyber-attacks;Usercentricity;Data Provenance;Datasets,Abstract,Title_Abstract_Keywords,
Web of Science,journalPaper,2023,Virtually secure: A taxonomic assessment of cybersecurity challenges in virtual reality environments,CS - Computers and Security,B,"Although Virtual Reality (VR) is certainly not a new technology, its recent adoption across several sectors beyond entertainment has led the information security research community to take note of the new cy-ber threats that come with it. The variety of system components presents an extensive attack surface that can be exploited. At the same time, VR's emphasis on immersion, interaction and presence means that the user can be targeted directly, yet the use of head-mounted displays may prevent them from observing a cyber attack's impact in their immediate physical environment. This paper presents the first taxonomic representation of VR security challenges. By systemically classifying existing VR cyber threats against ex-isting defences in a single comparative matrix, we aim to help researchers from different backgrounds to identify key focus areas where further research would be most beneficial.(c) 2022 Elsevier Ltd. All rights reserved.",Virtual Reality; Cyber-physical attacks; Cybersecurity; Privacy; Taxonomy,Title_Abstract_Keywords,Title_Abstract_Keywords,
Web of Science,journalPaper,2023,A systematic threat analysis and defense strategies for the metaverse and extended reality systems,CS - Computers and Security,B,"With the rapid development and evolution of immersive technologies there are growing concerns of security and privacy threats to the metaverse and extended reality (XR) systems. Immersive reality solutions are a combination of multiple vulnerable technologies allowing attackers to easily undermine security. Furthermore the deployment of appropriate security controls and defensive mechanisms for resource constrained proprietary XR products has been limited. In this paper, we provide a comprehensive overview of extended reality systems and the metaverse with emphasis on technology weaknesses, cyber security challenges and users' safety concerns. Five major taxonomies have been presented in this research with an aim of identifying privacy inference vectors and potential cyber threats; determining the impact on human health and the extent to which cyberstalking, and digital currency scam activities proliferate when using XR. This research also proposes strategies for primary lines of defense and provides recommendations on the adoption of safety measures.",Extended reality (XR); Metaverse; Cyber defense; Privacy; Cyber threats; Cyberstalking; Physical safety; XR commerce; Virtual reality; Augmented reality; Mixed reality; Blockchain; Cybersickness; Currency scams,Title_Abstract_Keywords,Abstract_Keywords,
Web of Science,journalPaper,2023,Rise of the Metaverse?s Immersive Virtual Reality Malware and the Man-in-the-Room Attack & Defenses,CS - Computers and Security,B,"The allure of the metaverse along with Virtual Reality (VR) technologies and speed at which they are deployed may shift focus away from security and privacy fundamentals. In this work we employ classic exploitation techniques against cutting edge devices to obtain equally novel results. The unique features of the Virtual Reality landscape set the stage for our primary account of a new attack, the Man-in-the-Room (MitR). This attack, realized from a vulnerable social networking application led to both worming and botnet capabilities being adapted for VR with potential critical impacts affecting millions of users. Our work improves the state-of-the-art in Virtual Reality (VR) security and socio-technical research in VR. It shares several analytical and attacking tools, example exploits, evaluation dataset, and vulnerability signatures with the scientific and professional communities to ensure secure VR software development. The presented results demonstrate the detection and prevention of VR vulnerabilities, and raise questions in the law and policy domains pertaining to VR security and privacy. Published by Elsevier Ltd.",Emerging technologies; Network-level security and protection; Network communications; Network Protocols; Protection mechanisms; Quality analysis and evaluation; System issues; Security and Privacy Protection; Authentication; Communications Applications; Virtual reality; Security and Protection; Artificial augmented and virtual realities; Invasive software (viruses worms Trojan; horses); Unauthorized access (hacking phreaking),Title_Abstract_Keywords,Abstract_Keywords,
Web of Science,journalPaper,2023,Virtual reality for improving cyber situational awareness in security operations centers,CS - Computers and Security,B,"Security operations centers (SOCs) are the 911 centers of many organizational networks, except they not only respond, but also monitor. SOC operators are charged with detection, response, and mitigation. This is a tall task when one considers the volume, velocity, and variety of both internal and external organizational network and system data. SOC operations are truly a big data problem. Security orchestration, incident event management, data fusion, and anomaly detection systems help, but more is needed. This study examines the impact virtual reality (VR) can have on SOC operator performance and perceived task load. We developed a VR based network monitoring tool and assigned human subjects to one of three conditions - VR only, traditional tool only, or both. Our results, though small in scale, provide very promising indication that VR based technology may be beneficial for improving cyber situational awareness (SA), particularly with overall data perception involving novice SOC operators. The results are promising, but the sample size is small, so future research should validate this pilot study. Given the workforce challenges in the cybersecurity space, and the need to perceive large quantities of data, VR may be a very good addition to SOCs.",Cyber situational awareness; Virtual reality; Security operations centers; Network monitoring,Title_Abstract_Keywords,Title_Abstract_Keywords,
IEEE,journalPaper,2018,Arya: Operating System Support for Securely Augmenting Reality,SPM - Security & Privacy Magazine,B,"Augmented reality (AR) applications capture sensor input from a userâ€™s surroundings and overlay virtual output on their perception of the world, enabling new, immersive experiences. However, this technology raises serious security and privacy risks such as malicious or buggy AR output.",,Abstract,Abstract,
IEEE,conferencePaper,2019,Collaborative Visual Analysis with Multi-level Information Sharing Using a Wall-Size Display and See-Through HMDs,PACIFICVIS - Pacific Visualization Symposium,B,"Solving complex data analysis problems can often benefit a collaborative effort. For synchronous co-located collaboration, a well-recognized challenge is to deliver different contents to people with different privileges and different responsibilities. This challenge is becoming more obvious with the use of a shared display space such as a wall-size display. In particular, scenarios often arise that a privileged participant needs to access sensitive information that other participants are not permitted to view. This is nearly impossible to achieve with only a single display. As a result, it becomes clear that additional devices are needed to provide some of the participants the capability to access and manage certain information in a private space. In this work, we investigate incorporating optical see-through head-mounted displays (OST-HMDs) with a wall-size display to deliver sensitive information in a synchronous co-located, collaborative setting. With our prototype system, we conduct a user study to observe the collaboration styles under this unique setup. We also present the lessons learned by reflecting on the iterative design process of our prototype system.",augmented reality;collaborative visual analysis;head mounted display;privacy;synchronous co located collaboration;wall size display,Keywords,Keywords,
