Database,Item Type,Publication Year,Title,Venue,Venue Rank,Abstract,Keywords,Found In Group1,Found In Group2,Duplicate
IEEE,conferencePaper,2024,Understanding Parentsâ€™ Perceptions and Practices Toward Childrenâ€™s Security and Privacy in Virtual Reality,SP - IEEE Symposium on Security and Privacy,A*,"Recent years have seen a sharp increase in the number of underage users in virtual reality (VR), where security and privacy (S&P) risks such as data surveillance and self-disclosure in social interaction have been increasingly prominent. Prior work shows children largely rely on parents to mitigate S&P risks in their technology use. Therefore, understanding parentsâ€™ S&P knowledge, perceptions, and practices is critical for identifying the gaps for parents, technology designers, and policymakers to enhance childrenâ€™s S&P. While such empirical knowledge is substantial in other consumer technologies, it remains largely unknown in the context of VR. To address the gap, we conducted in-depth semi-structured interviews with 20 parents of children under the age of 18 who use VR at home. Our findings highlight parents generally lack S&P awareness due to the perception that VR is still in its infancy. To protect their childrenâ€™s interactions with VR, parents currently primarily rely on active strategies such as verbal education about S&P. Passive strategies such as using parental controls in VR are not commonly used among our interviewees, mainly due to their perceived technical constraints. Parents also highlight that a multi-stakeholder ecosystem must be established towards more S&P support for children in VR. Based on the findings, we propose actionable S&P recommendations for critical stakeholders, including parents, educators, VR companies, and governments.",Virtual Reality;Security and Privacy;Qualitative studies;Human-centered computing;Technology Use of Parents and Children,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,conferencePaper,2024,Eavesdropping on Controller Acoustic Emanation for Keystroke Inference Attack in Virtual Reality,NDSS - Usenix Network and Distributed System Security Symposium,A*,"Understanding the vulnerability of virtual reality (VR) is crucial for protecting sensitive data and building user trust in VR ecosystems. Previous attacks have demonstrated the feasibility of inferring VR keystrokes inside head-mounted displays (HMDs) by recording side-channel signals generated during user-HMD interactions. However, these attacks are heavily constrained by the physical layout or victim pose in the attack scenario since the recording device must be strictly positioned and oriented in a particular way with respect to the victim. In this paper, we unveil a placement-flexible keystroke inference attack in VR by eavesdropping the clicking sounds of the moving hand controller during keystrokes. The malicious recording smartphone can be placed anywhere surrounding the victim, making the attack more flexible and practical to deploy in VR environments. As the first acoustic attack in VR, our system, Heimdall, overcomes unique challenges unaddressed by previous acoustic attacks on physical keyboards and touchscreens. These challenges include differentiating sounds in a 3D space, adaptive mapping between keystroke sound and key in varying recording placement, and handling occasional hand rotations. Experiments with 30 participants show that Heimdall achieves key inference accuracy of 96.51% and top-5 accuracy of 85.14%–91.22% for inferring passwords with 4–8 characters. Heimdall is also robust under various practical impacts such as smartphone-user placement, attack environments, hardware models, and victim conditions.",,Title_Abstract,Title_Abstract,
Scopus,conferencePaper,2024,That Doesn’t Go There: Attacks on Shared State in Multi-User Augmented Reality Applications,USS - Usenix Security Symposium,A*,"Augmented Reality (AR) can enable shared virtual experiences between multiple users. In order to do so, it is crucial for multi-user AR applications to establish a consensus on the “shared state” of the virtual world and its augmentations through which users interact. Current methods to create and access shared state collect sensor data from devices (e.g., camera images), process them, and integrate them into the shared state. However, this process introduces new vulnerabilities and opportunities for attacks. Maliciously writing false data to “poison” the shared state is a major concern for the security of the downstream victims that depend on it. Another type of vulnerability arises when reading the shared state: by providing false inputs, an attacker can view hologram augmentations at locations they are not allowed to access. In this work, we demonstrate a series of novel attacks on multiple AR frameworks with shared states, focusing on three publicly accessible frameworks. We show that these frameworks, while using different underlying implementations, scopes, and mechanisms to read from and write to the shared state, have shared vulnerability to a unified threat model. Our evaluations of these state-of-the-art AR frameworks demonstrate reliable attacks both on updating and accessing the shared state across different systems. To defend against such threats, we discuss a number of potential mitigation strategies that can help enhance the security of multi-user AR applications and implement an initial prototype.",,Title_Abstract,Title_Abstract,
Scopus,conferencePaper,2024,Penetration Vision through Virtual Reality Headsets: Identifying 360-degree Videos from Head Movements,USS - Usenix Security Symposium,A*,"In this paper, we present the first contactless side-channel attack for identifying 360◦ videos being viewed in a Virtual Reality (VR) Head Mounted Display (HMD). Although the video content is displayed inside the HMD without any external exposure, we observe that user head movements are driven by the video content, which creates a unique side channel that does not exist in traditional 2D videos. By recording the user whose vision is blocked by the HMD via a malicious camera, an attacker can analyze the correlation between the user’s head movements and the victim video to infer the video title. To exploit this new vulnerability, we present INTRUDE, a system for identifying 360◦ videos from recordings of user head movements. INTRUDE is empowered by an HMD-based head movement estimation scheme to extract a head movement trace from the recording and a video saliency-based trace-fingerprint matching framework to infer the video title. Evaluation results show that INTRUDE achieves over 96% of accuracy for video identification and is robust under different recording environments. Moreover, INTRUDE maintains its effectiveness in the open-world identification scenario.",,Title_Abstract,Abstract,
Scopus,conferencePaper,2024,Can Virtual Reality Protect Users from Keystroke Inference Attacks?,USS - Usenix Security Symposium,A*,"Virtual Reality (VR) has gained popularity by providing immersive and interactive experiences without geographical limitations. It also provides a sense of personal privacy through physical separation. In this paper, we show that despite assumptions of enhanced privacy, VR is unable to shield its users from side-channel attacks that steal private information. Ironically, this vulnerability arises from VR’s greatest strength, its immersive and interactive nature. We demonstrate this by designing and implementing a new set of keystroke inference attacks in shared virtual environments, where an attacker (VR user) can recover the content typed by another VR user by observing their avatar. While the avatar displays noisy telemetry of the user’s hand motion, an intelligent attacker can use that data to recognize typed keys and reconstruct typed content, without knowing the keyboard layout or gathering labeled data. We evaluate the proposed attacks using IRB-approved user studies across multiple VR scenarios. For 13 out of 15 tested users, our attacks accurately recognize 86%-98% of typed keys, and the recovered content retains up to 98% of the meaning of the original typed content. We also discuss potential defenses.",,Title_Abstract,Title_Abstract,
Scopus,conferencePaper,2024,When the User Is Inside the User Interface: An Empirical Study of UI Security Properties in Augmented Reality,USS - Usenix Security Symposium,A*,"Augmented reality (AR) experiences place users inside the user interface (UI), where they can see and interact with three-dimensional virtual content. This paper explores UI security for AR platforms, for which we identify three UI security-related properties: Same Space (how does the platform handle virtual content placed at the same coordinates?), Invisibility (how does the platform handle invisible virtual content?), and Synthetic Input (how does the platform handle simulated user input?). We demonstrate the security implications of different instantiations of these properties through five proof-of-concept attacks between distrusting AR application components (i.e., a main app and an included library) — including a clickjacking attack and an object erasure attack. We then empirically investigate these UI security properties on five current AR platforms: ARCore (Google), ARKit (Apple), Hololens (Microsoft), Oculus (Meta), and WebXR (browser). We find that all platforms enable at least three of our proofof-concept attacks to succeed. We discuss potential future defenses, including applying lessons from 2D UI security and identifying new directions for AR UI security.",,Title_Abstract,Title_Abstract,
ACM DL,conferencePaper,2024,Exploring the Design Space of Optical See-through AR Head-Mounted Displays to Support First Responders in the Field,CHI - Human Factors in Computing Systems,A*,"First responders (FRs) navigate hazardous, unfamiliar environments in the field (e.g., mass-casualty incidents), making life-changing decisions in a split second. AR head-mounted displays (HMDs) have shown promise in supporting them due to its capability of recognizing and augmenting the challenging environments in a hands-free manner. However, the design space have not been thoroughly explored by involving various FRs who serve different roles (e.g., firefighters, law enforcement) but collaborate closely in the field. We interviewed 26 first responders in the field who experienced a state-of-the-art optical-see-through AR HMD, as well as its interaction techniques and four types of AR cues (i.e., overview cues, directional cues, highlighting cues, and labeling cues), soliciting their first-hand experiences, design ideas, and concerns. Our study revealed both generic and role-specific preferences and needs for AR hardware, interactions, and feedback, as well as identifying desired AR designs tailored to urgent, risky scenarios (e.g., affordance augmentation to facilitate fast and safe action). While acknowledging the value of AR HMDs, concerns were also raised around trust, privacy, and proper integration with other equipment. Finally, we derived comprehensive and actionable design guidelines to inform future AR systems for in-field FRs.",Augmented Reality; Design; First Responders; In-the-field Tasks,Keywords,Abstract,
ACM DL,conferencePaper,2024,EITPose: Wearable and Practical Electrical Impedance Tomography for Continuous Hand Pose Estimation,CHI - Human Factors in Computing Systems,A*,"Real-time hand pose estimation has a wide range of applications spanning gaming, robotics, and human-computer interaction. In this paper, we introduce EITPose, a wrist-worn, continuous 3D hand pose estimation approach that uses eight electrodes positioned around the forearm to model its interior impedance distribution during pose articulation. Unlike wrist-worn systems relying on cameras, EITPose has a slim profile (12 mm thick sensing strap) and is power-efficient (consuming only 0.3 W of power), making it an excellent candidate for integration into consumer electronic devices. In a user study involving 22 participants, EITPose achieves with a within-session mean per joint positional error of 11.06 mm. Its camera-free design prioritizes user privacy, yet it maintains cross-session and cross-user accuracy levels comparable to camera-based wrist-worn systems, thus making EITPose a promising technology for practical hand pose estimation.",Extended Reality; Input; Electrical Impedance Tomography; Natural User Interfaces; Hand Gesture; Hand Pose; Interaction Technique,Keywords,Abstract,
ACM DL,conferencePaper,2024,Assessing User Apprehensions About Mixed Reality Artifacts and Applications: The Mixed Reality Concerns (MRC) Questionnaire,CHI - Human Factors in Computing Systems,A*,"Current research in Mixed Reality (MR) presents a wide range of novel use cases for blending virtual elements with the real world. This yet-to-be-ubiquitous technology challenges how users currently work and interact with digital content. While offering many potential advantages, MR technologies introduce new security, safety, and privacy challenges. Thus, it is relevant to understand users’ apprehensions towards MR technologies, ranging from security concerns to social acceptance. To address this challenge, we present the Mixed Reality Concerns (MRC) Questionnaire, designed to assess users’ concerns towards MR artifacts and applications systematically. The development followed a structured process considering previous work, expert interviews, iterative refinements, and confirmatory tests to analytically validate the questionnaire. The MRC Questionnaire offers a new method of assessing users’ critical opinions to compare and assess novel MR artifacts and applications regarding security, privacy, social implications, and trust.",Mixed Reality; Privacy; Security; Trust; Safety; Concerns; Social Acceptance; User Apprehensions,Title_Abstract_Keywords,Abstract_Keywords,
ACM DL,conferencePaper,2024,What You Experience is What We Collect: User Experience Based Fine-Grained Permissions for Everyday Augmented Reality,CHI - Human Factors in Computing Systems,A*,"Everyday Augmented Reality (AR) headsets pose significant privacy risks, potentially allowing prolonged sensitive data collection of both users and bystanders (e.g. members of the public). While users control data access through permissions, current AR systems inherit smartphone permission prompts, which may be less appropriate for all-day AR. This constrains informed choices and risks over-privileged access to sensors. We propose (N=20) a novel AR permission control system that allows better-informed privacy decisions and evaluate it using five mock application contexts. Our system’s novelty lies in enabling users to experience the varying impacts of permission levels on not only a) privacy, but also b) application functionality. This empowers users to better understand what data an application depends on and how its functionalities are impacted by limiting said data. Participants found that our method allows for making better informed privacy decisions, and deemed it more transparent and trustworthy than state-of-the-art AR and smartphone permission systems taken from Android and iOS. Our results offer insights into new and necessary AR permission systems, improving user understanding and control over data access.",Augmented Reality; Privacy; AR sensing,Title_Abstract_Keywords,Abstract_Keywords,
ACM DL,conferencePaper,2024,Kinetic Signatures: A Systematic Investigation of Movement-Based User Identification in Virtual Reality,CHI - Human Factors in Computing Systems,A*,"Behavioral Biometrics in Virtual Reality (VR) enable implicit user identification by leveraging the motion data of users’ heads and hands from their interactions in VR. This spatiotemporal data forms a Kinetic Signature, which is a user-dependent behavioral biometric trait. Although kinetic signatures have been widely used in recent research, the factors contributing to their degree of identifiability remain mostly unexplored. Drawing from existing literature, this work systematically examines the influence of static and dynamic components in human motion. We conducted a user study (N&nbsp;=&nbsp;24) with two sessions to reidentify users across different VR sports and exercises after one week. We found that the identifiability of a kinetic signature depends on its inherent static and dynamic factors, with the best combination allowing for 90.91% identification accuracy after one week had passed. Therefore, this work lays a foundation for designing and refining movement-based identification protocols in immersive environments.",virtual reality; usable security; identification; task-driven biometrics; kinetic signatures,Title_Abstract_Keywords,Keywords,
ACM DL,conferencePaper,2024,"Privacy in Immersive Extended Reality: Exploring User Perceptions, Concerns, and Coping Strategies",CHI - Human Factors in Computing Systems,A*,"Extended Reality (XR) technology is changing online interactions, but its granular data collection sensors may be more invasive to user privacy than web, mobile, and the Internet of Things technologies. Despite an increased interest in studying developers’ concerns about XR device privacy, user perceptions have rarely been addressed. We surveyed 464 XR users to assess their awareness, concerns, and coping strategies around XR data in 18 scenarios. Our findings demonstrate that many factors, such as data types and sensitivity, affect users’ perceptions of privacy in XR. However, users’ limited awareness of XR sensors’ granular data collection capabilities, such as involuntary body signals of emotional responses, restricted the range of privacy-protective strategies they used. Our results highlight a need to enhance users’ awareness of data privacy threats in XR, design privacy-choice interfaces tailored to XR environments, and develop transparent XR data practices.",Augmented Reality; Mixed Reality; Virtual Reality; Extended Reality; User privacy; Privacy Perception; Privacy-Seeking Strategies,Title_Abstract_Keywords,Title_Abstract_Keywords,
ACM DL,conferencePaper,2024,An Empirical Study on Oculus Virtual Reality Applications: Security and Privacy Perspectives,ICSE - International Conference on Software Engineering,A*,"Although Virtual Reality (VR) has accelerated its prevalent adoption in emerging metaverse applications, it is not a fundamentally new technology. On one hand, most VR operating systems (OS) are based on off-the-shelf mobile OS (e.g., Android). As a result, VR apps also inherit privacy and security deficiencies from conventional mobile apps. On the other hand, in contrast to conventional mobile apps, VR apps can achieve immersive experience via diverse VR devices, such as head-mounted displays, body sensors, and controllers though achieving this requires the extensive collection of privacy-sensitive human biometrics (e.g., hand-tracking and face-tracking data). Moreover, VR apps have been typically implemented by 3D gaming engines (e.g., Unity), which also contain intrinsic security vulnerabilities. Inappropriate use of these technologies may incur privacy leaks and security vulnerabilities although these issues have not received significant attention compared to the proliferation of diverse VR apps. In this paper, we develop a security and privacy assessment tool, namely the VR-SP detector for VR apps. The VR-SP detector has integrated program static analysis tools and privacy-policy analysis methods. Using the VR-SP detector, we conduct a comprehensive empirical study on 500 popular VR apps. We obtain the original apps from the popular Oculus and SideQuest app stores and extract APK files via the Meta Oculus Quest 2 device. We evaluate security vulnerabilities and privacy data leaks of these VR apps by VR app analysis, taint analysis, and privacy-policy analysis. We find that a number of security vulnerabilities and privacy leaks widely exist in VR apps. Moreover, our results also reveal conflicting representations in the privacy policies of these apps and inconsistencies of the actual data collection with the privacy-policy statements of the apps. Based on these findings, we make suggestions for the future development of VR apps.",metaverse; security and privacy; static analysis; virtual reality,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,journalPaper,2024,Machine Learning in Metaverse Security: Current Solutions and Future Challenges,CSUR - Computing Surveys,A*,"The Metaverse, positioned as the next frontier of the Internet, has the ambition to forge a virtual shared realm characterized by immersion, hyper-spatiotemporal dynamics, and self-sustainability. Recent technological strides in AI, Extended Reality, 6G, and blockchain propel the Metaverse closer to realization, gradually transforming it from science fiction into an imminent reality. Nevertheless, the extensive deployment of the Metaverse faces substantial obstacles, primarily stemming from its potential to infringe on privacy and be susceptible to security breaches, whether inherent in its underlying technologies or arising from the evolving digital landscape. Metaverse security provisioning is poised to confront various foundational challenges owing to its distinctive attributes, encompassing immersive realism, hyper-spatiotemporally, sustainability, and heterogeneity. This article undertakes a comprehensive study of the security and privacy challenges facing the Metaverse, leveraging machine learning models for this purpose. In particular, our focus centers on an innovative distributed Metaverse architecture characterized by interactions across 3D worlds. Subsequently, we conduct a thorough review of the existing cutting-edge measures designed for Metaverse systems while also delving into the discourse surrounding security and privacy threats. As we contemplate the future of Metaverse systems, we outline directions for open research pursuits in this evolving landscape.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",Blockchain; Digital Twin; Extended Reality; Generative AI; Machine Learning; Metaverse Security,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,journalPaper,2024,The First Principles: Setting the Context for a Safe and Secure Metaverse,CSUR - Computing Surveys,A*,"The metaverse delivered through converged and amalgamated technologies holds promise. No wonder technology heavyweights, large corporates, research organizations and businesses cutting across industry verticals are racing to put in place a metaverse-first strategy. The bets on consumers rapidly migrating from traditional social networks and collaborative applications to more immersive digital experiences have been placed. However, the transition is not expected to be seamless. Privacy, safety and security concerns abound in the early versions of the metaverse. Increased regulatory oversight and diverse national laws threaten to derail the hype around the metaverse. It is increasingly clear that the final iteration of the metaverse will need to assuage the concerns of individual users while addressing complex legal and regulatory requirements. Thus, a multi-perspective approach needs to be adopted to help set the agenda for the evolution of the metaverse. This research paper examines the different aspects and challenges which the future metaverse will need to address. A set of “first principles” are formulated, which if implemented will lead to the development of an equitable, inclusive, safe and secure metaverse. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",first principles for the metaverse; Metaverse; metaverse security,Title_Abstract_Keywords,Abstract_Keywords,
Scopus,journalPaper,2024,Secure and Trustworthy Artificial Intelligence-extended Reality (AI-XR) for Metaverses,CSUR - Computing Surveys,A*,"Metaverse is expected to emerge as a new paradigm for the next-generation Internet, providing fully immersive and personalized experiences to socialize, work, and play in self-sustaining and hyper-spatio-temporal virtual world(s). The advancements in different technologies such as augmented reality, virtual reality, extended reality (XR), artificial intelligence (AI), and 5G/6G communication will be the key enablers behind the realization of AI-XR metaverse applications. While AI itself has many potential applications in the aforementioned technologies (e.g., avatar generation, network optimization), ensuring the security of AI in critical applications like AI-XR metaverse applications is profoundly crucial to avoid undesirable actions that could undermine users' privacy and safety, consequently putting their lives in danger. To this end, we attempt to analyze the security, privacy, and trustworthiness aspects associated with the use of various AI techniques in AI-XR metaverse applications. Specifically, we discuss numerous such challenges and present a taxonomy of potential solutions that could be leveraged to develop secure, private, robust, and trustworthy AI-XR applications. To highlight the real implications of AI-associated adversarial threats, we designed a metaverse-specific case study and analyzed it through the adversarial lens. Finally, we elaborate upon various open issues that require further research interest from the community.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.",AR; Metaverse; MR; robust ML; secure ML; trustworthy ML; VR; XR,Title_Abstract_Keywords,Abstract,
ACM DL,conferencePaper,2024,EgoTouch: On-Body Touch Input Using AR/VR Headset Cameras,UIST - Symposium on User Interface Software and Technology,A*,"In augmented and virtual reality (AR/VR) experiences, a user’s arms and hands can provide a convenient and tactile surface for touch input. Prior work has shown on-body input to have significant speed, accuracy, and ergonomic benefits over in-air interfaces, which are common today. In this work, we demonstrate high accuracy, bare hands (i.e., no special instrumentation of the user) skin input using just an RGB camera, like those already integrated into all modern XR headsets. Our results show this approach can be accurate, and robust across diverse lighting conditions, skin tones, and body motion (e.g., input while walking). Finally, our pipeline also provides rich input metadata including touch force, finger identification, angle of attack, and rotation. We believe these are the requisite technical ingredients to more fully unlock on-skin interfaces that have been well motivated in the HCI literature but have lacked robust and practical methods.",AR/VR; Computer Vision; On-Body Computing; Touch Surfaces and Touch Interaction,Abstract,Abstract,
IEEE,conferencePaper,2024,Motion Passwords,VR - International Symposium Virtual Reality,A*,"This paper introduces “Motion Passwords”, a novel biometric authentication approach where virtual reality users verify their identity by physically writing a chosen word in the air with their hand controller. This method allows combining three layers of verification: knowledge-based password input, handwriting style analysis, and motion profile recognition. As a first step towards realizing this potential, we focus on verifying users based on their motion profiles. We conducted a data collection study with 48 participants, who performed over 3800 Motion Password signatures across two sessions. We assessed the effectiveness of feature-distance and similarity-learning methods for motion-based verification using the Motion Passwords as well as specific and uniform ball-throwing signatures used in previous works. In our results, the similarity-learning model was able to verify users with the same accuracy for both signature types. This demonstrates that Motion Passwords, even when applying only the motion-based verification layer, achieve reliability comparable to previous methods. This highlights the potential for Motion Passwords to become even more reliable with the addition of knowledge-based and handwriting style verification layers. Furthermore, we present a proof-of-concept Unity application demonstrating the registration and verification process with our pretrained similarity-learning model. We publish our code, the Motion Password dataset, the pretrained model, and our Unity prototype on https://github.com/cschell/MoPs",Authentication; Biometrics; Extended Reality; Verification,Abstract_Keywords,Abstract_Keywords,
IEEE,conferencePaper,2024,"A Critical Review of Virtual and Extended Reality Immersive Police Training: Application Areas, Benefits &amp; Vulnerabilities",VR - International Symposium Virtual Reality,A*,"Virtual and Extended Reality (VR/XR) headsets have promised to enhance police training through the delivery of immersive simulations able to be conducted anywhere, anytime. However, little consideration has been given to reviewing the evidenced benefits and potential issues posed by XR police training. In this paper, we summarise the evidenced usage and benefits of XR police training through a formative targeted literature review (n=41 publications). We then reflect on the prospective technical, security, social and legal issues posed by XR police training, identifying four areas where issues or vulnerabilities exist: training content, trainees and trainers, systems and devices, and state and institutional stakeholders. We highlight significant concerns around e.g. the validity of training; the psychological impact and risks of trauma; the safety and privacy risks posed to trainees and trainers; and the risks to policing institutions. We aim to encourage end-user communities (e.g. police forces) to more openly reflect on the risks of immersive training, so we can ultimately move towards transparent, validated, trusted training that is evidenced to improve policing outcomes.",Extended Reality; Police Training; Virtual Reality,Title_Abstract_Keywords,Abstract,
IEEE,conferencePaper,2024,GazeLock: Gaze- and Lock Pattern-Based Authentication,VR - International Symposium Virtual Reality,A*,"Password entry is common authentication approach in Extended Reality (XR) applications for its simplicity and familiarity, but it faces challenges in public and dynamic environments due to its cumbersome nature and susceptibility to observation attacks. Manual password input can be disruptive and prone to theft through shoulder surfing or surveillance. While alternative knowledge-based approaches exist, they often require complex physical gestures and are impractical for frequent public use. We present GazeLock, an eye-tracking and lock pattern-based authentication method. This method aims to provide an easy-to-learn and efficient alternative by leveraging familiar lock patterns operated through gaze. It ensures resilience to external observation, as physical interaction is unnecessary and eyes are obscured by the headset. Its hands-free, discreet nature makes it suitable for secure public use. We demonstrate this method by simulating the unlocking of a smart lock via an XR headset, showcasing its potential applications and benefits in real-world scenarios.",Authentication; Extended Reality (XR); Eye Tracking; Gaze-based Interaction,Abstract_Keywords,Title_Abstract_Keywords,
Scopus,conferencePaper,2024,A Generative Framework for Low-Cost Result Validation of Machine Learning-as-a-Service Inference,AsiaCCS - Asia Conference on Computer and Communications Security,A,"The growing popularity of Machine Learning (ML) has led to its deployment in various sensitive domains, which has resulted in significant research focused on ML security and privacy. However, in some applications, such as Augmented/Virtual Reality, integrity verification of the outsourced ML tasks is more critical-a facet that has not received much attention. Existing solutions, such as multi-party computation and proof-based systems, impose significant computation overhead, which makes them unfit for real-time applications. We propose Fides, a novel framework for real-time integrity validation of ML-as-a-Service (MLaaS) inference. Fides features a novel and efficient distillation technique-Greedy Distillation Transfer Learning-that dynamically distills and fine-tunes a space and compute-efficient verification model for verifying the corresponding service model while running inside a trusted execution environment. Fides features a client-side attack detection model that uses statistical analysis and divergence measurements to identify, with a high likelihood, if the service model is under attack. Fides also offers a re-classification functionality that predicts the original class whenever an attack is identified. We devised a generative adversarial network framework for training the attack detection and re-classification models. The evaluation shows that Fides achieves an accuracy of up to 98% for attack detection and 94% for re-classification.",edge computing; machine learning as a service; result verification; trusted execution environment; verifiable computing,Abstract,Abstract,
Scopus,conferencePaper,2024,SoK: Data Privacy in Virtual Reality,PETS - International Symposium on Privacy Enhancing Technologies,A,"The adoption of virtual reality (VR) technologies has rapidly gained momentum in recent years as companies around the world begin to position the so-called “metaverse” as the next major medium for accessing and interacting with the internet. While consumers have become accustomed to a degree of data harvesting on the web, the real-time nature of data sharing in the metaverse indicates that privacy concerns are likely to be even more prevalent in the new “Web 3.0.” Research into VR privacy has demonstrated that a plethora of sensitive personal information is observable by various would-be adversaries from just a few minutes of telemetry data. On the other hand, we have yet to see VR parallels for many privacy-preserving tools aimed at mitigating threats on conventional platforms. This paper aims to systematize knowledge on the landscape of VR privacy threats and countermeasures by proposing a comprehensive taxonomy of data attributes, protections, and adversaries based on the study of 74 collected publications. We complement our qualitative discussion with a statistical analysis of the risk associated with various data sources inherent to VR in consideration of the known attacks and defenses. By focusing on highlighting the clear outstanding opportunities, we hope to motivate and guide further research into this increasingly important field.",,Title_Abstract,Title_Abstract,
Scopus,journalPaper,2024,<italic>xr-droid</italic>: A Benchmark Dataset for AR/VR and Security Applications,TODSC -Transactions on Dependable and Secure Computing,A,"The development of metaverses and virtual worlds on various platforms, including mobile devices, has led to the growth of applications in virtual reality (VR) and augmented reality (AR) in recent years. This application growth is paralleled by a growth of interest in analyzing and understanding AR/VR applications from security and performance standpoints. Despite this growing interest, benchmark datasets are lacking to facilitate this research pursuit. In this paper, we collect a dataset that consists of 408 diverse AR/VR applications from the Google Play Store and acquire various data modalities associated with those applications standardized in the form of seven features: control flow graphs, strings, functions, permissions, API calls, hexdump, and metadata. We highlight various research endeavors (applications) that can benefit from our dataset for each data modality. IEEE",Android; AR; Benchmark testing; Dataset; Hardware; Internet; Operating systems; Security; Security Applications; Solid modeling; Three-dimensional displays; VR,Abstract,Title_Abstract_Keywords,
Scopus,journalPaper,2024,Time to Think the Security of WiFi-Based Behavior Recognition Systems,TODSC -Transactions on Dependable and Secure Computing,A,"Behavior recognition plays an essential role in numerous behavior-driven applications (e.g., virtual reality and smart home) and even in the security-critical applications (e.g., security surveillance and elder healthcare). Recently, WiFi-based behavior recognition (WBR) technique stands out among many behavior recognition techniques due to its advantages of being non-intrusive, device-free, and ubiquitous. However, existing WBR research mainly focuses on improving the recognition precision, while rarely studying the security aspects. In this article, we reveal that WBR systems are vulnerable to manipulating physical signals. For instance, our observation shows that WiFi signals can be changed by jamming signals. By exploiting the vulnerability, we propose two approaches to generate physically online adversarial samples to perform untargeted attack and targeted attack, respectively. The effectiveness of these attacks are extensively evaluated over four real-world WBR systems. The experiment results show that our attack approaches can achieve 80% and 60% success rates for untargeted attack and targeted attack in physical world, respectively. We also show that our attack approaches can be generalized to other WiFi-based sensing applications, such as user authentication.  © 2004-2012 IEEE.",Adversarial sample; behavior recognition; genetic algorithm; WiFi,Abstract,Title_Abstract,
Scopus,journalPaper,2024,Dangers Behind Charging VR Devices: Hidden Side Channel Attacks via Charging Cables,TOIFS - Transactions on Information Forensics and Security,A,"Virtual reality (VR), offering 3D visuals and stereophonic sounds, significantly enhances users' immersive experiences and has become a milestone in the era of the metaverse. However, due to the limited battery capacity of VR devices, it is common for users to rely on charging cables, which serve the dual purpose of power supply and audio output, to recharge their VR devices while in use. In this study, we propose an inconspicuous and stealthy side channel attack, coined as LineTalker, which can unveil visual-related and audio-related activities from VR devices during the charging process. The insight behind LineTalker is rooted in the observation that visual-related activities (e.g., 3D image rendering) are power-intensive and result in fluctuations in the current strength of the cable's power supply line, which can be leveraged as side channel information. Similarly, audio-related activities (e.g., playing music) leave traces on the cable's audio output line. Rather than providing a user with a compromised charging cable (i.e., embedding a current sensor) to measure the current strength, to make the attack less conspicuous, LineTalker employs the Hall effect to indirectly access side channel information. This is achieved by capturing magnetic signals using a Hall sensor placed near the target cable in a contactless manner. Experimental results demonstrate that LineTalker achieves an overall accuracy of 94.60% and 64.38% in inferring user activities in VR devices with intrusive and non-intrusive attack manners, respectively.  © 2005-2012 IEEE.",charging cable; non-intrusive attack; privacy inference; side channel attack; Virtual reality,Abstract_Keywords,Title_Abstract_Keywords,
Scopus,journalPaper,2024,An Anti-Disguise Authentication System Using the First Impression of Avatar in Metaverse,TOIFS - Transactions on Information Forensics and Security,A,"Metaverse is a vast virtual world parallel to the physical world, where the user acts as an avatar to enjoy various services that break through the temporal and spatial limitations of the physical world. Metaverse allows users to create arbitrary digital appearances as their own avatars by which an adversary may disguise his/her avatar to fraud others. In this paper, we propose an anti-disguise authentication method that draws on the idea of the first impression from the physical world to recognize an old friend. Specifically, the first meeting scenario in the metaverse is stored and recalled to help the authentication between avatars. To prevent the adversary from replacing and forging the first impression, we construct a chameleon-based signcryption mechanism and design a ciphertext authentication protocol to ensure the public verifiability of encrypted identities. The security analysis shows that the proposed signcryption mechanism meets not only the security requirement but also the public verifiability. Besides, the ciphertext authentication protocol has the capability of defending against the replacing and forging attacks on the first impression. Extensive experiments show that the proposed avatar authentication system is able to achieve anti-disguise authentication at a low storage consumption on the blockchain.  © 2005-2012 IEEE.",anti-disguise; authentication; avatar; Metaverse,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,journalPaper,2024,Privacy-Preserving Gaze Data Streaming in Immersive Interactive Virtual Reality: Robustness and User Experience,TVCG - Transactions on Visualization and Computer Graphics,A,"Eye tracking is routinely being incorporated into virtual reality (VR) systems. Prior research has shown that eye tracking data, if exposed, can be used for re-identification attacks [14]. The state of our knowledge about currently existing privacy mechanisms is limited to privacy-utility trade-off curves based on data-centric metrics of utility, such as prediction error, and black-box threat models. We propose that for interactive VR applications, it is essential to consider user-centric notions of utility and a variety of threat models. We develop a methodology to evaluate real-time privacy mechanisms for interactive VR applications that incorporate subjective user experience and task performance metrics. We evaluate selected privacy mechanisms using this methodology and find that re-identification accuracy can be decreased to as low as 14% while maintaining a high usability score and reasonable task performance. Finally, we elucidate three threat scenarios (black-box, black-box with exemplars, and white-box) and assess how well the different privacy mechanisms hold up to these adversarial scenarios. This work advances the state of the art in VR privacy by providing a methodology for end-to-end assessment of the risk of re-identification attacks and potential mitigating solutions. f  © 1995-2012 IEEE.",eye tracking; privacy; Virtual reality,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,journalPaper,2024,"Berkeley Open Extended Reality Recordings 2023 (BOXRR-23): 4.7 Million Motion Capture Recordings from 105,000 XR Users",TVCG - Transactions on Visualization and Computer Graphics,A,"Extended reality (XR) devices such as the Meta Quest and Apple Vision Pro have seen a recent surge in attention, with motion tracking atelemetrya data lying at the core of nearly all XR and metaverse experiences. Researchers are just beginning to understand the implications of this data for security, privacy, usability, and more, but currently lack large-scale human motion datasets to study. The BOXRR-23 dataset contains 4,717,215 motion capture recordings, voluntarily submitted by 105,852 XR device users from over 50 countries. BOXRR-23 is over 200 times larger than the largest existing motion capture research dataset and uses a new, highly efficient and purpose-built XR Open Recording (XROR) file format. © 1995-2012 IEEE.",big data; Dataset; extended reality; motion capture; virtual reality,Title_Abstract_Keywords,Abstract,
Scopus,journalPaper,2024,Analysis and Design of Efficient Authentication Techniques for Password Entry with the Qwerty Keyboard for VR Environments,TVCG - Transactions on Visualization and Computer Graphics,A,"Authentication in digital security relies heavily on text-based passwords, even with other available methods like biometrics and graphical passwords. While virtual reality (VR) keyboards are typically invisible to onlookers, the presence of inconspicuous sensors, including accelerometers, gyroscopes, and barometers, poses a potential risk of unauthorized observation and recording. Traditional defense shoulder-surfing attack methods typically involve breaking apart the Qwerty layout, which destroys the user's inherent familiarity with the layout. This research addresses the need for secure password entry in VR environments while retaining the Qwerty layout. We explore three keyboard-related position alteration strategies to ensure security while mitigating the decline in user experience. These strategies involve moving the entire keyboard, cursor, and keys. Our theoretical study assesses the effectiveness of these strategies against shoulder-surfing attacks. Two user studies, employing ray-based and position-based text entry methods, respectively, evaluate the practical effectiveness of the three strategies in resisting shoulder-surfing attacks, as well as their impact on typing performance and user experience. Our findings demonstrate that the three strategies achieve shoulder-surfing attack resistance comparable to a random layout keyboard. Moreover, compared to a random layout, the two strategies involving the movement of the entire keyboard and the repositioning of keys support faster entry rates and enhanced user experience. © 1995-2012 IEEE.",keyboard layout; password; text entry; user study; Virtual reality,Abstract_Keywords,Title_Abstract,
Scopus,conferencePaper,2017,Augmented invaders: a mixed reality multiplayer outdoor game,VRST - Virtual Reality Software and Technology,A,"Many virtual and mixed reality games focus on single player experiences. In this paper, we describe the concept and prototype implementation of a mixed reality multiplayer game that can be played with a smartphone and an HMD in outdoor environments. Players can team up to fight against attacking alien drones. The relative positions between the players are tracked using GPS, and the rear camera of the smartphone is used to augment the environment and teammates with virtual objects. The combination of multiplayer, mixed reality, the use of geographical location and outdoor action together with affordable, mobile equipment enables a novel strategic and social game experience.",AR; augmented reality; games; GPS; mixed reality; multiplayer,Title_Abstract_Keywords,Abstract,
Scopus,conferencePaper,2019,DexController : Designing a VR Controller with Grasp-Recognition for Enriching Natural Game Experience,VRST - Virtual Reality Software and Technology,A,"We present DexController, which is a hand-held controller leveraging grasp as an additional modality for virtual reality (VR) game. The pressure-sensitive surface of DexController was designed to recognize two different grasp-poses (i.e. precision grip and power grip) and detect grasp-force. Based on the results of two feasibility tests, a VR defense game was designed in which players could attack each enemy using the proper weapon with a proper level of force. A within-subject comparative study is conducted with a button-based controller which has the same physical form of DexController. The results indicated that DexController enhanced the perceived naturalness of the controller and game enjoyment, with having acceptable physical demand. This study clarifies the empirical effect of utilizing grasp-recognition on VR game controller to enhance interactivity. Also, we provide insight for the integration of VR game elements with the grasping modality of a controller.",controller; game experience; gaming; natural interaction; Virtual reality,Abstract_Keywords,Abstract,
Scopus,conferencePaper,2019,DexController : Hand-Held Controller Recognizing Grasp-Pose and Grasp-Force in Virtual Reality Defense Game,VRST - Virtual Reality Software and Technology,A,"We developed a hand-held controller named DexController, leveraging grasp as an additional input modality for virtual reality(VR) game. The pressure-sensitive surface of DexController could recognize two different grasp-poses (i.e. precision grip and power grip) and detect grasp-force. For demonstration, we designed a VR defense game in which players should attack different virtual enemies using the proper weapon with a proper level of force. User study confirmed that utilizing meaningful information of grasping facilitates natural mapping with game contents, which led VR game users to experience enhanced presence and enjoyment.",controller; game experience; natural interaction; Virtual reality,Title_Abstract_Keywords,Abstract,
Scopus,conferencePaper,2020,Anonymity vs. Familiarity: Self-Disclosure and Privacy in Social Virtual Reality,VRST - Virtual Reality Software and Technology,A,"Understanding how and why users reveal information about their self in online social spaces and what they perceive as privacy online is a central research agenda in HCI. Drawing on 30 in-depth interviews, in this paper we focus on what type of information users disclose, to whom they reveal information, and concerns they had regarding self-disclosure in social Virtual Reality (VR) - where multiple users can interact with one another through VR head-mounted displays in 3D virtual spaces. Our findings show that overall, users felt comfortable to disclose their emotions, personal experience, and personal information in social VR. However, they also acknowledged that disclosing personal information in social VR was an inevitable trade-off: giving up bio-metric information in order to better use the system. We contribute to existing literature on self-disclosure and privacy online by focusing on social VR as an emerging novel online social space. We also explicate implications for designing and developing future social VR applications.",digital privacy; online social interaction; self-disclosure; social virtual reality,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,conferencePaper,2020,A Quest for Co-Located Mixed Reality: Aligning and Assessing SLAM Tracking for Same-Space Multi-User Experiences,VRST - Virtual Reality Software and Technology,A,"Current solutions for creating co-located Mixed Reality (MR) experiences typically rely on platform-specific synchronisation of spatial anchors or Simultaneous Localisation and Mapping (SLAM) data across clients, often coupled to cloud services. This introduces significant costs (in development and deployment), constraints (with interoperability across platforms often limited), and privacy concerns. For practitioners, support is needed for creating platform-agnostic co-located MR experiences. This paper explores the utility of aligned SLAM solutions by 1) surveying approaches toward aligning disparate device coordinate spaces, formalizing their theoretical accuracy and limitations; 2) providing skeleton implementations for audience-based, small-scale and large-scale co-location using said alignment approaches; and 3) detailing how we can assess the accuracy and safety of 6DoF/SLAM tracking solutions for any arbitrary device and dynamic environment without the need for an expensive ground truth optical tracking, by using trilateration and a $30 laser distance meter. Through this, we hope to further democratise the creation of cross-platform co-located MR experiences.",AR; Co-location; Mixed Reality; Multi-User; SLAM; VR,Title_Abstract_Keywords,Abstract,
Scopus,conferencePaper,2021,BreachMob: Detecting Vulnerabilities in Physical Environments Using Virtual Reality,VRST - Virtual Reality Software and Technology,A,"BreachMob is a virtual reality (VR) tool that applies open design principles from information security to physical buildings and structures. BreachMob uses a detailed 3D digital model of a property owner's building. The model is then published as a virtual environment (VE), complete with all applicable security measures and released to the public to test the building's security and find any potential vulnerabilities by completing specified objectives. Our paper contributes a new method of applying VR to crowd source detection of physical environment vulnerabilities. We detail the technical realization of two BreachMob prototypes (a home and an airport) reflecting on static and dynamic vulnerabilities. Our design critique suggests that&nbsp;BreachMob&nbsp;promotes user immersion by allowing participants the freedom to behave in ways that align with the experience of breaching physical security protocols.",,Title_Abstract,Abstract,
Scopus,conferencePaper,2021,Using Gaze Behavior and Head Orientation for Implicit Identification in Virtual Reality,VRST - Virtual Reality Software and Technology,A,"Identifying users of a Virtual Reality (VR) headset provides designers of VR content with the opportunity to adapt the user interface, set user-specific preferences, or adjust the level of difficulty either for games or training applications. While most identification methods currently rely on explicit input, implicit user identification is less disruptive and does not impact the immersion of the users. In this work, we introduce a biometric identification system that employs the user’s gaze behavior as a unique, individual characteristic. In particular, we focus on the user’s gaze behavior and head orientation while following a moving stimulus. We verify our approach in a user study. A hybrid post-hoc analysis results in an identification accuracy of up to 75&nbsp;% for an explainable machine learning algorithm and up to 100&nbsp;% for a deep learning approach. We conclude with discussing application scenarios in which our approach can be used to implicitly identify users.",eye tracking; gaze-based authentication; implicit identification; virtual reality,Title_Abstract_Keywords,Keywords,
Scopus,conferencePaper,2021,Dealing with a Panic Attack: a Virtual Reality Training Module for Postgraduate Psychology Students,VRST - Virtual Reality Software and Technology,A,"In this paper we present a virtual reality training simulator for postgraduate psychology students. This simulator features an interaction between a clinical psychologist (student) and a patient (virtual agent) suffering from Obsessive Compulsive Disorder (OCD). Our simulation focuses on the form of OCD treatment called “Exposure Therapy”. The traditional way of learning how to perform Exposure Therapy (ET) currently involves watching video recordings and discussing those in the class. In our simulation we conduct an immersive exposure therapy session in VR. This session involves a live interaction with a patient that at one stage triggers a panic attack. Our hypothesis is that the immersive nature of the training session will affect the decision making process of the students so that they are more likely to cease the exposure task than those student participating in a less immersive form of learning (watching a video recording). We also hypothesise that participating in an immersive VR training session is more effective than watching videos, as far as information retention goes.",Exposure Therapy; OCD; Panic Attack; Psychology training; Virtual Reality,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,conferencePaper,2023,Exploring the Stability of Behavioral Biometrics in Virtual Reality in a Remote Field Study: Towards Implicit and Continuous User Identification through Body Movements,VRST - Virtual Reality Software and Technology,A,"Behavioral biometrics has recently become a viable alternative method for user identification in Virtual Reality (VR). Its ability to identify users based solely on their implicit interaction allows for high usability and removes the burden commonly associated with security mechanisms. However, little is known about the temporal stability of behavior (i.e., how behavior changes over time), as most previous works were evaluated in highly controlled lab environments over short periods. In this work, we present findings obtained from a remote field study (N = 15) that elicited data over a period of eight weeks from a popular VR game. We found that there are changes in people’s behavior over time, but that two-session identification still is possible with a mean F1-score of up to 71%, while an initial training yields 86%. However, we also see that performance can drop by up to over 50 percentage points when testing with later sessions, compared to the first session, particularly for smaller groups. Thus, our findings indicate that the use of behavioral biometrics in VR is convenient for the user and practical with regard to changing behavior and also reliable regarding behavioral variation.",Virtual Reality; Field Study; Continuous Identification.; Implicit User Identification,Title_Abstract_Keywords,Abstract,
Scopus,conferencePaper,2024,Motion Passwords,VRST - Virtual Reality Software and Technology,A,"This paper introduces “Motion Passwords”, a novel biometric authentication approach where virtual reality users verify their identity by physically writing a chosen word in the air with their hand controller. This method allows combining three layers of verification: knowledge-based password input, handwriting style analysis, and motion profile recognition. As a first step towards realizing this potential, we focus on verifying users based on their motion profiles. We conducted a data collection study with 48 participants, who performed over 3800 Motion Password signatures across two sessions. We assessed the effectiveness of feature-distance and similarity-learning methods for motion-based verification using the Motion Passwords as well as specific and uniform ball-throwing signatures used in previous works. In our results, the similarity-learning model was able to verify users with the same accuracy for both signature types. This demonstrates that Motion Passwords, even when applying only the motion-based verification layer, achieve reliability comparable to previous methods. This highlights the potential for Motion Passwords to become even more reliable with the addition of knowledge-based and handwriting style verification layers. Furthermore, we present a proof-of-concept Unity application demonstrating the registration and verification process with our pretrained similarity-learning model. We publish our code, the Motion Password dataset, the pretrained model, and our Unity prototype on https://github.com/cschell/MoPs",Biometrics; Extended Reality; Authentication; Verification,Abstract_Keywords,Abstract_Keywords,Duplicate
Scopus,conferencePaper,2024,"A Critical Review of Virtual and Extended Reality Immersive Police Training: Application Areas, Benefits &amp; Vulnerabilities",VRST - Virtual Reality Software and Technology,A,"Virtual and Extended Reality (VR/XR) headsets have promised to enhance police training through the delivery of immersive simulations able to be conducted anywhere, anytime. However, little consideration has been given to reviewing the evidenced benefits and potential issues posed by XR police training. In this paper, we summarise the evidenced usage and benefits of XR police training through a formative targeted literature review (n=41 publications). We then reflect on the prospective technical, security, social and legal issues posed by XR police training, identifying four areas where issues or vulnerabilities exist: training content, trainees and trainers, systems and devices, and state and institutional stakeholders. We highlight significant concerns around e.g. the validity of training; the psychological impact and risks of trauma; the safety and privacy risks posed to trainees and trainers; and the risks to policing institutions. We aim to encourage end-user communities (e.g. police forces) to more openly reflect on the risks of immersive training, so we can ultimately move towards transparent, validated, trusted training that is evidenced to improve policing outcomes.",Virtual Reality; Extended Reality; Police Training,Title_Abstract_Keywords,Abstract,Duplicate
Scopus,conferencePaper,2024,GazeLock: Gaze- and Lock Pattern-Based Authentication,VRST - Virtual Reality Software and Technology,A,"Password entry is common authentication approach in Extended Reality (XR) applications for its simplicity and familiarity, but it faces challenges in public and dynamic environments due to its cumbersome nature and susceptibility to observation attacks. Manual password input can be disruptive and prone to theft through shoulder surfing or surveillance. While alternative knowledge-based approaches exist, they often require complex physical gestures and are impractical for frequent public use. We present GazeLock, an eye-tracking and lock pattern-based authentication method. This method aims to provide an easy-to-learn and efficient alternative by leveraging familiar lock patterns operated through gaze. It ensures resilience to external observation, as physical interaction is unnecessary and eyes are obscured by the headset. Its hands-free, discreet nature makes it suitable for secure public use. We demonstrate this method by simulating the unlocking of a smart lock via an XR headset, showcasing its potential applications and benefits in real-world scenarios.",Eye Tracking; Extended Reality (XR); Authentication; Gaze-based Interaction,Abstract_Keywords,Title_Abstract_Keywords,Duplicate
Scopus,conferencePaper,2024,Usable Authentication in Virtual Reality: Exploring the Usability of PINs and Gestures,ACNS - International Conference on Applied Cryptography and Network Security,B,"Virtual Reality (VR) is becoming increasingly popular with its ability to offer new forms of interaction, user interface, and immersion not only for recreation but also for work, therapy, arts, or education. These new spaces need to be safeguarded by authentication similar to conventional IT systems. However, porting conventional interfaces to VR has often been found to be less than optimal as it fails to fully embrace the technology’s potential and potentially disrupt the immersive experience. This paper evaluates and compares the usability of two major authentication methods for VR: 2D Personal Identification Number (PIN) and gesture-based authentication - with 40 participants. While prior research has shown promising results in authentication security, there is a lack of studies specifically on usability in VR. Our findings indicate that the type of authentication and the user’s experience level affect usability, with gesture-based authentication having a higher usability score than a PIN and having faster authentication times. Hereby, users with less VR experience profited the most from a natural interaction mode for VR. The results suggest that developers should rather choose a native interaction mode in VR than try to port a familiar conventional interaction such as number pads for PINs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",Authentication; Gestures; PINs; Usability; Virtual Reality,Title_Abstract_Keywords,Title_Abstract_Keywords,
Scopus,conferencePaper,2024,Leveraging Overshadowing for Time-Delay Attacks in 4G/5G Cellular Networks: An Empirical Assessment,"ARES - International Conference on Availability, Reliability and Security",B,"Ensuring both reliable and low-latency communications over 4G or 5G Radio Access Network (RAN) is a key feature for services such as smart power grids and the metaverse. However, the lack of appropriate security mechanisms at the lower-layer protocols of the RAN–a heritage from 4G networks–opens up vulnerabilities that can be exploited to conduct stealthy Reduction-of-Quality attacks against the latency guarantees. This paper presents an empirical assessment of a proposed time-delay attack that leverages overshadowing to exploit the reliability mechanisms of the Radio Link Control (RLC) in Acknowledged Mode. By injecting falsified RLC Negative Acknowledgements, an attacker can maliciously trigger retransmissions at the victim User Equipment (UE), degrading the uplink latency of application flows. Extensive experimental evaluations on open-source and commercial off-the-shelf UEs demonstrate the attack’s effectiveness in increasing latency, network load, and buffer occupancy. The attack impact is quantified by varying the bitrate representing different applications and the number of injected negative acknowledgments controlling the attack intensity. This work studies a realistic threat against the latency quality of service in 4G/5G RANs and highlights the urgent need to revisit protocol security at the lower-RAN layers for 5G (and beyond) networks.",Deny of Service; Latency; Man on the Side; Overshadowing; Radio Access Network; Reduction of Quality; Time-delay,Abstract,Title_Abstract,
Scopus,conferencePaper,2024,A Domain-Specific Language for Augmented Reality Games,SAC - Selected Areas in Cryptography,B,"Augmented Reality (AR) applications have become popular over the last few years, with significant impact on video games. AR does not require advanced technology, but a mobile device with a camera is enough. However, building AR games is time-consuming and requires deep expertise in the tools, technologies and programming languages of the field, as well as on mathematical concepts related to the graphics and physics of the virtual objects. We attack this problem by means of a Domain-Specific Language (DSL) named argDSL, tailored to create AR games. It offers primitives to customise the domain and logic of the game, the physics of the virtual objects, and their graphical representation. We provide an Eclipse environment enabling the definition of AR games using the DSL, and an iOS client able to run the defined games.",augmented reality; domain-specific languages; games,Title_Abstract_Keywords,Abstract,
Scopus,conferencePaper,2024,Securing Contrastive mmWave-based Human Activity Recognition against Adversarial Label Flipping,WiSec - Security and Privacy in Wireless and Mobile Networks,B,"Wireless Human Activity Recognition (HAR), leveraging their non-intrusive nature, has the potential to revolutionize various sectors, including healthcare, virtual reality, and surveillance. The advent of millimeter wave (mmWave) technology has significantly enhanced the capabilities of wireless HAR systems. This paper presents the first systematic study on the vulnerabilities of mmWave-based HAR to label flipping poisoning attacks in the context of supervised contrastive learning. We identify three label poisoning attacks on the contrastive mmWave-based HAR and propose corresponding countermeasures. The efficacy of the attacks and also our countermeasures are experimentally validated on a prototype system. The attacks and countermeasures can be easily extended to other wireless HAR systems, thereby promoting security considerations in system design and deployment.",human activity recognition; label poisoning; millimeter-wave (mmwave) technology; supervised contrastive learning (scl),Abstract,Abstract,
Scopus,conferencePaper,2024,De-anonymizing VR Avatars using Non-VR Motion Side-channels,WiSec - Security and Privacy in Wireless and Mobile Networks,B,"Virtual Reality (VR) technology offers an immersive audio-visual experience to users through which they can interact with a digitally represented 3D space (i.e., a virtual world) using a headset device. By (visually) transporting users from their physical world to realistic virtual spaces, VR systems enable interactive and true-to-life versions of traditional applications such as gaming, remote conferencing and virtual tourism. However, VR applications also present significant user-privacy challenges. This paper studies a new type of privacy threat targeting VR users which attempts to connect their activities visible in the virtual world to their physical state sensed in the real world. Specifically, this paper analyzes the feasibility of carrying out a de-anonymization or identification attack on VR users by correlating visually observed movements of users' avatars in the virtual world with some auxiliary data (e.g., motion sensor data from mobile/wearable devices) representing their context/state in the physical world. To enable this attack, the paper proposes a novel framework which first employs a learning-based activity classification approach to translate the disparate visual movement data and motion sensor data into an activity-vector to ease comparison, followed by a filtering and identity ranking phase outputting an ordered list of potential identities corresponding to the target visual movement data. A comprehensive empirical evaluation of the proposed framework is conducted to study the feasibility of such a de-anonymization attack.",de-anonymization; motion; side channel; virtual reality,Abstract_Keywords,Abstract,
Scopus,journalPaper,2024,Securing Bystander Privacy in Mixed Reality While Protecting the User Experience,SPM - Security & Privacy Magazine,B,"The modern mixed-reality devices that make the Metaverse viable require vast information about the physical world and can also violate the privacy of unsuspecting or unwilling bystanders. We provide an introduction to the problem, existing solutions, and avenues for future research.  © 2003-2012 IEEE.",,Title_Abstract,Title_Abstract,
Scopus,journalPaper,2024,Security and Privacy in the Metaverse,SPM - Security & Privacy Magazine,B,[No abstract available],,Title,Title,
Scopus,journalPaper,2024,Augmenting Security and Privacy in the Virtual Realm: An Analysis of Extended Reality Devices,SPM - Security & Privacy Magazine,B,We present a device-centric analysis of security and privacy attacks and defenses on extended reality (XR) devices. We present future research directions and propose design considerations to help ensure the security and privacy of XR devices.  © 2003-2012 IEEE.,,Title_Abstract,Title_Abstract,
Scopus,journalPaper,2024,Understanding Privacy in Virtual Reality Classrooms: A Contextual Integrity Perspective,SPM - Security & Privacy Magazine,B,"We outline privacy concerns and challenges associated with adopting virtual reality technologies in established social contexts using the theory of contextual integrity, examining information flows within and in between the real and virtual environments that could violate existing privacy norms.  © 2003-2012 IEEE.",,Title_Abstract,Title_Abstract,
Scopus,journalPaper,2024,Handling Identity and Fraud in the Metaverse,SPM - Security & Privacy Magazine,B,"Given the metaverse&#x2019;s potential realism and immersive nature, users may find it difficult to detect fraud. We explore the design space and technical aspects of verification and identification and how they may apply to fraud prevention in the metaverse. IEEE",Avatars; Fraud; Internet; Metaverse; Museums; Privacy; Security,Title_Abstract_Keywords,Keywords,
Scopus,journalPaper,2024,Truth in Motion: The Unprecedented Risks and Opportunities of Extended Reality Motion Data,SPM - Security & Privacy Magazine,B,"Motion-tracking telemetry data lie at the core of most modern extended reality (XR) and metaverse experiences. Recent studies have demonstrated that motion data have the potential to profile and deanonymize XR users, posing a threat to privacy in the metaverse.  © 2003-2012 IEEE.",,Title_Abstract,Abstract,
Scopus,journalPaper,2024,Cybersickness with passenger VR in the aircraft: Influence of turbulence and VR content,VRS - Virtual Reality,B,"Using VR in the airplane cabin is appealing, primarily because of the enhanced entertainment value, increased privacy, and improved recreational opportunities provided by higher levels of immersion. However, VR applications in aircrafts contain the risk of passengers developing cybersickness. The particular environment of a moving aircraft in interaction with visual representation of movements in VR could lead to severe cybersickness, especially during turbulence. We had 129 participants experience VR in a full flight simulator with different content (static or dynamic VR clips) and during varying phases of flight including turbulence. The employed simulator is equipped with a cabin module, creating an economically valid environment. VR induced significant but mild symptoms of cybersickness. Nausea and dizziness symptoms were most severe during turbulence and especially with dynamic VR content being presented. More anxious participants tended to report more symptoms. In addition, there was an association with video game use and attitudes toward new technologies. While mild content and short exposure times only led to fairly low expressions of cybersickness, a long-term use of VR under turbulence could possibly become a concern. Airlines should especially address passengers’ negative attitudes toward new technologies, and VR in particular, to reduce fears and the risk of low tolerability. © The Author(s) 2024.",Aircraft cabins; Airplanes; Cybersickness; Moving vehicles; Virtual reality,Keywords,Abstract,
Scopus,journalPaper,2024,A real-time wearable AR system for egocentric vision on the edge,VRS - Virtual Reality,B,"Real-time performance is critical for Augmented Reality (AR) systems as it directly affects responsiveness and enables the timely rendering of virtual content superimposed on real scenes. In this context, we present the DARLENE wearable AR system, analysing its specifications, overall architecture and core algorithmic components. DARLENE comprises AR glasses and a wearable computing node responsible for several time-critical computation tasks. These include computer vision modules developed for the real-time analysis of dynamic scenes supporting functionalities for instance segmentation, tracking and pose estimation. To meet real-time requirements in limited resources, concrete algorithmic adaptations and design choices are introduced. The proposed system further supports real-time video streaming and interconnection with external IoT nodes. To improve user experience, a novel approach is proposed for the adaptive rendering of AR content by considering the user’s stress level, the context of use and the environmental conditions for adjusting the level of presented information towards enhancing their situational awareness. Through extensive experiments, we evaluate the performance of individual components and end-to-end pipelines. As the proposed system targets time-critical security applications where it can be used to enhance police officers’ situational awareness, further experimental results involving end users are reported with respect to overall user experience, workload and evaluation of situational awareness. © The Author(s) 2024.",Artificial intelligence; Augmented reality; Intelligent user interfaces; Situational awareness,Abstract_Keywords,Abstract,
Scopus,journalPaper,2024,Therapist perspectives on telehealth-based virtual reality exposure therapy,VRS - Virtual Reality,B,"Virtual reality (VR) can enhance mental health care. In particular, the effectiveness of VR-based exposure therapy (VRET) has been well-demonstrated for treatment of anxiety disorders. However, most applications of VRET remain localized to clinic spaces. We aimed to explore mental health therapists’ perceptions of telehealth-based VRET (tele-VRET) by conducting semi-structured, qualitative interviews with 18 telemental health therapists between October and December 2022. Interview topics included telehealth experiences, exposure therapy over telehealth, previous experiences with VR, and perspectives on tele-VRET. Therapists described how telehealth reduced barriers (88.9%, 16/18), enhanced therapy (61.1%, 11/18), and improved access to clients (38.9%, 7/18), but entailed problems with technology (61.1%, 11/18), uncontrolled settings (55.6%, 10/18), and communication difficulties (50%, 9/18). Therapists adapted exposure therapy to telehealth by using online resources (66.7%, 12/18), preparing client expectations (55.6%, 10/18), and adjusting workflows (27.8%, 5/18). Most therapists had used VR before (72.2%, 13/18) and had positive impressions of VR (55.6%, 10/18), but none had used VR clinically. In response to tele-VRET, therapists requested interactive session activities (77.8%, 14/18) and customizable interventions components (55.6%, 10/18). Concerns about tele-VRET included risks with certain clients (77.8%, 14/18), costs (50%, 9/18), side effects and privacy (22.2%, 4/18), and inappropriateness for specific forms of exposure therapy (16.7%, 3/18). These results reveal how combining telehealth and VRET may expand therapeutic options for mental healthcare providers and can help inform collaborative development of immersive health technologies. © The Author(s) 2024.",Clinical practice; Exposure therapy; Mental health; Telehealth; Virtual reality,Title_Abstract_Keywords,Abstract,
Scopus,journalPaper,2024,ARGo: augmented reality-based mobile Go stone collision game,VRS - Virtual Reality,B,"In this study, we present a mobile Go stone collision game based on augmented reality, which we call ARGo, inspired by the traditional Korean board game, Alkkagi. ARGo aims to resolve two main issues: (1) the portability and space constraints of the original Alkkagi and (2) the limited sense of reality due to the touchscreen-based interface of the existing mobile Alkkagi games. To improve a sense of the reality of the game, ARGo provides a gameplay interface similar to the original Alkkagi by recognizing the user‘s hand motion based on AR. Additionally, it provides a customization mechanism for each user to improve the recognition of the hand motion and the strength of the attack considering each user‘s characteristics. Finally, we make the following three main contributions. First, we employ the automata theory to design the game and collision scenarios between stones. Consequently, we can clearly define the complicated states incurred by AR-based motion recognition and collisions between virtual objects. Second, we propose a collision equation based on Continuous Collision Detection tailored to ARGo, i.e., Go stones and their collisions. Through experimental studies, we demonstrate that the collision equation enables the simulation of the exact collision effects. Third, through user experience studies, we verify the effectiveness of ARGo by showing the effects of the functions implemented in ARGo and its superiority over the existing mobile game Alkkagi Mania. © 2024, The Author(s).",Augmented reality; Automata theory-based game design; Collision effects; Customization; Mobile games; Motion recognition,Title_Abstract_Keywords,Abstract,
Scopus,journalPaper,2023,Seamless-walk: natural and comfortable virtual reality locomotion method with a high-resolution tactile sensor,VRS - Virtual Reality,B,"Efficient locomotion methods have been proposed to compensate for the limited space in real-world environments, and such methods offer users more immersive and natural experiences in relatively large virtual environments. The foot-based locomotion method is one of the best options for implementing natural locomotion using foot movement as an input. However, existing foot-based locomotion methods force users to wear equipment or take a video of the user’s body. These actions can cause discomfort, unnatural feelings, or privacy problems. Thus, we propose a Seamless-walk system that can seamlessly translate a real-world gait action to locomotion signals using a high-resolution tactile carpet sensor without requiring wearable equipment. The proposed method captures and analyzes high-resolution footprint information using a machine learning technique and calculates the user’s movement direction and speed in a real-time manner. In addition, the modular structure of Seamless-walk enables scalable installation of a tactile sensing platform at reasonable cost. Human tests (n = 80) confirmed that the proposed Seamless-walk system’s technical advantage increases usability. A 3D virtual world exploration game experiment revealed that the proposed method significantly increases comfort and overall naturalness. Additionally, The proposed method has no negative effects on exploration suitability, task load, simulator sickness, or the game experience. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",Human computer interaction; Human-centered computing; Interaction paradigms; Virtual reality,Title_Keywords,Abstract,
Scopus,journalPaper,2021,Landmine detection training simulation using virtual reality technology,VRS - Virtual Reality,B,"Landmines are frequently used for defence and attack. Thus, landmine detection is vital to preventing the damages incurred. Various landmine detection methods have been developed from the past to the present. Thus, a need has arisen for the employment of qualified personnel in this field. In today’s landmine detection training, soldiers are first subjected to theoretical training about landmine types. After this stage, they attend practical training in the field. However, when training is given in this way, sample application fields do not contain all possible terrain and weather conditions. Also, many accidents and injuries occur during this practical training. To overcome the disadvantages elucidated above, a landmine detection training simulation was developed in this study, which supports real terrain conditions and creates a safe detection environment. In this study, the developed simulation software was based on virtual reality technology. The interaction with the computer is both provided by a detector appearance control device (DACD) controller developed for this simulator and by Kinect controller. The simulator has remarkable benefits concerning time and cost when compared with the landmine detection training given today. At the same time, detections performed in a safe environment without any risk factors and real land conditions were provided close to reality. Also, the actual space coordinates of the joints in the human body can be detected correctly using the DACD controller, as much as the Kinect device. © 2020, Springer-Verlag London Ltd., part of Springer Nature.",Kinect V2; Landmine detection training; Landmine sweeping; Simulation; Unity 3D; VR,Title_Abstract,Abstract,
Scopus,journalPaper,2020,Evaluation of augmented reality technology for the design of an evacuation training game,VRS - Virtual Reality,B,"Building evacuation training systems and training employees in an organization have a vital role in emergency cases in which people need to know what to do exactly. In every building, procedures, rules, and actions are attractively shown on the walls, but most of the people living in that building are not aware of these procedures and do not have any experience what to do in these dangerous situations. In order to be able to apply these procedures properly in an emergency situation, community members should be trained with the state-of-the-art equipment and technologies, but to do so, up-front investment and development of such a system are necessary. In this study, augmented reality (AR) technology was applied to realize a game-based evacuation training system that implements gamification practices. The architectural plans of a university were used to model the floors and the relevant environment. Employees are trained to learn how to reach the nearest exit location in the event of a fire or earthquake, and also, the system provides the shortest path for the evacuation. In addition to these features, our training game has educational animations about the fire, chemical attack, and earthquake events. A mobile application was implemented to train employees working in the building and inform them to know how to escape in an emergency situation. The technology acceptance model and the related questionnaire form were applied, and the response of 36 participants was analyzed. It was demonstrated that AR and relevant tools provide a flexible environment to develop evacuation systems in a university, our mobile application enabled participants to be trained in a realistic environment, and trainees were highly satisfied with the system. Educational animations were also another benefit for the trainees. © 2019, The Author(s).",Animation; ARKit framework; Augmented reality; Evacuation training system; Game engine; Software; Training; Unity3D,Title_Abstract_Keywords,Abstract,
Scopus,journalPaper,2020,Challenges in passenger use of mixed reality headsets in cars and other transportation,VRS - Virtual Reality,B,"This paper examines key challenges in supporting passenger use of augmented and virtual reality headsets in transit. These headsets will allow passengers to break free from the restraints of physical displays placed in constrained environments such as cars, trains and planes. Moreover, they have the potential to allow passengers to make better use of their time by making travel more productive and enjoyable, supporting both privacy and immersion. However, there are significant barriers to headset usage by passengers in transit contexts. These barriers range from impediments that would entirely prevent safe usage and function (e.g. motion sickness) to those that might impair their adoption (e.g. social acceptability). We identify the key challenges that need to be overcome and discuss the necessary resolutions and research required to facilitate adoption and realize the potential advantages of using mixed reality headsets in transit. © 2019, The Author(s).",Augmented reality; In-car; In-flight; Mixed reality; Passenger; Transportation; Travel; Virtual reality,Title_Abstract_Keywords,Abstract,
Scopus,journalPaper,2023,"19th IFIP TC 13 International Conference on Human-Computer Interaction, INTERACT 2023",INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,The proceedings contain 206 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: “The Relief is Amazing”: An In-situ Short Field Evaluation of a Personal Voice Assistive Technology for a User Living with Dementia; towards an Automatic Easy-to-Read Adaptation of Morphological Features in Spanish Texts; Challenges Faced by the Employed Indian DHH Community; haptic Auditory Feedback for Enhanced Image Description: A Study of User Preferences and Performance; using Colour and Brightness for Sound Zone Feedback; common Objects for Programming Workshops in Non-Formal Learning Contexts; engaging a Project Consortium in Ethics-Aware Design and Research; exploring Emotions: Study of Five Design Workshops for Generating Ideas for Emotional Self-report Interfaces; moving Away from the Blocks: Evaluating the Usability of EduBlocks for Supporting Children to Transition from Block-Based Programming; Point- and Volume-Based Multi-object Acquisition in VR; dark Finance: Exploring Deceptive Design in Investment Apps; elements that Influence Transparency in Artificial Intelligent Systems - A Survey; empowering Users: Leveraging Interface Cues to Enhance Password Security; friendly Folk Advice: Exploring Cybersecurity Information Sharing in Nigeria; trust in Facial Recognition Systems: A Perspective from the Users; comparing Screen-Based Version Control to Augmented Artifact Version Control for Physical Objects; emoClock: Communicating Real-Time Emotional States Through Data Physicalizations; extending User Interaction with Mixed Reality Through a Smartphone-Based Controller; fitts’ Throughput Vs Empirical Throughput: A Comparative Study; Developing and Evaluating a Novel Gamified Virtual Learning Environment for ASL; using Mid-Air Haptics to Guide Mid-Air Interactions; effects of Moving Speed and Phone Location on Eyes-Free Gesture Input with Mobile Devices; hap2Gest: An Eyes-Free Interaction Concept with Smartphones Using Gestures and Haptic Feedback; user-Centered Evaluation of Different Configurations of a Touchless Gestural Interface for Interactive Displays; assignment of a Vibration to a Graphical Object Induced by Resonant Frequency; mid-air Haptic Cursor for Physical Objects.,,Abstract,Abstract,
Scopus,journalPaper,2023,"Co-designing Immersive Virtual and Extended Reality Systems for Remote and Unsupervised Interaction, Intervention, Training and Research",INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,"We propose a one-day transdisciplinary workshop in the broad area of HCI focused on co-designing immersive virtual reality (IVR) for remote and unsupervised interaction, intervention, training and research. The development and deployment of such systems is a significant and important challenge. While remote and unsupervised systems are more accessible to a wider user-base, their design, implementation and deployment poses unique challenges, related to the need to involve truly transdisciplinary design teams, co-designing solutions with users, providing step-by-step interaction scenarios, and retaining user motivation and engagement over longer periods of time. Moreover, there are multiple ethical considerations related to both the inclusivity and accessibility of such systems and the security of data collected. Therefore, to facilitate the use of IVR systems in various contexts, ranging from unique interactions and research, through psychological interventions, to education and training, we propose to formulate a set of best practices. Taking into account the diverse aspects involved, we will formulate actionable guidelines for co-designing such solutions with users based on review of extant literature, expert knowledge, case studies and insights from the workshop. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",co-design; human-computer interaction; immersive virtual and extended reality systems; participatory design; remote and unsupervised interaction; transdisciplinary collaboration,Title_Abstract_Keywords,Abstract,
Scopus,journalPaper,2023,"19th IFIP TC 13 International Conference on Human-Computer Interaction, INTERACT 2023",INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,The proceedings contain 206 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: “The Relief is Amazing”: An In-situ Short Field Evaluation of a Personal Voice Assistive Technology for a User Living with Dementia; towards an Automatic Easy-to-Read Adaptation of Morphological Features in Spanish Texts; Challenges Faced by the Employed Indian DHH Community; haptic Auditory Feedback for Enhanced Image Description: A Study of User Preferences and Performance; using Colour and Brightness for Sound Zone Feedback; common Objects for Programming Workshops in Non-Formal Learning Contexts; engaging a Project Consortium in Ethics-Aware Design and Research; exploring Emotions: Study of Five Design Workshops for Generating Ideas for Emotional Self-report Interfaces; moving Away from the Blocks: Evaluating the Usability of EduBlocks for Supporting Children to Transition from Block-Based Programming; Point- and Volume-Based Multi-object Acquisition in VR; dark Finance: Exploring Deceptive Design in Investment Apps; elements that Influence Transparency in Artificial Intelligent Systems - A Survey; empowering Users: Leveraging Interface Cues to Enhance Password Security; friendly Folk Advice: Exploring Cybersecurity Information Sharing in Nigeria; trust in Facial Recognition Systems: A Perspective from the Users; comparing Screen-Based Version Control to Augmented Artifact Version Control for Physical Objects; emoClock: Communicating Real-Time Emotional States Through Data Physicalizations; extending User Interaction with Mixed Reality Through a Smartphone-Based Controller; fitts’ Throughput Vs Empirical Throughput: A Comparative Study; Developing and Evaluating a Novel Gamified Virtual Learning Environment for ASL; using Mid-Air Haptics to Guide Mid-Air Interactions; effects of Moving Speed and Phone Location on Eyes-Free Gesture Input with Mobile Devices; hap2Gest: An Eyes-Free Interaction Concept with Smartphones Using Gestures and Haptic Feedback; user-Centered Evaluation of Different Configurations of a Touchless Gestural Interface for Interactive Displays; assignment of a Vibration to a Graphical Object Induced by Resonant Frequency; mid-air Haptic Cursor for Physical Objects.,,Abstract,Abstract,Duplicate
Scopus,journalPaper,2023,"19th IFIP TC 13 International Conference on Human-Computer Interaction, INTERACT 2023",INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,The proceedings contain 206 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: “The Relief is Amazing”: An In-situ Short Field Evaluation of a Personal Voice Assistive Technology for a User Living with Dementia; towards an Automatic Easy-to-Read Adaptation of Morphological Features in Spanish Texts; Challenges Faced by the Employed Indian DHH Community; haptic Auditory Feedback for Enhanced Image Description: A Study of User Preferences and Performance; using Colour and Brightness for Sound Zone Feedback; common Objects for Programming Workshops in Non-Formal Learning Contexts; engaging a Project Consortium in Ethics-Aware Design and Research; exploring Emotions: Study of Five Design Workshops for Generating Ideas for Emotional Self-report Interfaces; moving Away from the Blocks: Evaluating the Usability of EduBlocks for Supporting Children to Transition from Block-Based Programming; Point- and Volume-Based Multi-object Acquisition in VR; dark Finance: Exploring Deceptive Design in Investment Apps; elements that Influence Transparency in Artificial Intelligent Systems - A Survey; empowering Users: Leveraging Interface Cues to Enhance Password Security; friendly Folk Advice: Exploring Cybersecurity Information Sharing in Nigeria; trust in Facial Recognition Systems: A Perspective from the Users; comparing Screen-Based Version Control to Augmented Artifact Version Control for Physical Objects; emoClock: Communicating Real-Time Emotional States Through Data Physicalizations; extending User Interaction with Mixed Reality Through a Smartphone-Based Controller; fitts’ Throughput Vs Empirical Throughput: A Comparative Study; Developing and Evaluating a Novel Gamified Virtual Learning Environment for ASL; using Mid-Air Haptics to Guide Mid-Air Interactions; effects of Moving Speed and Phone Location on Eyes-Free Gesture Input with Mobile Devices; hap2Gest: An Eyes-Free Interaction Concept with Smartphones Using Gestures and Haptic Feedback; user-Centered Evaluation of Different Configurations of a Touchless Gestural Interface for Interactive Displays; assignment of a Vibration to a Graphical Object Induced by Resonant Frequency; mid-air Haptic Cursor for Physical Objects.,,Abstract,Abstract,Duplicate
Scopus,journalPaper,2023,"19th IFIP TC 13 International Conference on Human-Computer Interaction, INTERACT 2023",INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,The proceedings contain 206 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: “The Relief is Amazing”: An In-situ Short Field Evaluation of a Personal Voice Assistive Technology for a User Living with Dementia; towards an Automatic Easy-to-Read Adaptation of Morphological Features in Spanish Texts; Challenges Faced by the Employed Indian DHH Community; haptic Auditory Feedback for Enhanced Image Description: A Study of User Preferences and Performance; using Colour and Brightness for Sound Zone Feedback; common Objects for Programming Workshops in Non-Formal Learning Contexts; engaging a Project Consortium in Ethics-Aware Design and Research; exploring Emotions: Study of Five Design Workshops for Generating Ideas for Emotional Self-report Interfaces; moving Away from the Blocks: Evaluating the Usability of EduBlocks for Supporting Children to Transition from Block-Based Programming; Point- and Volume-Based Multi-object Acquisition in VR; dark Finance: Exploring Deceptive Design in Investment Apps; elements that Influence Transparency in Artificial Intelligent Systems - A Survey; empowering Users: Leveraging Interface Cues to Enhance Password Security; friendly Folk Advice: Exploring Cybersecurity Information Sharing in Nigeria; trust in Facial Recognition Systems: A Perspective from the Users; comparing Screen-Based Version Control to Augmented Artifact Version Control for Physical Objects; emoClock: Communicating Real-Time Emotional States Through Data Physicalizations; extending User Interaction with Mixed Reality Through a Smartphone-Based Controller; fitts’ Throughput Vs Empirical Throughput: A Comparative Study; Developing and Evaluating a Novel Gamified Virtual Learning Environment for ASL; using Mid-Air Haptics to Guide Mid-Air Interactions; effects of Moving Speed and Phone Location on Eyes-Free Gesture Input with Mobile Devices; hap2Gest: An Eyes-Free Interaction Concept with Smartphones Using Gestures and Haptic Feedback; user-Centered Evaluation of Different Configurations of a Touchless Gestural Interface for Interactive Displays; assignment of a Vibration to a Graphical Object Induced by Resonant Frequency; mid-air Haptic Cursor for Physical Objects.,,Abstract,Abstract,Duplicate
Scopus,journalPaper,2021,An Empirical Study of Picture Password Composition on Smartwatches,INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,"Recent research works suggest that human cognitive differences affect security and usability of picture passwords within a variety of interaction contexts, such as conventional desktops, smartphones, and extended reality. However, the interplay of human cognition towards users’ interaction behavior and security of picture passwords on smartwatch devices has not been investigated so far. In this paper, we report on such a research attempt that embraced a between-subjects in-lab user study (n = 50) in which users were classified according to their cognitive processing characteristics (i.e., Field Dependence-Independence cognitive differences), and further composed a picture password on a smartwatch device. Analysis of results reveal that already known effects of human cognition towards interaction behavior and security of picture passwords within conventional interaction contexts, do not necessarily replicate when these are deployed on smartwatch devices. Findings point towards the need to design for diversity and device-aware picture password schemes. © 2021, IFIP International Federation for Information Processing.",Efficiency; Graphical authentication; Human cognition; Security,Abstract,Abstract_Keywords,
Scopus,journalPaper,2019,Influences of mixed reality and human cognition on picture passwords: An eye tracking study,INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,"Recent research revealed that individual cognitive differences affect visual behavior and task performance of picture passwords within conventional interaction realms such as desktops and tablets. Bearing in mind that mixed reality environments necessitate from end-users to perceive, process and comprehend visually-enriched content, this paper further investigates whether this new interaction realm amplifies existing observed effects of individual cognitive differences towards user interactions in picture passwords. For this purpose, we conducted a comparative eye tracking study (N = 50) in which users performed a picture password composition task within a conventional interaction context vs. a mixed reality context. For interpreting the derived results, we adopted an accredited human cognition theory that highlights cognitive differences in visual perception and search. Analysis of results revealed that new technology realms like mixed reality extend and, in some cases, amplify the effect of human cognitive differences towards users’ visual and interaction behavior in picture passwords. Findings can be of value for improving future implementations of picture passwords by considering human cognitive differences as a personalization factor for the design of user-adaptive graphical passwords in mixed reality. © 2019, IFIP International Federation for Information Processing.",Eye tracking; Human cognition; Mixed reality; Picture passwords; Security; Usability; Visual behavior,Title_Abstract_Keywords,Keywords,
Scopus,journalPaper,2017,"16th IFIP TC13 International Conference on Human-Computer Interaction, INTERACT 2017",INTERACT - IFIP TC 13 International Conference on Human-Computer Interaction,B,"The proceedings contain 161 papers. The special focus in this conference is on Human-Computer Interaction. The topics include: Coping with accessibility challenges for security - a user study with blind smartphone users; effects of uncertainty and cognitive load on user trust in predictive decision making; towards understanding the influence of personality on mobile app permission settings; towards understanding the influence of personality on mobile app permission settings; exploring offline context and consciousness in everyday social media use; the design of alipay and wechat wallet for mobile payment practices in china; active involvement of software developers in usability engineering; adoption of UX evaluation in practice; empowering project managers in enterprises - a design thinking approach to manage commercial projects; learning HCI across institutions, disciplines and countries; UX professionals' definitions of usability and UX - a comparison between turkey, finland, denmark, france and malaysia; estimating visual discomfort in head-mounted displays using electroencephalography; immersion and reflection between reality and virtuality; guidelines for designing interactive omnidirectional video applications; increasing presence in virtual reality with a vibrotactile grid around the head; user experience and immersion of interactive omnidirectional videos in CAVE systems and head-mounted displays; a digital employability marketplace; adoption of structural analysis capabilities in an IOT based scenario for connected assets; design and development of a location-based social networking mobile application; designing interactive spatiotemporal visualizations to enhance movie browsing; designing and assessing interactive systems using task models.",,Abstract,Abstract,Duplicate
Scopus,journalPaper,2021,Understanding Bystanders’ Tendency to Shoulder Surf Smartphones Using 360-degree Videos in Virtual Reality,MobileHCI - International Conference on Human-Computer Interaction with Mobile Devices and Services,B,"Shoulder surfing is an omnipresent risk for smartphone users. However, investigating these attacks in the wild is difficult because of either privacy concerns, lack of consent, or the fact that asking for consent would influence people’s behavior (e.g., they could try to avoid looking at smartphones). Thus, we propose utilizing 360-degree videos in Virtual Reality (VR), recorded in staged real-life situations on public transport. Despite differences between perceiving videos in VR and experiencing real-world situations, we believe this approach to allow novel insights on observers’ tendency to shoulder surf another person’s phone authentication and interaction to be gained. By conducting a study (N=16), we demonstrate that a better understanding of shoulder surfers’ behavior can be obtained by analyzing gaze data during video watching and comparing it to post-hoc interview responses. On average, participants looked at the phone for about 11% of the time it was visible and could remember half of the applications used.",Eye Tracking; Omnidirectional Videos; Shoulder Surfing; Virtual Reality,Title_Abstract_Keywords,Abstract,
Scopus,journalPaper,2024,Exploring Redirection and Shifting Techniques to Mask Hand Movements from Shoulder-Surfing Attacks during PIN Authentication in Virtual Reality,MobileHCI - International Conference on Human-Computer Interaction with Mobile Devices and Services,B,"The proliferation of mobile Virtual Reality (VR) headsets shifts our interaction with virtual worlds beyond our living rooms into shared spaces. Consequently, we are entrusting more and more personal data to these devices, calling for strong security measures and authentication. However, the standard authentication method of such devices - entering PINs via virtual keyboards - is vulnerable to shoulder-surfing, as movements to enter keys can be monitored by an unnoticed observer. To address this, we evaluated masking techniques to obscure VR users' input during PIN authentication by diverting their hand movements. Through two experimental studies, we demonstrate that these methods increase users' security against shoulder-surfing attacks from observers without excessively impacting their experience and performance. With these discoveries, we aim to enhance the security of future VR authentication without disrupting the virtual experience or necessitating additional hardware or training of users.",hand redirection; shoulder-surfing; virtual reality,Title_Abstract_Keywords,Title_Abstract,
Scopus,journalPaper,2024,Medusa3D: The Watchful Eye Freezing Illegitimate Users in Virtual Reality Interactions,MobileHCI - International Conference on Human-Computer Interaction with Mobile Devices and Services,B,"The remarkable growth of Virtual Reality (VR) in recent years has extended its applications beyond entertainment to sectors including education, e-commerce, and remote communication. Since VR devices contain user's private information, user authentication becomes increasingly important. Current authentication systems in VR, such as password-based or static biometric-based methods, are either cumbersome to use or vulnerable to attacks such as shoulder surfing. To address these limitations, we propose Medusa3D, a challenge-response authentication system for VR based on reflexive eye responses. Unlike existing methods, reflexive eye responses are involuntary and effortless, offering a secure and user-friendly credential for authentication. We implement Medusa3D on an off-the-shelf VR and conduct evaluations with 25 participants. The evaluation results show that Medusa3D achieves 0.21% FAR and 0.13% FRR, demonstrating high security under various ocular conditions and resilience against attacks such as zero-effort attack, replay attack, and mimicry attack. A user study indicates that Medusa3D is user-friendly and well-adopted among participants.",gaze; user authentication; vr,Title_Abstract,Abstract_Keywords,
Scopus,journalPaper,2024,A cloud-edge service offloading method for the metaverse in smart manufacturing,SPE  - Software - Practice and Experience,B,"With the development of artificial intelligence, cloud-edge computing and virtual reality, the industrial design that originally depends on human imagination and computing power can be transitioned to metaverse applications in smart manufacturing, which offloads the services of metaverse to cloud and edge platforms for enhancing quality of service (QoS), considering inadequate computing power of terminal devices like industrial sensors and access points (APs). However, large overhead and privacy exposure occur during data transmission to cloud, while edge computing devices (ECDs) are at risk of overloading with redundant service requests and difficult central control. To address these challenges, this paper proposes a minority game (MG) based cloud-edge service offloading method named COM for metaverse manufacturing. Technically, MG possesses a distribution mechanism that can minimize reliance on centralized control, and gains its effectiveness in resource allocation. Besides, a dynamic control of cut-off value is supplemented on the basis of MG for better adaptability to network variations. Then, agents in COM (i.e., APs) leverage reinforcement learning (RL) to work on MG history, offloading decision, QoS mapping to state, action and reward, for further optimizing distributed offloading decision-making. Finally, COM is evaluated using a variety of real-world datasets of manufacturing. The results indicate that COM has 5.38% higher QoS and 8.58% higher privacy level comparing to benchmark method. © 2023 John Wiley & Sons Ltd.",cloud-edge computing; metaverse; minority game; reinforcement learning; service offloading,Title_Abstract_Keywords,Abstract,
ACM DL,conferencePaper,2023,Toward a Secure Educational Metaverse: A Tale of Blockchain Design for Educational Environments,SEAA - Euromicro Conference on Software Engineering and Advanced Applications,B,"In the era of social distancing, distance learning represents a crucial educational challenge. Several 2D information technologies have been provided, yet these share multiple limitations and have negative social, educational, and psychological implications for learners. Metaverse promises to revolutionize education as we know it: this is a persistent, virtual, three-dimensional environment that is supposed to address most of the limitations of 2D information technologies. Nonetheless, there are still software engineering challenges to face to enable such a metaverse, especially when turning to software security and privacy. In this paper, we aim at performing the first steps toward an improved understanding of the security perspective of educational metaverse, by analyzing how blockchain can be employed within educational environments and how applications may be designed. Our ultimate goal is to provide insights into how blockchain can be further tailored in the context of educational metaverse. We conduct a systematic literature review, which targets 20 primary studies. The key findings of the study showcase the use of blockchain in 3 educational tasks, other than describing the blockchain design approaches, which protocol they commonly use and the associated limitations. We conclude by developing a conceptualization of a blockchain-based educational metaverse.",Bibliographies; Blockchain; Blockchains; Education; Educational Metaverse; Metaverse; Security; Software; Systematic Literature Review; Systematics; Turning,Title_Abstract_Keywords,Abstract_Keywords,
Scopus,conferencePaper,2018,Safe-AR: Reducing Risk while Augmenting Reality,ISSRE - International Symposium on Software Reliability Engineering,A,"Augmented reality (AR) systems excel at offering users real-time, situation-aware information to support users' decision making. With AR, rich visualizations of relevant data can be displayed to users without blocking their view of the real world. For example, an AR-enabled automotive windshield can display a red outline around a pedestrian to alert a driver starting a turn into that cross street. Other critical uses of AR applications that are or will soon be deployed include surgery, emergency response, vehicle maintenance, and pilot training. Many of these applications can enhance operational safety. However, developing risk analysis methods to handle failure modes in the melded virtual and physical realities remains an open problem. This paper proposes a risk analysis method with which to study computer-generated AR visualizations of system and environment states. The analysis framework incorporates three levels at which AR interfaces with the user: perception, comprehension, and decision-making. This method enables broader risk analysis of the entire cyber-physical-human system that an AR application may indirectly control. Preliminary results show that this method yields improved coverage of user-involved failure modes over current approaches. While the focus here is on safety, the method also appears applicable to AR security risks. © 2018 IEEE.",,Abstract,Abstract,
